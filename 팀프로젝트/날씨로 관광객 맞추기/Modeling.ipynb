{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Modeling.ipynb","provenance":[],"collapsed_sections":["jh1zabyiqGV4","HMeRJUcVCSSI","c8j9BBhpnP8d"],"mount_file_id":"13OUq9_veXAhz_axWidZ2YtXHZrLeGfx5","authorship_tag":"ABX9TyNPXLl3sJCRdN9qHQL3uZtF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HoigO5LNdQgc"},"source":["# # /content/drive/MyDrive/Proj_WT/DataSets/박정열/덕수궁_가을.csv\n","# import os\n","# from google.colab import drive\n","# # 구글 드라이브 접근\n","# ROOT = \"/content/drive\"\n","# drive.mount(ROOT)\n","# from os.path import join\n","# # 공유 폴더\n","# CO_WORK = \"MyDrive/Proj_WT\"\n","# CW_PATH = join(ROOT, CO_WORK)\n","# DATAS = \"DataSets/박정열/\"  # EDA 끝낸 데이터\n","# DATA_PATH = join(CW_PATH, DATAS)\n","# import numpy as np\n","# import pandas as pd\n","# tour_lst = ['덕수궁', '서대문자연사박물관', '서울시립미술관', '선릉정릉',\n","#             '종묘', '창경궁', '창덕궁', '태릉강릉', '헌릉인릉']\n","# season_lst = ['봄', '여름', '가을', '겨울']\n","# def load_csv2(path=None, tour_list=None, season_list=None):\n","#   dfname_list = []\n","#   for df in tour_list:\n","#     for ss in season_list:\n","#       dfname_list.append(df+\"_\"+ss)\n","#   for fname in dfname_list:\n","#     try:  # 인코딩 에러 피하기 위한 방법\n","#       globals()[f\"DF_{fname}\"] = pd.read_csv(f\"{path}/{fname}.csv\", encoding='euc-kr')\n","#       globals()[f\"DF_{fname}\"] = globals()[f\"DF_{fname}\"].loc[:, [chk for chk in globals()[f\"DF_{fname}\"] if \"Unnamed\" not in chk]] #혹시 index도 같이 저장되었으면 없애줌\n","#     except:\n","#       try:\n","#         globals()[f\"DF_{fname}\"] = pd.read_csv(f\"{path}/{fname}.csv\", encoding='cp949')\n","#         globals()[f\"DF_{fname}\"] = globals()[f\"DF_{fname}\"].loc[:, [chk for chk in globals()[f\"DF_{fname}\"] if \"Unnamed\" not in chk]]\n","#       except:\n","#         globals()[f\"DF_{fname}\"] = pd.read_csv(f\"{path}/{fname}.csv\", encoding='utf-8')\n","#         globals()[f\"DF_{fname}\"] = globals()[f\"DF_{fname}\"].loc[:, [chk for chk in globals()[f\"DF_{fname}\"] if \"Unnamed\" not in chk]]\n","#   dfname_list = [\"DF_\"+fname for fname in dfname_list]  #모델 반복문 돌릴 때 필요한 변수(list형태)\n","#   return dfname_list\n","# path = DATA_PATH\n","# dflst = load_csv2(path, tour_lst, season_lst)\n","\n","#################################################################################################\n","# 덕수궁 = []\n","# 서대문자연사박물관 = []\n","\n","# 관광지 = []\n","# for i in tour_lst:\n","#   관광지.append(i)\n","#   for j in season_lst:\n","#     data = pd.read_csv(DATA_PATH + i + '_' + j + '.csv')\n","#     덕수궁.append(data)\n","\n","# import os\n","# from google.colab import drive\n","# # 구글 드라이브 접근\n","# ROOT = \"/content/drive\"\n","# drive.mount(ROOT)\n","# from os.path import join\n","# # 공유 폴더\n","# CO_WORK = \"MyDrive/Proj_WT\"\n","# CW_PATH = join(ROOT, CO_WORK)\n","# DATAS = \"DataSets/박정열\"  # EDA 끝낸 데이터\n","# DATA_PATH = join(CW_PATH, DATAS)\n","# import numpy as np\n","# import pandas as pd\n","# def load_csv(path=None):\n","#   file_list = os.listdir(path)\n","#   file_list = [fpath for fpath in file_list if '(' not in fpath]\n","#   dfname_list = []\n","#   for fpath in file_list:\n","#     fname = fpath.split('.')[0]\n","#     dfname_list.append(\"DF_\"+fname) #모델 반복문 돌릴 때 필요한 데이터프레임 변수명 리스트\n","#     try:  # 인코딩 에러 피하기 위한 방법\n","#       globals()[f\"DF_{fname}\"] = pd.read_csv(f\"{path}/{fpath}\", encoding='euc-kr')\n","#       globals()[f\"DF_{fname}\"] = globals()[f\"DF_{fname}\"].loc[:, [chk for chk in globals()[f\"DF_{fname}\"] if \"Unnamed\" not in chk]] #혹시 index도 같이 저장되었으면 없애줌\n","#     except:\n","#       try:\n","#         globals()[f\"DF_{fname}\"] = pd.read_csv(f\"{path}/{fpath}\", encoding='cp949')\n","#         globals()[f\"DF_{fname}\"] = globals()[f\"DF_{fname}\"].loc[:, [chk for chk in globals()[f\"DF_{fname}\"] if \"Unnamed\" not in chk]]\n","#       except:\n","#         globals()[f\"DF_{fname}\"] = pd.read_csv(f\"{path}/{fpath}\", encoding='utf-8')\n","#         globals()[f\"DF_{fname}\"] = globals()[f\"DF_{fname}\"].loc[:, [chk for chk in globals()[f\"DF_{fname}\"] if \"Unnamed\" not in chk]]\n","#   return dfname_list\n","# path = DATA_PATH\n","# dflst = load_csv(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTs_oz2o-dtJ","executionInfo":{"status":"ok","timestamp":1626975971456,"user_tz":-540,"elapsed":5466,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"6287bc5b-d2d4-43f9-e145-49a756d781cc"},"source":["# class에 필요한 모든 모듈 불러오기\n","!pip install vecstack\n","!pip install catboost\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","from vecstack import stacking\n","from sklearn.ensemble import VotingRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: vecstack in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from vecstack) (0.22.2.post1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.19.5)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (1.0.1)\n","Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.26)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XbHZaBkNoyC-","executionInfo":{"status":"ok","timestamp":1626975972123,"user_tz":-540,"elapsed":670,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# 전체 데이터를 불러오는 class 만들기\n","class data_bring:\n","  def data_bring():\n","    # 관광지를 dict형태로 저장한다.\n","    target_map = ['ChangDeokGung', 'ChangGyeongGung', 'DuckSooGung', 'GyeongBokGung', 'HeonLeungInReung', 'JongMyo',\n","                  'SeoDaeMunNaturalHistoryMuseum', 'SeoulMuseumOfArt', 'SunReungJungReung', 'TaeReungGangNeung', 'TrickEyeMuseum',\n","                  'SeoDaeMunPrisonHistoryMuseum', 'NamSanGolHanOkVillage', 'NationalMuseumOfKorea']\n","\n","    # colab path를 찾는다.\n","    PATH = '/content/drive/MyDrive/Proj_WT/DataSets/weathergodata/'\n","    # dict로 담아놓을 공간을 만든다.\n","    bucket = {}\n","    # items를 사용하여 각 key와 value를 받는다.\n","    for i in target_map:\n","      # 불러올 데이터의 path를 지정한다.\n","      final_path = PATH + i + '.csv'\n","      # 데이터를 불러온다.\n","      data = pd.read_csv(final_path)\n","      # 관광지에 데이터를 담는다.\n","      bucket[f'{i}'] = data\n","\n","    return bucket\n","\n","# 전처리와 각 모델들을 저장할 class를 만든다.\n","class modeling:\n","  # train과 test로 나누기\n","  def train_test_split(data = None):\n","    # 2018년 12월 이전을 train\n","    train = data[data['date'] <= 201812]\n","    # 2018년 12월 이후를 test\n","    test = data[data['date'] > 201812]\n","    # train을 X_train, y_train으로 나눈다.\n","    X_train, y_train = train.drop('target', axis = 1), train['target']\n","    # test를 X_test, y_test로 나눈다.\n","    X_test, y_test = test.drop('target', axis = 1), test['target']\n","\n","    X_test.reset_index(drop = True, inplace = True)\n","    X_train = X_train.drop('date', axis = 1)\n","    X_test = X_test.drop('date', axis = 1)\n","    return X_train, X_test, y_train, y_test\n","\n","  def lmm_train_test_split(data = None):\n","    # 2018년 12월 이전을 train\n","    train = data[data['date'] <= 201812]\n","    # 2018년 12월 이후를 test\n","    test = data[data['date'] > 201812]\n","    # train을 X_train, y_train으로 나눈다.\n","    X_train, y_train = train.drop('target', axis = 1), train['target']\n","    # test를 X_test, y_test로 나눈다.\n","    X_test, y_test = test.drop('target', axis = 1), test['target']\n","    X_test.reset_index(drop = True, inplace = True)\n","    X_train['month'] = X_train['date'].apply(lambda x: str(x)[4:])\n","    X_test['month'] = X_test['date'].apply(lambda x:str(x)[4:])\n","    return X_train, X_test, y_train, y_test\n","\n","\n","  # linear regression 돌리기\n","  def lr():\n","    model = LinearRegression()\n","    \n","    return model\n","  # xgboost 돌리기\n","  def xgb():\n","    model = XGBRegressor(random_state = 42,tree_method = 'gpu_hist')\n","\n","    return model\n","  # lightgbm\n","  def lgb():\n","    model = LGBMRegressor(random_state = 42)\n","\n","    return model\n","  # catboost\n","  def cat():\n","    model = CatBoostRegressor(random_state = 42,task_type = 'GPU')\n","    return model\n","  # ridge\n","  def ridge():\n","    model = Ridge(random_state = 42)\n","    return model\n","  \n","  # lasso\n","  def lasso():\n","    model = Lasso()\n","\n","    return model\n","\n","  # adaboost\n","  def ada():\n","    model = AdaBoostRegressor(random_state = 42)\n","\n","    return model\n","\n","  # randomforest\n","  def rfg():\n","    model = RandomForestRegressor(random_state = 42)\n","    \n","    return model\n","\n","  def gb():\n","    model = GradientBoostingRegressor(random_state = 42)\n","    return model\n","\n","  def decision():\n","    model = DecisionTreeRegressor(random_state = 42)\n","    return model\n","\n","  def elasticnet():\n","    model = ElasticNet(random_state = 42)\n","    return model\n","\n","\n","  # rmse가 가장 낮은 것을 데이터 프레임으로 rmse함수를 만든다.\n","  def rmse(y_test, y_pred):\n","    RMSE = mean_squared_error(y_test, y_pred)**0.5\n","\n","    return RMSE\n","\n","  def smape(y_true, y_pred):\n","    return 1/len(y_true) * np.sum(2 * np.abs(y_pred-y_true)/(np.abs(y_true) + np.abs(y_pred)) *100)\n","\n","# 모델 전부 한번씩 돌려보기\n","class class_all_model:\n","  # 각 모델을 돌리기 위해서 dict로 쌓아준다.\n","  def models():\n","    models = {'lr':modeling.lr(), 'lgb':modeling.lgb(), 'xgb':modeling.xgb(), 'lasso':modeling.lasso(),'ridge':modeling.ridge(),'ada':modeling.ada(), 'rfg':modeling.rfg(), 'gb':modeling.gb(), 'decision':modeling.decision(),'elastic': modeling.elasticnet()}\n","    return models\n","  \n","  # 모델을 하나씩 돌려서 keys = 모델명, value = 모델의 rmse를 쌓아준다.\n","  def run(data = None):\n","    models = class_all_model.models()\n","    # 모델별로 rmse를 넣는다.\n","    final_rmse = {}\n","    # 모델별로 score를 넣는다.\n","    model_score = {}\n","    # 모델의 파라미터를 저장한다. \n","    model_store = {}\n","    # 모델별로 smape을 넣는다.\n","    model_smape = {}\n","\n","    # 데이터를 train과 test로 나눈다.\n","    X_train, X_test, y_train, y_test = modeling.train_test_split(data = data)\n","    # dict로 쌓아놓은 데이터를 전부 가져온다.\n","    for i, j in models.items():\n","      # 각 모델의 y_pred를 구한다.\n","      model = j\n","      model.fit(X_train, y_train)\n","      y_pred = model.predict(X_test)\n","      \n","      # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","      final_rmse[i] = modeling.rmse(y_test, y_pred)\n","      model_score[i] = model.score(X_test, y_test)\n","      model_store[i] = model\n","      model_smape[i] = modeling.smape(y_test, y_pred)\n","\n","    return final_rmse, model_score, model_store, model_smape\n","\n","# LMM(Linear Mixture Model)\n","class lmm:\n","  # 처음으로 LinearRegression을 돌려준다.\n","  def linearmodel(data = None):\n","    X_train, X_test, y_train, y_test = modeling.train_test_split(data)\n","    model = modeling.lr()\n","    model.fit(X_train,y_train)\n","    train_y_pred = model.predict(X_train)\n","    test_y_pred = model.predict(X_test)\n","\n","    train_y_pred = pd.DataFrame(train_y_pred, columns = ['target_pred'])\n","    test_y_pred = pd.DataFrame(test_y_pred, columns = ['target_pred'])\n","\n","    return train_y_pred, test_y_pred\n","\n","  # lmm.linearmodel로 돌린 데이터를 변수로 넣어주고 다시 돌린다.\n","  def lmm_mean(data = None):\n","    # 변수를 mapping시켜주기 위해서 lmm_train_test_split을 써준다.\n","    X_train, X_test, y_train, y_test = modeling.lmm_train_test_split(data = data)\n","\n","    # train의 예측값과 test의 예측값을 가져온다.\n","    train_y_pred, test_y_pred = lmm.linearmodel(data = data)\n","\n","    # X_train과 y_train에 각각 넣어준다.\n","    X_train = pd.concat([X_train, train_y_pred], axis = 1)\n","    X_test = pd.concat([X_test, test_y_pred], axis = 1)\n","\n","    # groupby를 통해 month별 예측 평균을 구해준다.\n","    train_target_pred = X_train.groupby('month')['target_pred'].mean().reset_index()\n","    test_target_pred = X_test.groupby('month')['target_pred'].mean().reset_index()\n","\n","    # train과 test에 merge시킨다\n","    X_train = pd.merge(X_train, train_target_pred, on = 'month', how = 'left')\n","    X_test = pd.merge(X_test, test_target_pred, on = 'month', how = 'left')\n","\n","    # 예측값, date, month를 제거해준다.\n","    X_train = X_train.drop(['date','month','target_pred_x'], axis = 1)\n","    X_test = X_test.drop(['date','month','target_pred_x'], axis = 1)\n","\n","    # 다시 LinearRegression을 돌려준다.\n","    model = modeling.lr()\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    \n","    # 평가지표를 저장한다.\n","    score = model.score(X_test, y_test)\n","    rmse = modeling.rmse(y_test, y_pred)\n","    smape = modeling.smape(y_test, y_pred)\n","\n","    return rmse, score, model, smape\n","\n","  # lmm.linearmodel로 돌린 데이터를 변수로 넣어주고 다시 돌린다.\n","  def lmm_median(data = None):\n","    # 변수를 mapping시켜주기 위해서 lmm_train_test_split을 써준다.\n","    X_train, X_test, y_train, y_test = modeling.lmm_train_test_split(data = data)\n","\n","    # train의 예측값과 test의 예측값을 가져온다.\n","    train_y_pred, test_y_pred = lmm.linearmodel(data = data)\n","\n","    # X_train과 y_train에 각각 넣어준다.\n","    X_train = pd.concat([X_train, train_y_pred], axis = 1)\n","    X_test = pd.concat([X_test, test_y_pred], axis = 1)\n","\n","    # groupby를 통해 month별 예측 중앙값을 구해준다.\n","    train_target_pred = X_train.groupby('month')['target_pred'].median().reset_index()\n","    test_target_pred = X_test.groupby('month')['target_pred'].median().reset_index()\n","\n","    # train과 test에 merge시킨다\n","    X_train = pd.merge(X_train, train_target_pred, on = 'month', how = 'left')\n","    X_test = pd.merge(X_test, test_target_pred, on = 'month', how = 'left')\n","\n","    # 예측값, date, month를 제거해준다.\n","    X_train = X_train.drop(['date','month','target_pred_x'], axis = 1)\n","    X_test = X_test.drop(['date','month','target_pred_x'], axis = 1)\n","\n","    # 다시 LinearRegression을 돌려준다.\n","    model = modeling.lr()\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    # 평가지표를 저장한다.\n","    score = model.score(X_test, y_test)\n","    rmse = modeling.rmse(y_test, y_pred)\n","    smape = modeling.smape(y_test, y_pred)\n","\n","    return rmse, score, model, smape   \n","\n","  # lmm.linearmodel로 돌린 데이터를 변수로 넣어주고 다시 돌린다.\n","  def lmm_log(data = None):\n","    # 변수를 mapping시켜주기 위해서 lmm_train_test_split을 써준다.\n","    X_train, X_test, y_train, y_test = modeling.lmm_train_test_split(data = data)\n","\n","    # train의 예측값과 test의 예측값을 가져온다.\n","    train_y_pred, test_y_pred = lmm.linearmodel(data = data)\n","    \n","    # X_train과 y_train에 각각 넣어준다.\n","    X_train = pd.concat([X_train, train_y_pred], axis = 1)\n","    X_test = pd.concat([X_test, test_y_pred], axis = 1)\n","\n","    # 넣어줬던 데이터를 log화 시켜서 데이터에 넣어준다.    \n","    X_train['target_pred'] = X_train['target_pred'].apply(lambda x:np.log1p(x))\n","    X_test['target_pred'] = X_test['target_pred'].apply(lambda x: np.log1p(x))\n","\n","    # date, month를 제거해준다.\n","    X_train = X_train.drop(['date','month'], axis = 1)\n","    X_test = X_test.drop(['date','month'], axis = 1)\n","\n","    # 다시 LinearRegression을 돌려준다.\n","    model = modeling.lr()\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    # 평가지표를 저장한다.\n","    score = model.score(X_test, y_test)\n","    rmse = modeling.rmse(y_test, y_pred)\n","    smape = modeling.smape(y_test, y_pred)\n","\n","    return rmse, score, model, smape\n","\n","\n","# dict로 쌓여있는 모델을 돌린다.\n","class final_model:\n","  def run(data = None):\n","    # 위의 class에서 모델을 돌려서 rmse, score, model을 불러온다.\n","    final_rmse , model_score, model, model_smape = class_all_model.run(data = data)\n","    final_rmse['lmm_mean'], model_score['lmm_mean'], model['lmm_mean'], model_smape['lmm_mean'] = lmm.lmm_mean(data =data)\n","    final_rmse['lmm_median'], model_score['lmm_median'], model['lmm_median'], model_smape['lmm_median'] = lmm.lmm_median(data =data)\n","\n","    # lmm.lmm_log만  try except를 사용한 이유는 예측값이 -값이 나오게 된다면 log를 씌울 수 없기 때문이다.\n","    try:\n","      final_rmse['lmm_log'], model_score['lmm_log'], model['lmm_log'], model_smape['lmm_log'] = lmm.lmm_log(data =data)\n","    except:\n","      pass\n","\n","    # model_score의 key = 모델 , value = 모델의 score를 받는다.\n","    for i, j in model_score.items():\n","      # score가 가장 높은 모델을 찾아낸다.\n","      if j == max(model_score.values()):\n","        # score가 가장 높은 모델을 dataframe의 형태로 만들기 위한 작업을 한다.\n","        model = model[i]\n","        final_rmse = final_rmse[i]\n","        model_score = model_score[i]\n","        model_smape = model_smape[i]\n","\n","        break\n","\n","    # 가장 score가 높은 모델의 모델, rmse, score를 데이터 프레임 형태로 저장한다.\n","    score = pd.DataFrame([[model, final_rmse, model_score, model_smape]], columns = ['model','final_rmse','model_score','model_smape'], index = [i])\n","\n","    return score\n","\n","# 각 관광지의 데이터를 하나의 데이터 프레임에 보기 위해서 class 를 생성한다.\n","class data_concat:\n","  def final_run():\n","    # 관광지별 데이터를 전부 불러온다.\n","    final_dict = data_bring.data_bring()\n","    # 각 관광지별 rmse, model, score를 저장할 데이터 프레임을 만든다.\n","    final_dataframe = pd.DataFrame([])\n","    # 각 관광지별 데이터를 가져온다.\n","    for i, j in final_dict.items():\n","      # 각 관광지별 데이터를 위에 선언된 class로 모델을 돌린다.\n","      dataframe = final_model.run(data = j)\n","      # 관광지라는 변수를 지정해준다.\n","      # 왜 이렇게 하는가? index에 바로 안들어가기 때문이다.\n","      dataframe['TourSpot'] = i\n","      # 관광지를 concat으로 쌓는다.\n","      final_dataframe =  pd.concat([final_dataframe,dataframe], axis = 0)\n","    # 최종 데이터 프레임이 만들어지면 관광지를 index로 변경해준다.\n","    # final_dataframe.index = final_dataframe['TourSpot']\n","    # 관광지라는 컬럼을 제거한다.\n","    # final_dataframe.drop('TourSpot', axis = 1, inplace = True)\n","\n","    return final_dataframe"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":716},"id":"L6DwYjG-vnYn","executionInfo":{"status":"ok","timestamp":1626975981141,"user_tz":-540,"elapsed":9020,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"e89ffe73-c10b-4ed4-ef00-984506ba76f3"},"source":["data_concat.final_run()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["[17:46:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","[17:46:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>final_rmse</th>\n","      <th>model_score</th>\n","      <th>model_smape</th>\n","      <th>TourSpot</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>decision</th>\n","      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n","      <td>9657.777928</td>\n","      <td>0.962743</td>\n","      <td>9.218917</td>\n","      <td>ChangDeokGung</td>\n","    </tr>\n","    <tr>\n","      <th>lr</th>\n","      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n","      <td>9222.652742</td>\n","      <td>0.874627</td>\n","      <td>14.673402</td>\n","      <td>ChangGyeongGung</td>\n","    </tr>\n","    <tr>\n","      <th>gb</th>\n","      <td>([DecisionTreeRegressor(ccp_alpha=0.0, criteri...</td>\n","      <td>27373.745443</td>\n","      <td>0.751337</td>\n","      <td>12.756385</td>\n","      <td>DuckSooGung</td>\n","    </tr>\n","    <tr>\n","      <th>lgb</th>\n","      <td>LGBMRegressor(boosting_type='gbdt', class_weig...</td>\n","      <td>36664.030079</td>\n","      <td>0.864150</td>\n","      <td>9.696550</td>\n","      <td>GyeongBokGung</td>\n","    </tr>\n","    <tr>\n","      <th>decision</th>\n","      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n","      <td>651.179763</td>\n","      <td>0.900403</td>\n","      <td>16.024904</td>\n","      <td>HeonLeungInReung</td>\n","    </tr>\n","    <tr>\n","      <th>lgb</th>\n","      <td>LGBMRegressor(boosting_type='gbdt', class_weig...</td>\n","      <td>5016.178262</td>\n","      <td>0.782613</td>\n","      <td>15.724096</td>\n","      <td>JongMyo</td>\n","    </tr>\n","    <tr>\n","      <th>xgb</th>\n","      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n","      <td>3341.165393</td>\n","      <td>0.663756</td>\n","      <td>12.604186</td>\n","      <td>SeoDaeMunNaturalHistoryMuseum</td>\n","    </tr>\n","    <tr>\n","      <th>decision</th>\n","      <td>DecisionTreeRegressor(ccp_alpha=0.0, criterion...</td>\n","      <td>33065.193759</td>\n","      <td>0.794934</td>\n","      <td>19.888264</td>\n","      <td>SeoulMuseumOfArt</td>\n","    </tr>\n","    <tr>\n","      <th>rfg</th>\n","      <td>(DecisionTreeRegressor(ccp_alpha=0.0, criterio...</td>\n","      <td>2051.322433</td>\n","      <td>0.976263</td>\n","      <td>5.302718</td>\n","      <td>SunReungJungReung</td>\n","    </tr>\n","    <tr>\n","      <th>xgb</th>\n","      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n","      <td>1613.953000</td>\n","      <td>0.944599</td>\n","      <td>18.201148</td>\n","      <td>TaeReungGangNeung</td>\n","    </tr>\n","    <tr>\n","      <th>xgb</th>\n","      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n","      <td>580.798771</td>\n","      <td>0.846056</td>\n","      <td>15.079752</td>\n","      <td>TrickEyeMuseum</td>\n","    </tr>\n","    <tr>\n","      <th>xgb</th>\n","      <td>XGBRegressor(base_score=0.5, booster='gbtree',...</td>\n","      <td>25057.625895</td>\n","      <td>0.473651</td>\n","      <td>23.341317</td>\n","      <td>SeoDaeMunPrisonHistoryMuseum</td>\n","    </tr>\n","    <tr>\n","      <th>lgb</th>\n","      <td>LGBMRegressor(boosting_type='gbdt', class_weig...</td>\n","      <td>15717.192657</td>\n","      <td>0.811186</td>\n","      <td>10.920657</td>\n","      <td>NamSanGolHanOkVillage</td>\n","    </tr>\n","    <tr>\n","      <th>gb</th>\n","      <td>([DecisionTreeRegressor(ccp_alpha=0.0, criteri...</td>\n","      <td>13627.908880</td>\n","      <td>0.972742</td>\n","      <td>4.759947</td>\n","      <td>NationalMuseumOfKorea</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                      model  ...                       TourSpot\n","decision  DecisionTreeRegressor(ccp_alpha=0.0, criterion...  ...                  ChangDeokGung\n","lr        LinearRegression(copy_X=True, fit_intercept=Tr...  ...                ChangGyeongGung\n","gb        ([DecisionTreeRegressor(ccp_alpha=0.0, criteri...  ...                    DuckSooGung\n","lgb       LGBMRegressor(boosting_type='gbdt', class_weig...  ...                  GyeongBokGung\n","decision  DecisionTreeRegressor(ccp_alpha=0.0, criterion...  ...               HeonLeungInReung\n","lgb       LGBMRegressor(boosting_type='gbdt', class_weig...  ...                        JongMyo\n","xgb       XGBRegressor(base_score=0.5, booster='gbtree',...  ...  SeoDaeMunNaturalHistoryMuseum\n","decision  DecisionTreeRegressor(ccp_alpha=0.0, criterion...  ...               SeoulMuseumOfArt\n","rfg       (DecisionTreeRegressor(ccp_alpha=0.0, criterio...  ...              SunReungJungReung\n","xgb       XGBRegressor(base_score=0.5, booster='gbtree',...  ...              TaeReungGangNeung\n","xgb       XGBRegressor(base_score=0.5, booster='gbtree',...  ...                 TrickEyeMuseum\n","xgb       XGBRegressor(base_score=0.5, booster='gbtree',...  ...   SeoDaeMunPrisonHistoryMuseum\n","lgb       LGBMRegressor(boosting_type='gbdt', class_weig...  ...          NamSanGolHanOkVillage\n","gb        ([DecisionTreeRegressor(ccp_alpha=0.0, criteri...  ...          NationalMuseumOfKorea\n","\n","[14 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"DT_xa64-moUG"},"source":["# # 데이터를 dict형태로 쌓아서 각 관광지를 key 관광지의 계절을 value로 받게 만들었다.\n","# class data_bring:\n","#   def data_bring():\n","#     target_map = {'ChangDeokGung' : '창덕궁', 'ChangGyeongGung' : '창경궁', 'DuckSooGung' : '덕수궁', 'GyeongBokGung' : '경복궁', 'HeonLeungInReung' : '헌릉인릉', 'JongMyo' : '종묘', 'SeoDaeMunNaturalHistoryMuseum' : '서대문자연사박물관', 'SeoulMuseumOfArt' : '서울시립미술관', 'SunReungJungReung' : '선릉정릉', 'TaeReungGangNeung' : '태릉강릉', 'TrickEyeMuseum' : '트릭아이미술관', 'SeoDaeMunPrisonHistoryMuseum' : '서대문형무소역사관', 'NamSanGolHanOkVillage' : '남산골한옥마을', 'NationalMuseumOfKorea' : '국립중앙박물관'}\n","#     # season_map = ['','Spring','Summer','Fall','Winter']\n","#     PATH = '/content/drive/MyDrive/Proj_WT/DataSets/박정열/'\n","#     담아놓기 = {}\n","#     for i, j in target_map.items():\n","#       final_path = PATH + i + '.csv'\n","#       data = pd.read_csv(final_path)\n","#       담아놓기[f'{i}'] = data\n","\n","#     return 담아놓기\n","\n","# class modeling:\n","#   # train과 test로 나누기\n","#   # 전처리에서 했어야할 drop을 여기서 해주네... 뭐 그냥 그렇다구요\n","#   def train_test_split(data = None):\n","#     train = data[data['date'] <= 201712]\n","#     test = data[data['date'] > 201712]\n","\n","#     try:\n","#       train.drop(['date','최고 기온(°C)','평균 기온(°C)'], axis = 1, inplace = True)\n","#       test.drop(['date','최고 기온(°C)','평균 기온(°C)'], axis = 1, inplace = True)\n","#     except:\n","#       train.drop(['date','평균 기온(°C)'], axis = 1, inplace = True)\n","#       test.drop(['date','평균 기온(°C)'], axis = 1, inplace = True)\n","\n","#     X_train, y_train = train.drop('target', axis = 1), train['target']\n","#     X_test, y_test = test.drop('target', axis = 1), test['target']\n","\n","#     return X_train, X_test, y_train, y_test\n","\n","#   # linear regression 돌리기\n","#   def lr():\n","#     model = LinearRegression()\n","    \n","#     return model\n","\n","#   # xgboost 돌리기\n","#   def xgb():\n","#     model = XGBRegressor(random_state = 42,tree_method = 'gpu_hist')\n","\n","#     return model\n","\n","#   # lightgbm\n","#   def lgb():\n","#     model = LGBMRegressor(random_state = 42)\n","\n","#     return model\n","\n","#   # catboost\n","#   def cat():\n","#     model = CatBoostRegressor(random_state = 42,task_type = 'GPU')\n","\n","#     return model\n","\n","#   # ridge\n","#   def ridge():\n","#     model = Ridge(random_state = 42)\n","    \n","#     return model\n","  \n","#   # lasso\n","#   def lasso():\n","#     model = Lasso()\n","\n","#     return model\n","\n","#   # adaboost\n","#   def ada():\n","#     model = AdaBoostRegressor(random_state = 42)\n","\n","#     return model\n","\n","#   # randomforest\n","#   def rfg():\n","#     model = RandomForestRegressor(random_state = 42)\n","\n","#     return model\n","\n","#   # rmse가 가장 낮은 것을 데이터 프레임으로 rmse함수를 만든다.\n","#   def rmse(y_test, y_pred):\n","#     RMSE = mean_squared_error(y_test, y_pred)**0.5\n","\n","#     return RMSE\n","\n","# # 모델 전부 한번씩 돌려보기\n","# class class_all_model:\n","#   # 각 모델을 돌리기 위해서 dict로 쌓아준다.\n","#   def models():\n","#     models = {'lr':modeling.lr(), 'lgb':modeling.lgb(), 'xgb':modeling.xgb(), 'lasso':modeling.lasso(),'ridge':modeling.ridge(),'ada':modeling.ada(), 'rfg':modeling.rfg()}\n","#     return models\n","  \n","#   # 모델을 하나씩 돌려서 keys = 모델명, value = 모델의 rmse를 쌓아준다.\n","#   def run(data = None):\n","#     models = class_all_model.models()\n","#     final_models = {}\n","#     model_score = {}\n","#     model_binning = {}\n","#     X_train, X_test, y_train, y_test = modeling.train_test_split(data = data)\n","#     # dict로 쌓아놓은 데이터를 전부 가져온다.\n","#     for i, j in models.items():\n","#       model = j\n","#       model.fit(X_train, y_train)\n","#       y_pred = model.predict(X_test)\n","      \n","#       # 전체 모델을 돌려서 rmse가 가장 낮은 데이터를 찾아온다.\n","#       final_models[i] = modeling.rmse(y_test, y_pred)\n","#       model_score[i] = model.score(X_test, y_test)\n","#       model_binning[i] = model\n","\n","#     return final_models, model_score, model_binning\n","\n","# # stacking ensemble\n","# # class class_stack:\n","# #   # stacking에 사용할 모델들을 stacking에 바로 넣을 수 있게 만들어준다.\n","# #   def model_stack():\n","# #       models = [modeling.lgb(), modeling.cat(), modeling.lr(), modeling.xgb(), modeling.lasso(), modeling.ada(), modeling.rfg(),modeling.ridge()]\n","# #       return models\n","# #   # stacking모듈을 사용\n","# #   def stack(data = None):\n","# #     X_train, X_test, y_train, y_test = modeling.train_test_split(data = data)\n","\n","# #     S_train, S_test = stacking(class_stack.model_stack(), X_train, y_train, X_test, regression = True, metric = ['acc'], n_folds = 3)\n","# #     model = modeling.lgb()\n","# #     model.fit(S_train, y_train)\n","# #     y_pred = model.predict(S_test)\n","# #     model_score = model.score(S_test, y_test)\n","\n","#     # return modeling.rmse(y_test, y_pred), model_score, model\n","# # voting ensemble\n","# # class class_voting:\n","# #   # 모델들을 voting에 맞게 모아준다.\n","# #   def collect_model():\n","# #     models= [('xgb',modeling.xgb()),('lgb',modeling.lgb()),('rfg',modeling.rfg()),('ada',modeling.ada()),('lr',modeling.lr()),('ridge',modeling.ridge()),('lasso',modeling.lasso()),('cat',modeling.cat())]\n","    \n","# #     return models\n","\n","#   # VotingRegressor를 돌려준다.\n","#   # def voting(data = None):\n","#   #   X_train, X_test, y_train, y_test = modeling.train_test_split(data = data)\n","#   #   model = VotingRegressor(class_voting.collect_model(), )\n","#   #   model.fit(X_train, y_train)\n","#   #   y_pred = model.predict(X_test)\n","#   #   model_score = model.score(X_test, y_test)\n","#   #   return modeling.rmse(y_test, y_pred), model_score, model\n","\n","# # class로 짠 모델들을 전부 돌려준다.\n","# class final_model:\n","#   def run(data = None):\n","#     final_rmse , model_score, model = class_all_model.run(data = data)\n","#     # final_rmse['stack'], model_score['stack'], model['stack'] = class_stack.stack(data = data)\n","#     # final_rmse['voting'], model_score['voting'], model['voting'] = class_voting.voting(data = data)\n","\n","#     for i, j in model_score.items():\n","#       if j == max(model_score.values()):\n","#         model = model[i]\n","#         final_rmse = final_rmse[i]\n","#         model_score = model_score[i]\n","#         break\n","\n","#     score = pd.DataFrame([[model, final_rmse, model_score]], columns = ['model','final_rmse','model_score'], index = [i])\n","\n","#     return score\n","\n","# # 계절별로 데이터 프레임 만들기\n","# class data_concat:\n","#   def data_concat(data = [None]):\n","#     final_data = pd.DataFrame([], columns = ['model','final_rmse','model_score'])\n","#     a = final_model.run(data = data)\n","#     final_data = pd.concat([final_data, a], axis = 0)\n","\n","#     return final_data\n","\n","#   def final_run():\n","#     final_dict = data_bring.data_bring()\n","#     final_dataframe = pd.DataFrame([])\n","#     for i, j in final_dict.items():\n","#       dataframe = data_concat.data_concat(data = j)\n","#       dataframe['관광지'] = i\n","#       final_dataframe =  pd.concat([final_dataframe,dataframe], axis = 0)\n","#     return final_dataframe\n","\n","#   # def \n","#     print('------ 끝 --------------------------------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6CE-mJmhOvd"},"source":["# 학습된 모델 저장하기\n","# import pickle\n","# import joblib\n","\n","# final_Df = data_concat.final_run()\n","# for i in final_Df.index:\n","#   model = final_Df.loc[i, 'model']\n","#   save_model = pickle.dumps(model)\n","#   joblib,dump(save_model, f'/content/drive/MyDrive/Proj_WT/ModelScore/{i}의 모델.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4q2BuePjh6O"},"source":["# class를 이용해서 모든 모델을 돌려준다.\n","######## base line ############################\n","# final_rmse, model_score, model = final_model.run(data = data)\n","# print(final_rmse, model_score, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XeRKTxhfqZNu"},"source":["# 더미화, "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24GTZ8c0hLGu"},"source":["# class visualizer_class:"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5aeYqy1gwHw"},"source":["# import statsmodels.api as sm\n","\n","# train = data[data['date'] <= 201712]\n","# test = data[data['date'] > 201712]\n","\n","\n","\n","\n","# X_train, y_train = train.drop('target', axis = 1), train['target']\n","# X_test, y_test = test.drop('target', axis = 1), test['target']\n","\n","\n","# model = sm.OLS(y_train, X_train)\n","# result = model.fit()\n","# result.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mrStWiuHCuPE"},"source":["# y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aD8BlsEhNwbY"},"source":["# 데이터를 dict형태로 쌓아서 각 관광지를 key 관광지의 계절을 value로 받게 만들었다.\n","# import pandas as pd\n","# target_map = {'ChangDeokGung' : '창덕궁', 'ChangGyeongGung' : '창경궁', 'DuckSooGung' : '덕수궁', 'GyeongBokGung' : '경복궁', 'HeonLeungInReung' : '헌릉인릉', 'JongMyo' : '종묘', 'SeoDaeMunNaturalHistoryMuseum' : '서대문자연사박물관', 'SeoulMuseumOfArt' : '서울시립미술관', 'SunReungJungReung' : '선릉정릉', 'TaeReungGangNeung' : '태릉강릉', 'TrickEyeMuseum' : '트릭아이미술관', 'SeoDaeMunPrisonHistoryMuseum' : '서대문형무소역사관', 'NamSanGolHanOkVillage' : '남산골한옥마을', 'NationalMuseumOfKorea' : '국립중앙박물관'}\n","# season_map = ['','Spring','Summer','Fall','Winter']\n","\n","# PATH = '/content/drive/MyDrive/Proj_WT/DataSets/박정열/'\n","# 담아놓기 = {}\n","# for i, j in target_map.items():\n","#   데이터 = []\n","#   for k in season_map:\n","#     try:\n","#       final_path = PATH + i + '_' + k + '.csv'\n","#       data = pd.read_csv(final_path)\n","#       데이터.append(data)\n","#     except:\n","#       final_path = PATH + i + '.csv'\n","#       data = pd.read_csv(final_path)\n","#       데이터.append(data)\n","#   담아놓기[j] = 데이터"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWMgcD520ubC"},"source":["# final_data = data_bring.data_bring()\n","# len(final_data['창덕궁'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NYq-q5cO8pus"},"source":["# final_data.keys()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JPM54_5Un0hF"},"source":["# 딥러닝으로 비교해보기"]},{"cell_type":"code","metadata":{"id":"TjqudmVwfOGl","executionInfo":{"status":"ok","timestamp":1626972941078,"user_tz":-540,"elapsed":708,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":102,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVGfyNWVn7ry"},"source":["data = pd.read_csv('/content/drive/MyDrive/Proj_WT/DataSets/박정열/DuckSooGung.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"7IA5-Q9Sn8Yj","executionInfo":{"status":"ok","timestamp":1626953242848,"user_tz":-540,"elapsed":9,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"598cd8b7-e44a-461b-b69a-f34afaec5b05"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>month</th>\n","      <th>최고 기온(°C)</th>\n","      <th>최소 상대습도(%)</th>\n","      <th>평균 기온(°C)</th>\n","      <th>평균 상대습도(%)</th>\n","      <th>일강수량(mm)</th>\n","      <th>평균 풍속(m/s)</th>\n","      <th>합계 일조 시간(hr)</th>\n","      <th>0.5m 지중온도(°C)</th>\n","      <th>최대 풍속(m/s)</th>\n","      <th>합계 일사량(MJ/m2)</th>\n","      <th>target</th>\n","      <th>season</th>\n","      <th>tp_1_0</th>\n","      <th>tp_1_1</th>\n","      <th>tp_1_2</th>\n","      <th>tp_1_3</th>\n","      <th>tp_2_0</th>\n","      <th>tp_2_1</th>\n","      <th>tp_2_2</th>\n","      <th>tp_2_3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>201101</td>\n","      <td>1</td>\n","      <td>-3.406452</td>\n","      <td>35.129032</td>\n","      <td>-7.183871</td>\n","      <td>53.829032</td>\n","      <td>1.112500</td>\n","      <td>2.796774</td>\n","      <td>7.048387</td>\n","      <td>1.541935</td>\n","      <td>5.593548</td>\n","      <td>9.951290</td>\n","      <td>92135</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>201102</td>\n","      <td>2</td>\n","      <td>5.864286</td>\n","      <td>32.000000</td>\n","      <td>1.221429</td>\n","      <td>55.228571</td>\n","      <td>9.700000</td>\n","      <td>2.553571</td>\n","      <td>5.950000</td>\n","      <td>1.025000</td>\n","      <td>5.239286</td>\n","      <td>10.827857</td>\n","      <td>132920</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>201103</td>\n","      <td>3</td>\n","      <td>8.345161</td>\n","      <td>25.258065</td>\n","      <td>3.616129</td>\n","      <td>51.112903</td>\n","      <td>2.085714</td>\n","      <td>3.406452</td>\n","      <td>7.748387</td>\n","      <td>5.158065</td>\n","      <td>6.877419</td>\n","      <td>16.342258</td>\n","      <td>64869</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>201104</td>\n","      <td>4</td>\n","      <td>15.596667</td>\n","      <td>28.666667</td>\n","      <td>10.720000</td>\n","      <td>54.240000</td>\n","      <td>10.009091</td>\n","      <td>3.243333</td>\n","      <td>6.736667</td>\n","      <td>10.736667</td>\n","      <td>6.650000</td>\n","      <td>16.832333</td>\n","      <td>85548</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>201105</td>\n","      <td>5</td>\n","      <td>22.983871</td>\n","      <td>32.161290</td>\n","      <td>17.925806</td>\n","      <td>56.416129</td>\n","      <td>4.107692</td>\n","      <td>2.832258</td>\n","      <td>5.819355</td>\n","      <td>16.303226</td>\n","      <td>6.235484</td>\n","      <td>17.091935</td>\n","      <td>103100</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     date  month  최고 기온(°C)  최소 상대습도(%)  ...  tp_2_0  tp_2_1  tp_2_2  tp_2_3\n","0  201101      1  -3.406452   35.129032  ...       1       0       0       0\n","1  201102      2   5.864286   32.000000  ...       1       0       0       0\n","2  201103      3   8.345161   25.258065  ...       0       1       0       0\n","3  201104      4  15.596667   28.666667  ...       0       1       0       0\n","4  201105      5  22.983871   32.161290  ...       0       0       1       0\n","\n","[5 rows x 22 columns]"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"tVW7AAKaoMBp"},"source":["train = data[data['date'] <= 201712]\n","test = data[data['date'] > 201712]\n","train.drop(['date','최고 기온(°C)','평균 기온(°C)'], axis = 1, inplace = True)\n","test.drop(['date','최고 기온(°C)','평균 기온(°C)'], axis = 1, inplace = True)\n","X_train, y_train = train.drop('target', axis = 1), train['target']\n","X_test, y_test = test.drop('target', axis = 1), test['target']\n","\n","from sklearn.preprocessing import RobustScaler\n","# robust 스케일러를 사용하여 데이터를 처리 해준다.\n","transform = RobustScaler().fit(X_train)\n","X_train = transform.transform(X_train)\n","transform = RobustScaler().fit(X_test)\n","X_test = transform.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_SBCTKNpZzG","executionInfo":{"status":"ok","timestamp":1626974209154,"user_tz":-540,"elapsed":554,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten, BatchNormalization\n","import tensorflow as tf\n","\n","def rmse(true, pred):\n","  RMSE = mean_squared_error(true, pred)** 0.5\n","  return RMSE\n","\n","class data_bring:\n","  def data_bring():\n","    # 관광지를 dict형태로 저장한다.\n","    target_map = ['ChangDeokGung', 'ChangGyeongGung', 'DuckSooGung', 'GyeongBokGung', 'HeonLeungInReung', 'JongMyo',\n","                  'SeoDaeMunNaturalHistoryMuseum', 'SeoulMuseumOfArt', 'SunReungJungReung', 'TaeReungGangNeung', 'TrickEyeMuseum',\n","                  'SeoDaeMunPrisonHistoryMuseum', 'NamSanGolHanOkVillage', 'NationalMuseumOfKorea']\n","\n","    # colab path를 찾는다.\n","    PATH = '/content/drive/MyDrive/Proj_WT/DataSets/weathergodata/'\n","    # dict로 담아놓을 공간을 만든다.\n","    bucket = {}\n","    # items를 사용하여 각 key와 value를 받는다.\n","    for i in target_map:\n","      # 불러올 데이터의 path를 지정한다.\n","      final_path = PATH + i + '.csv'\n","      # 데이터를 불러온다.\n","      data = pd.read_csv(final_path)\n","      # 관광지에 데이터를 담는다.\n","      bucket[f'{i}'] = data\n","\n","    return bucket\n","\n","class deep_learning:\n","  def lstm(data = None):\n","    X_train, X_test, y_train, y_test = modeling.train_test_split(data = data)\n","\n","    # shape 맞춰주기\n","    X_train_t = X_train.values.reshape(X_train.shape[0], X_train.shape[1],1)\n","    X_test_t = X_test.values.reshape(X_test.shape[0], X_train.shape[1] ,1)\n","    y_train = y_train.values\n","    y_test = y_test.values\n","\n","    # LSTM 사용하기\n","    model = Sequential()\n","    model.add(LSTM(1024, activation = 'relu', input_shape = (X_train_t.shape[1], X_train_t.shape[2], ), return_sequences = True))\n","    model.add(LSTM(512, activation = 'relu', return_sequences = True))\n","    model.add(Dropout(0.1))\n","    model.add(LSTM(256, activation = 'relu', return_sequences = True))\n","    model.add(Dropout(0.2))\n","    model.add(LSTM(128, activation = 'relu', return_sequences = True))\n","    model.add(Dropout(0.3))\n","    BatchNormalization()\n","    model.add(Dense(1024, activation = 'relu'))\n","    model.add(Dense(512, activation = 'relu'))\n","    model.add(Dense(256, activation = 'relu'))\n","    model.add(Dense(128, activation = 'relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(64, activation = 'relu'))\n","    model.add(Dense(16, activation = 'relu'))\n","\n","    model.add(Flatten())\n","    model.add(Dense(1))\n","\n","    model.compile(loss = 'mae', optimizer = 'adam', metrics = ['mean_squared_error'])\n","    print('------------------------- LSTM ---------------------------------------------')\n","    print(model.summary())\n","\n","    model.fit(X_train_t, y_train, epochs = 50, batch_size = 1, validation_data = (X_test_t, y_test))\n","    y_pred = model.predict(X_test_t)\n","\n","    final_y_pred = []\n","    for i in y_pred:\n","      for j in i:\n","        final_y_pred.append(j)\n","\n","    model_rmse = modeling.rmse(y_test, final_y_pred)\n","    model_smape = modeling.smape(y_test, final_y_pred)\n","    \n","    return model_rmse, model_smape\n","\n","  def CNN(data = None):\n","    # train과 test로 나눠주기\n","    X_train, X_test, y_train, y_test = modeling.train_test_split(data = data)\n","\n","    # 데이터 shape 확인해 주기\n","    model = Sequential()\n","    model.add(Dense(1024, activation = 'relu', input_shape = (X_train.shape[1],)))\n","    model.add(Dense(512, activation = 'relu'))\n","    model.add(Dense(256, activation = 'relu'))\n","    BatchNormalization()\n","    model.add(Dense(128, activation = 'relu'))\n","    model.add(Dense(64, activation = 'relu'))\n","    model.add(Dense(32, activation = 'relu'))\n","    model.add(Dense(16, activation = 'relu'))\n","    model.add(Flatten())\n","    model.add(Dense(1))\n","\n","    model.compile(loss = 'mae', optimizer = 'adam', metrics = ['mean_squared_error'])\n","    print('------------------------- LSTM ---------------------------------------------')\n","    print(model.summary())\n","\n","    model.fit(X_train, y_train, epochs = 50, batch_size = 1, validation_data = (X_test, y_test))\n","    y_pred = model.predict(X_test)\n","    final_y_pred = []\n","    for i in y_pred:\n","      for j in i:\n","        final_y_pred.append(j)\n","\n","    model_rmse = modeling.rmse(y_test, final_y_pred)\n","    model_smape = modeling.smape(y_test, final_y_pred)\n","\n","    return model_rmse, model_smape\n","\n","  def final_run():\n","    final_data = data_bring.data_bring()\n","    \n","    for i, j in final_data.items():\n","      final_dataframe = pd.DataFrame([], columns = ['rmse','smape'], index = final_data.keys())\n","\n","      # 위의 함수들을 전부 불러온다.\n","      cnn_rmse, cnn_smape = deep_learning.CNN(data = j)\n","      lstm_rmse, lstm_smape = deep_learning.lstm(data = j)\n","\n","      # 저장할 공간을 만들어서 데이터 프레임으로 만들어 주자.\n","      model_rmse = {}\n","      model_smape = {}\n","\n","      model_rmse['cnn'] = cnn_rmse\n","      model_rmse['lstm'] = lstm_rmse\n","      model_smape['cnn'] = cnn_smape\n","      model_smape['lstm'] = lstm_smape\n","\n","      final_dataframe = pd.DataFrame([], columns = ['rmse','smape'], index = final_data.keys())\n","\n","      print(final_dataframe)\n","      for i, j in model_rmse.items():\n","        for k in final_dataframe.index:\n","          if k == i:\n","            final_dataframe.loc[i, 'rmse'] = j\n","\n","      for i, j in model_smape.items():\n","        for k in final_dataframe.index:\n","          if k == i:\n","            final_dataframe.loc[i, 'smape'] = j\n","    return final_dataframe      "],"execution_count":139,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"gnm5U39KxHm7","executionInfo":{"status":"error","timestamp":1626975399309,"user_tz":-540,"elapsed":1190159,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"1722542a-6f54-4574-8c46-9a4164e508a2"},"source":["deep_learning.final_run()"],"execution_count":140,"outputs":[{"output_type":"stream","text":["------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_77 (Dense)             (None, 1024)              5120      \n","_________________________________________________________________\n","dense_78 (Dense)             (None, 512)               524800    \n","_________________________________________________________________\n","dense_79 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dense_80 (Dense)             (None, 128)               32896     \n","_________________________________________________________________\n","dense_81 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dense_82 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_83 (Dense)             (None, 16)                528       \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_84 (Dense)             (None, 1)                 17        \n","=================================================================\n","Total params: 705,025\n","Trainable params: 705,025\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 1s 4ms/step - loss: 64702.1836 - mean_squared_error: 6346260480.0000 - val_loss: 46748.6523 - val_mean_squared_error: 3922610944.0000\n","Epoch 2/50\n","96/96 [==============================] - 0s 2ms/step - loss: 45361.7383 - mean_squared_error: 3792162048.0000 - val_loss: 41628.7656 - val_mean_squared_error: 2841820416.0000\n","Epoch 3/50\n","96/96 [==============================] - 0s 2ms/step - loss: 46060.1250 - mean_squared_error: 3632263424.0000 - val_loss: 41800.0586 - val_mean_squared_error: 3101246208.0000\n","Epoch 4/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47315.9805 - mean_squared_error: 4139423744.0000 - val_loss: 64579.9883 - val_mean_squared_error: 6626385920.0000\n","Epoch 5/50\n","96/96 [==============================] - 0s 2ms/step - loss: 46352.9570 - mean_squared_error: 4127723520.0000 - val_loss: 41262.1680 - val_mean_squared_error: 3003721472.0000\n","Epoch 6/50\n","96/96 [==============================] - 0s 2ms/step - loss: 45109.5156 - mean_squared_error: 3731459328.0000 - val_loss: 41703.8906 - val_mean_squared_error: 2609876992.0000\n","Epoch 7/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43566.2383 - mean_squared_error: 3384609024.0000 - val_loss: 43770.5312 - val_mean_squared_error: 2354264576.0000\n","Epoch 8/50\n","96/96 [==============================] - 0s 3ms/step - loss: 44321.9375 - mean_squared_error: 3541594112.0000 - val_loss: 43176.6641 - val_mean_squared_error: 3412208640.0000\n","Epoch 9/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45464.8945 - mean_squared_error: 3755340544.0000 - val_loss: 42290.4023 - val_mean_squared_error: 2380816128.0000\n","Epoch 10/50\n","96/96 [==============================] - 0s 3ms/step - loss: 44676.6758 - mean_squared_error: 3607241472.0000 - val_loss: 47912.4492 - val_mean_squared_error: 2935683328.0000\n","Epoch 11/50\n","96/96 [==============================] - 0s 2ms/step - loss: 45170.2969 - mean_squared_error: 3417787648.0000 - val_loss: 45599.7969 - val_mean_squared_error: 3919613184.0000\n","Epoch 12/50\n","96/96 [==============================] - 0s 2ms/step - loss: 46071.1562 - mean_squared_error: 3898130176.0000 - val_loss: 50622.7305 - val_mean_squared_error: 4577971712.0000\n","Epoch 13/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46110.3555 - mean_squared_error: 3783917312.0000 - val_loss: 41387.7070 - val_mean_squared_error: 3112136448.0000\n","Epoch 14/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46056.0898 - mean_squared_error: 3608857344.0000 - val_loss: 40859.0078 - val_mean_squared_error: 2376645632.0000\n","Epoch 15/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43631.7148 - mean_squared_error: 3465706496.0000 - val_loss: 41180.7461 - val_mean_squared_error: 2291190528.0000\n","Epoch 16/50\n","96/96 [==============================] - 0s 2ms/step - loss: 43051.6133 - mean_squared_error: 3345781504.0000 - val_loss: 50460.0742 - val_mean_squared_error: 3188395264.0000\n","Epoch 17/50\n","96/96 [==============================] - 0s 2ms/step - loss: 43946.1055 - mean_squared_error: 3361236224.0000 - val_loss: 44910.1289 - val_mean_squared_error: 3772825344.0000\n","Epoch 18/50\n","96/96 [==============================] - 0s 3ms/step - loss: 42738.5430 - mean_squared_error: 3671339776.0000 - val_loss: 41219.3398 - val_mean_squared_error: 3047630080.0000\n","Epoch 19/50\n","96/96 [==============================] - 0s 3ms/step - loss: 44618.8281 - mean_squared_error: 3562944768.0000 - val_loss: 40888.7109 - val_mean_squared_error: 2946219008.0000\n","Epoch 20/50\n","96/96 [==============================] - 0s 3ms/step - loss: 42142.4961 - mean_squared_error: 3499280640.0000 - val_loss: 41016.3867 - val_mean_squared_error: 2973019904.0000\n","Epoch 21/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43279.1211 - mean_squared_error: 3345951744.0000 - val_loss: 39854.7148 - val_mean_squared_error: 2265982464.0000\n","Epoch 22/50\n","96/96 [==============================] - 0s 2ms/step - loss: 43472.6836 - mean_squared_error: 3387449344.0000 - val_loss: 40298.4961 - val_mean_squared_error: 2782293760.0000\n","Epoch 23/50\n","96/96 [==============================] - 0s 2ms/step - loss: 42723.9336 - mean_squared_error: 3716640512.0000 - val_loss: 39858.7695 - val_mean_squared_error: 2453241344.0000\n","Epoch 24/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43615.4102 - mean_squared_error: 3715939584.0000 - val_loss: 39808.6875 - val_mean_squared_error: 2536204032.0000\n","Epoch 25/50\n","96/96 [==============================] - 0s 2ms/step - loss: 41377.8867 - mean_squared_error: 3467253504.0000 - val_loss: 39858.9258 - val_mean_squared_error: 2557581568.0000\n","Epoch 26/50\n","96/96 [==============================] - 0s 2ms/step - loss: 43382.6992 - mean_squared_error: 3573918720.0000 - val_loss: 39632.7812 - val_mean_squared_error: 2333256704.0000\n","Epoch 27/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43558.9922 - mean_squared_error: 3640829184.0000 - val_loss: 43960.8086 - val_mean_squared_error: 2530129920.0000\n","Epoch 28/50\n","96/96 [==============================] - 0s 3ms/step - loss: 42132.8789 - mean_squared_error: 3184562944.0000 - val_loss: 43083.7266 - val_mean_squared_error: 2485368064.0000\n","Epoch 29/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43566.1367 - mean_squared_error: 3501819904.0000 - val_loss: 39475.5312 - val_mean_squared_error: 2372777728.0000\n","Epoch 30/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43439.1055 - mean_squared_error: 3338055936.0000 - val_loss: 50501.2695 - val_mean_squared_error: 4542013952.0000\n","Epoch 31/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47578.2227 - mean_squared_error: 4078771200.0000 - val_loss: 40076.2500 - val_mean_squared_error: 2312798976.0000\n","Epoch 32/50\n","96/96 [==============================] - 0s 3ms/step - loss: 44051.2539 - mean_squared_error: 3728391424.0000 - val_loss: 39707.0117 - val_mean_squared_error: 2569144320.0000\n","Epoch 33/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45376.5508 - mean_squared_error: 3997157632.0000 - val_loss: 47170.7617 - val_mean_squared_error: 2904460032.0000\n","Epoch 34/50\n","96/96 [==============================] - 0s 3ms/step - loss: 42427.4531 - mean_squared_error: 3408875776.0000 - val_loss: 39481.4570 - val_mean_squared_error: 2326650624.0000\n","Epoch 35/50\n","96/96 [==============================] - 0s 2ms/step - loss: 43146.3359 - mean_squared_error: 3584790528.0000 - val_loss: 41737.5977 - val_mean_squared_error: 3012431104.0000\n","Epoch 36/50\n","96/96 [==============================] - 0s 3ms/step - loss: 42687.1172 - mean_squared_error: 3421025024.0000 - val_loss: 39256.8789 - val_mean_squared_error: 2254029568.0000\n","Epoch 37/50\n","96/96 [==============================] - 0s 2ms/step - loss: 39925.0547 - mean_squared_error: 3272413952.0000 - val_loss: 39501.0859 - val_mean_squared_error: 2303488256.0000\n","Epoch 38/50\n","96/96 [==============================] - 0s 2ms/step - loss: 41437.8398 - mean_squared_error: 3313332480.0000 - val_loss: 44915.2500 - val_mean_squared_error: 2736764160.0000\n","Epoch 39/50\n","96/96 [==============================] - 0s 2ms/step - loss: 43352.4102 - mean_squared_error: 3544083712.0000 - val_loss: 39415.0859 - val_mean_squared_error: 2234610432.0000\n","Epoch 40/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43395.0117 - mean_squared_error: 3414979584.0000 - val_loss: 39288.6602 - val_mean_squared_error: 2247382528.0000\n","Epoch 41/50\n","96/96 [==============================] - 0s 3ms/step - loss: 41767.6055 - mean_squared_error: 3415748608.0000 - val_loss: 41913.5586 - val_mean_squared_error: 3128037120.0000\n","Epoch 42/50\n","96/96 [==============================] - 0s 2ms/step - loss: 42568.4414 - mean_squared_error: 3698725120.0000 - val_loss: 39846.4219 - val_mean_squared_error: 2701364736.0000\n","Epoch 43/50\n","96/96 [==============================] - 0s 3ms/step - loss: 42612.7891 - mean_squared_error: 3582232320.0000 - val_loss: 39107.8242 - val_mean_squared_error: 2236067584.0000\n","Epoch 44/50\n","96/96 [==============================] - 0s 2ms/step - loss: 40703.4805 - mean_squared_error: 3339371264.0000 - val_loss: 39170.7891 - val_mean_squared_error: 2227313920.0000\n","Epoch 45/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43274.8945 - mean_squared_error: 3472293120.0000 - val_loss: 39933.2148 - val_mean_squared_error: 2686428416.0000\n","Epoch 46/50\n","96/96 [==============================] - 0s 2ms/step - loss: 41517.4141 - mean_squared_error: 3103675136.0000 - val_loss: 40600.9727 - val_mean_squared_error: 2351972608.0000\n","Epoch 47/50\n","96/96 [==============================] - 0s 2ms/step - loss: 39325.9492 - mean_squared_error: 3102111488.0000 - val_loss: 44223.9102 - val_mean_squared_error: 2696404736.0000\n","Epoch 48/50\n","96/96 [==============================] - 0s 2ms/step - loss: 42744.2070 - mean_squared_error: 3435276544.0000 - val_loss: 39001.2461 - val_mean_squared_error: 2235122944.0000\n","Epoch 49/50\n","96/96 [==============================] - 0s 3ms/step - loss: 40714.5273 - mean_squared_error: 3158757632.0000 - val_loss: 38764.0352 - val_mean_squared_error: 2233564672.0000\n","Epoch 50/50\n","96/96 [==============================] - 0s 2ms/step - loss: 40475.9570 - mean_squared_error: 2897918720.0000 - val_loss: 40954.1992 - val_mean_squared_error: 2848904960.0000\n","WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_11\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_12 (LSTM)               (None, 4, 1024)           4202496   \n","_________________________________________________________________\n","lstm_13 (LSTM)               (None, 4, 512)            3147776   \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 4, 512)            0         \n","_________________________________________________________________\n","lstm_14 (LSTM)               (None, 4, 256)            787456    \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 4, 256)            0         \n","_________________________________________________________________\n","lstm_15 (LSTM)               (None, 4, 128)            197120    \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 4, 128)            0         \n","_________________________________________________________________\n","dense_85 (Dense)             (None, 4, 1024)           132096    \n","_________________________________________________________________\n","dense_86 (Dense)             (None, 4, 512)            524800    \n","_________________________________________________________________\n","dense_87 (Dense)             (None, 4, 256)            131328    \n","_________________________________________________________________\n","dense_88 (Dense)             (None, 4, 128)            32896     \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 4, 128)            0         \n","_________________________________________________________________\n","dense_89 (Dense)             (None, 4, 64)             8256      \n","_________________________________________________________________\n","dense_90 (Dense)             (None, 4, 16)             1040      \n","_________________________________________________________________\n","flatten_11 (Flatten)         (None, 64)                0         \n","_________________________________________________________________\n","dense_91 (Dense)             (None, 1)                 65        \n","=================================================================\n","Total params: 9,165,329\n","Trainable params: 9,165,329\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 5s 23ms/step - loss: 60821.5938 - mean_squared_error: 6637559808.0000 - val_loss: 45426.9531 - val_mean_squared_error: 3783163136.0000\n","Epoch 2/50\n","96/96 [==============================] - 2s 17ms/step - loss: 50317.3945 - mean_squared_error: 4831030784.0000 - val_loss: 42084.8594 - val_mean_squared_error: 3300571904.0000\n","Epoch 3/50\n","96/96 [==============================] - 2s 16ms/step - loss: 52377.6602 - mean_squared_error: 4632182784.0000 - val_loss: 72402.2734 - val_mean_squared_error: 7595233280.0000\n","Epoch 4/50\n","96/96 [==============================] - 2s 16ms/step - loss: 50112.2539 - mean_squared_error: 4814728192.0000 - val_loss: 41786.9492 - val_mean_squared_error: 3279043584.0000\n","Epoch 5/50\n","96/96 [==============================] - 2s 16ms/step - loss: 45760.8945 - mean_squared_error: 4602513920.0000 - val_loss: 41881.9688 - val_mean_squared_error: 2355744000.0000\n","Epoch 6/50\n","96/96 [==============================] - 2s 16ms/step - loss: 47257.6602 - mean_squared_error: 3791564800.0000 - val_loss: 50942.1758 - val_mean_squared_error: 4533932544.0000\n","Epoch 7/50\n","96/96 [==============================] - 2s 16ms/step - loss: 41825.7891 - mean_squared_error: 3316156672.0000 - val_loss: 48018.6914 - val_mean_squared_error: 4012908544.0000\n","Epoch 8/50\n","96/96 [==============================] - 2s 16ms/step - loss: 46049.3633 - mean_squared_error: 3967080192.0000 - val_loss: 48820.6445 - val_mean_squared_error: 3572794368.0000\n","Epoch 9/50\n","96/96 [==============================] - 2s 16ms/step - loss: 50514.7969 - mean_squared_error: 5116784128.0000 - val_loss: 39483.3398 - val_mean_squared_error: 2106382976.0000\n","Epoch 10/50\n","96/96 [==============================] - 2s 16ms/step - loss: 48659.1289 - mean_squared_error: 4413039104.0000 - val_loss: 40712.9023 - val_mean_squared_error: 2478753280.0000\n","Epoch 11/50\n","96/96 [==============================] - 2s 16ms/step - loss: 46925.1367 - mean_squared_error: 4126335744.0000 - val_loss: 38201.0352 - val_mean_squared_error: 2122274304.0000\n","Epoch 12/50\n","96/96 [==============================] - 2s 16ms/step - loss: 48068.7148 - mean_squared_error: 4394725888.0000 - val_loss: 45123.9883 - val_mean_squared_error: 3373034752.0000\n","Epoch 13/50\n","96/96 [==============================] - 2s 16ms/step - loss: 43080.9141 - mean_squared_error: 3623803904.0000 - val_loss: 42018.5586 - val_mean_squared_error: 2778629888.0000\n","Epoch 14/50\n","96/96 [==============================] - 2s 17ms/step - loss: 48611.6523 - mean_squared_error: 4502437376.0000 - val_loss: 48630.3008 - val_mean_squared_error: 4013630720.0000\n","Epoch 15/50\n","96/96 [==============================] - 2s 16ms/step - loss: 42833.8477 - mean_squared_error: 3549805312.0000 - val_loss: 60920.1562 - val_mean_squared_error: 5610811904.0000\n","Epoch 16/50\n","96/96 [==============================] - 2s 16ms/step - loss: 43250.3555 - mean_squared_error: 3453276416.0000 - val_loss: 46875.9375 - val_mean_squared_error: 3716450560.0000\n","Epoch 17/50\n","96/96 [==============================] - 2s 16ms/step - loss: 44250.2852 - mean_squared_error: 3614537728.0000 - val_loss: 35605.2031 - val_mean_squared_error: 1785666048.0000\n","Epoch 18/50\n","96/96 [==============================] - 2s 16ms/step - loss: 41340.5977 - mean_squared_error: 3289684224.0000 - val_loss: 38616.2617 - val_mean_squared_error: 2139856256.0000\n","Epoch 19/50\n","96/96 [==============================] - 2s 16ms/step - loss: 47161.3906 - mean_squared_error: 4015604736.0000 - val_loss: 41132.8477 - val_mean_squared_error: 3019086080.0000\n","Epoch 20/50\n","96/96 [==============================] - 2s 16ms/step - loss: 41498.0664 - mean_squared_error: 3606093824.0000 - val_loss: 32579.2402 - val_mean_squared_error: 1564929024.0000\n","Epoch 21/50\n","96/96 [==============================] - 2s 16ms/step - loss: 47726.4062 - mean_squared_error: 4017467648.0000 - val_loss: 47823.5469 - val_mean_squared_error: 3841122560.0000\n","Epoch 22/50\n","96/96 [==============================] - 2s 16ms/step - loss: 39944.8086 - mean_squared_error: 3538870272.0000 - val_loss: 28493.7441 - val_mean_squared_error: 1308941696.0000\n","Epoch 23/50\n","96/96 [==============================] - 2s 16ms/step - loss: 33688.0195 - mean_squared_error: 2512499456.0000 - val_loss: 29004.1250 - val_mean_squared_error: 1622101632.0000\n","Epoch 24/50\n","96/96 [==============================] - 2s 16ms/step - loss: 37656.5742 - mean_squared_error: 2961340672.0000 - val_loss: 28569.9453 - val_mean_squared_error: 1160037248.0000\n","Epoch 25/50\n","96/96 [==============================] - 2s 16ms/step - loss: 39036.5352 - mean_squared_error: 3005998080.0000 - val_loss: 26506.0625 - val_mean_squared_error: 1006667776.0000\n","Epoch 26/50\n","96/96 [==============================] - 2s 16ms/step - loss: 30795.2109 - mean_squared_error: 1836430464.0000 - val_loss: 31922.1934 - val_mean_squared_error: 1528351232.0000\n","Epoch 27/50\n","96/96 [==============================] - 2s 16ms/step - loss: 38235.9727 - mean_squared_error: 2663610624.0000 - val_loss: 38744.6445 - val_mean_squared_error: 2678303744.0000\n","Epoch 28/50\n","96/96 [==============================] - 2s 17ms/step - loss: 32674.3828 - mean_squared_error: 2242784768.0000 - val_loss: 31163.3594 - val_mean_squared_error: 1426745472.0000\n","Epoch 29/50\n","96/96 [==============================] - 2s 18ms/step - loss: 34633.3008 - mean_squared_error: 2594522880.0000 - val_loss: 51367.4414 - val_mean_squared_error: 4150311680.0000\n","Epoch 30/50\n","96/96 [==============================] - 2s 17ms/step - loss: 35357.1914 - mean_squared_error: 2544382720.0000 - val_loss: 27132.7051 - val_mean_squared_error: 1387861376.0000\n","Epoch 31/50\n","96/96 [==============================] - 2s 17ms/step - loss: 31650.6934 - mean_squared_error: 2143277440.0000 - val_loss: 30300.2402 - val_mean_squared_error: 1279303424.0000\n","Epoch 32/50\n","96/96 [==============================] - 2s 17ms/step - loss: 31398.5703 - mean_squared_error: 1970367360.0000 - val_loss: 24080.3066 - val_mean_squared_error: 959334464.0000\n","Epoch 33/50\n","96/96 [==============================] - 2s 17ms/step - loss: 30807.6660 - mean_squared_error: 2053956224.0000 - val_loss: 25498.2207 - val_mean_squared_error: 1170310528.0000\n","Epoch 34/50\n","96/96 [==============================] - 2s 18ms/step - loss: 32540.7812 - mean_squared_error: 2247664384.0000 - val_loss: 42433.4609 - val_mean_squared_error: 2933166848.0000\n","Epoch 35/50\n","96/96 [==============================] - 2s 17ms/step - loss: 32541.1328 - mean_squared_error: 2200478976.0000 - val_loss: 23049.1035 - val_mean_squared_error: 1129154944.0000\n","Epoch 36/50\n","96/96 [==============================] - 2s 17ms/step - loss: 30090.4609 - mean_squared_error: 1887285632.0000 - val_loss: 28566.4844 - val_mean_squared_error: 1685411456.0000\n","Epoch 37/50\n","96/96 [==============================] - 2s 17ms/step - loss: 35438.7695 - mean_squared_error: 5283129344.0000 - val_loss: 43226.7773 - val_mean_squared_error: 3014450944.0000\n","Epoch 38/50\n","96/96 [==============================] - 2s 17ms/step - loss: 38818.8828 - mean_squared_error: 2985068544.0000 - val_loss: 25048.5215 - val_mean_squared_error: 968852160.0000\n","Epoch 39/50\n","96/96 [==============================] - 2s 17ms/step - loss: 31752.5527 - mean_squared_error: 2208450816.0000 - val_loss: 37837.1758 - val_mean_squared_error: 2285307648.0000\n","Epoch 40/50\n","96/96 [==============================] - 2s 18ms/step - loss: 31706.6348 - mean_squared_error: 2159037184.0000 - val_loss: 44462.5742 - val_mean_squared_error: 3191493376.0000\n","Epoch 41/50\n","96/96 [==============================] - 2s 17ms/step - loss: 33086.6758 - mean_squared_error: 2509964032.0000 - val_loss: 30816.8105 - val_mean_squared_error: 1657880064.0000\n","Epoch 42/50\n","96/96 [==============================] - 2s 18ms/step - loss: 29326.3203 - mean_squared_error: 1906924416.0000 - val_loss: 30991.4238 - val_mean_squared_error: 1974618496.0000\n","Epoch 43/50\n","96/96 [==============================] - 2s 16ms/step - loss: 30011.3926 - mean_squared_error: 2118773376.0000 - val_loss: 30870.0527 - val_mean_squared_error: 1137888384.0000\n","Epoch 44/50\n","96/96 [==============================] - 2s 16ms/step - loss: 33349.8320 - mean_squared_error: 2248864000.0000 - val_loss: 31113.8457 - val_mean_squared_error: 1629282176.0000\n","Epoch 45/50\n","96/96 [==============================] - 2s 16ms/step - loss: 24178.5059 - mean_squared_error: 1171262848.0000 - val_loss: 22984.0801 - val_mean_squared_error: 906958080.0000\n","Epoch 46/50\n","96/96 [==============================] - 2s 16ms/step - loss: 30580.2090 - mean_squared_error: 1979539456.0000 - val_loss: 23491.9434 - val_mean_squared_error: 1028818624.0000\n","Epoch 47/50\n","96/96 [==============================] - 2s 16ms/step - loss: 31491.2441 - mean_squared_error: 2057894912.0000 - val_loss: 47031.6523 - val_mean_squared_error: 3551224576.0000\n","Epoch 48/50\n","96/96 [==============================] - 2s 18ms/step - loss: 31762.5879 - mean_squared_error: 2285378560.0000 - val_loss: 29822.4004 - val_mean_squared_error: 1238520448.0000\n","Epoch 49/50\n","96/96 [==============================] - 2s 17ms/step - loss: 32503.2910 - mean_squared_error: 2084764160.0000 - val_loss: 44915.5625 - val_mean_squared_error: 2578531584.0000\n","Epoch 50/50\n","96/96 [==============================] - 2s 17ms/step - loss: 30608.2090 - mean_squared_error: 1901056896.0000 - val_loss: 34121.8633 - val_mean_squared_error: 2075128960.0000\n","                              rmse smape\n","ChangDeokGung                  NaN   NaN\n","ChangGyeongGung                NaN   NaN\n","DuckSooGung                    NaN   NaN\n","GyeongBokGung                  NaN   NaN\n","HeonLeungInReung               NaN   NaN\n","JongMyo                        NaN   NaN\n","SeoDaeMunNaturalHistoryMuseum  NaN   NaN\n","SeoulMuseumOfArt               NaN   NaN\n","SunReungJungReung              NaN   NaN\n","TaeReungGangNeung              NaN   NaN\n","TrickEyeMuseum                 NaN   NaN\n","SeoDaeMunPrisonHistoryMuseum   NaN   NaN\n","NamSanGolHanOkVillage          NaN   NaN\n","NationalMuseumOfKorea          NaN   NaN\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_12\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_92 (Dense)             (None, 1024)              19456     \n","_________________________________________________________________\n","dense_93 (Dense)             (None, 512)               524800    \n","_________________________________________________________________\n","dense_94 (Dense)             (None, 256)               131328    \n","_________________________________________________________________\n","dense_95 (Dense)             (None, 128)               32896     \n","_________________________________________________________________\n","dense_96 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dense_97 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_98 (Dense)             (None, 16)                528       \n","_________________________________________________________________\n","flatten_12 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_99 (Dense)             (None, 1)                 17        \n","=================================================================\n","Total params: 719,361\n","Trainable params: 719,361\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 1s 5ms/step - loss: 153866.9375 - mean_squared_error: 75943305216.0000 - val_loss: 25287.2598 - val_mean_squared_error: 904331456.0000\n","Epoch 2/50\n","96/96 [==============================] - 0s 3ms/step - loss: 51928.8555 - mean_squared_error: 6420826112.0000 - val_loss: 92690.0391 - val_mean_squared_error: 9269885952.0000\n","Epoch 3/50\n","96/96 [==============================] - 0s 3ms/step - loss: 35539.4102 - mean_squared_error: 2144318080.0000 - val_loss: 23724.0000 - val_mean_squared_error: 710356800.0000\n","Epoch 4/50\n","96/96 [==============================] - 0s 3ms/step - loss: 38171.6367 - mean_squared_error: 2935028736.0000 - val_loss: 60886.4180 - val_mean_squared_error: 4385594368.0000\n","Epoch 5/50\n","96/96 [==============================] - 0s 3ms/step - loss: 33190.4727 - mean_squared_error: 1974517120.0000 - val_loss: 24113.6504 - val_mean_squared_error: 742241728.0000\n","Epoch 6/50\n","96/96 [==============================] - 0s 3ms/step - loss: 43077.1289 - mean_squared_error: 4901657088.0000 - val_loss: 24682.9746 - val_mean_squared_error: 808485888.0000\n","Epoch 7/50\n","96/96 [==============================] - 0s 2ms/step - loss: 36998.5195 - mean_squared_error: 2619114240.0000 - val_loss: 23432.1328 - val_mean_squared_error: 681331200.0000\n","Epoch 8/50\n","96/96 [==============================] - 0s 3ms/step - loss: 33474.5195 - mean_squared_error: 1940795904.0000 - val_loss: 24700.9980 - val_mean_squared_error: 861287744.0000\n","Epoch 9/50\n","96/96 [==============================] - 0s 3ms/step - loss: 30226.0957 - mean_squared_error: 1667202176.0000 - val_loss: 43102.0742 - val_mean_squared_error: 2536224512.0000\n","Epoch 10/50\n","96/96 [==============================] - 0s 3ms/step - loss: 31178.9844 - mean_squared_error: 1606548352.0000 - val_loss: 23777.0703 - val_mean_squared_error: 714056128.0000\n","Epoch 11/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28007.0547 - mean_squared_error: 1382095744.0000 - val_loss: 27613.7344 - val_mean_squared_error: 1052772160.0000\n","Epoch 12/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29463.8887 - mean_squared_error: 1494284288.0000 - val_loss: 24097.3203 - val_mean_squared_error: 740686528.0000\n","Epoch 13/50\n","96/96 [==============================] - 0s 3ms/step - loss: 31837.1484 - mean_squared_error: 1722584064.0000 - val_loss: 23432.0000 - val_mean_squared_error: 679567296.0000\n","Epoch 14/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29279.8066 - mean_squared_error: 1476695168.0000 - val_loss: 25275.5254 - val_mean_squared_error: 893682176.0000\n","Epoch 15/50\n","96/96 [==============================] - 0s 3ms/step - loss: 31795.6582 - mean_squared_error: 1681802752.0000 - val_loss: 31667.4043 - val_mean_squared_error: 1432221824.0000\n","Epoch 16/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28510.1777 - mean_squared_error: 1440125312.0000 - val_loss: 23980.2812 - val_mean_squared_error: 730097472.0000\n","Epoch 17/50\n","96/96 [==============================] - 0s 3ms/step - loss: 30612.7949 - mean_squared_error: 1594429952.0000 - val_loss: 23663.3828 - val_mean_squared_error: 794162944.0000\n","Epoch 18/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28308.8887 - mean_squared_error: 1436012032.0000 - val_loss: 36360.9336 - val_mean_squared_error: 1944992384.0000\n","Epoch 19/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29501.6348 - mean_squared_error: 1532187520.0000 - val_loss: 23431.9297 - val_mean_squared_error: 690445248.0000\n","Epoch 20/50\n","96/96 [==============================] - 0s 3ms/step - loss: 32098.4512 - mean_squared_error: 1852705152.0000 - val_loss: 29917.8379 - val_mean_squared_error: 1252326016.0000\n","Epoch 21/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28971.8223 - mean_squared_error: 1490980224.0000 - val_loss: 23431.9277 - val_mean_squared_error: 737661184.0000\n","Epoch 22/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29271.9863 - mean_squared_error: 1481371776.0000 - val_loss: 24350.3047 - val_mean_squared_error: 842746560.0000\n","Epoch 23/50\n","96/96 [==============================] - 0s 3ms/step - loss: 27645.9277 - mean_squared_error: 1347508992.0000 - val_loss: 28083.8691 - val_mean_squared_error: 1090038912.0000\n","Epoch 24/50\n","96/96 [==============================] - 0s 3ms/step - loss: 27846.1309 - mean_squared_error: 1435047936.0000 - val_loss: 29413.2285 - val_mean_squared_error: 1204989056.0000\n","Epoch 25/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29731.1934 - mean_squared_error: 1586630272.0000 - val_loss: 23431.8340 - val_mean_squared_error: 739858688.0000\n","Epoch 26/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28059.3301 - mean_squared_error: 1449706496.0000 - val_loss: 23677.7207 - val_mean_squared_error: 795085312.0000\n","Epoch 27/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29118.1074 - mean_squared_error: 1474901504.0000 - val_loss: 23431.7793 - val_mean_squared_error: 710848960.0000\n","Epoch 28/50\n","96/96 [==============================] - 0s 3ms/step - loss: 30270.3730 - mean_squared_error: 1713860736.0000 - val_loss: 27899.9551 - val_mean_squared_error: 1075246720.0000\n","Epoch 29/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28226.1855 - mean_squared_error: 1400306176.0000 - val_loss: 33367.6758 - val_mean_squared_error: 1630505088.0000\n","Epoch 30/50\n","96/96 [==============================] - 0s 3ms/step - loss: 31493.6484 - mean_squared_error: 1670637696.0000 - val_loss: 30507.7715 - val_mean_squared_error: 1310241920.0000\n","Epoch 31/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28076.7344 - mean_squared_error: 1365748736.0000 - val_loss: 23431.6035 - val_mean_squared_error: 678988800.0000\n","Epoch 32/50\n","96/96 [==============================] - 0s 3ms/step - loss: 27126.8203 - mean_squared_error: 1278212608.0000 - val_loss: 27497.1016 - val_mean_squared_error: 1043792320.0000\n","Epoch 33/50\n","96/96 [==============================] - 0s 3ms/step - loss: 30121.2129 - mean_squared_error: 1740368256.0000 - val_loss: 30498.7109 - val_mean_squared_error: 1548333056.0000\n","Epoch 34/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29323.3203 - mean_squared_error: 1458486912.0000 - val_loss: 26399.5625 - val_mean_squared_error: 964692992.0000\n","Epoch 35/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28560.5879 - mean_squared_error: 1502877056.0000 - val_loss: 25588.7832 - val_mean_squared_error: 912449024.0000\n","Epoch 36/50\n","96/96 [==============================] - 0s 3ms/step - loss: 27446.6016 - mean_squared_error: 1343723008.0000 - val_loss: 33629.6523 - val_mean_squared_error: 1663117952.0000\n","Epoch 37/50\n","96/96 [==============================] - 0s 2ms/step - loss: 28929.6094 - mean_squared_error: 1411085952.0000 - val_loss: 26803.0020 - val_mean_squared_error: 992648896.0000\n","Epoch 38/50\n","96/96 [==============================] - 0s 2ms/step - loss: 27274.4004 - mean_squared_error: 1341163904.0000 - val_loss: 26896.9688 - val_mean_squared_error: 999347200.0000\n","Epoch 39/50\n","96/96 [==============================] - 0s 3ms/step - loss: 27424.7480 - mean_squared_error: 1324984064.0000 - val_loss: 31299.9297 - val_mean_squared_error: 1392403840.0000\n","Epoch 40/50\n","96/96 [==============================] - 0s 3ms/step - loss: 30236.5098 - mean_squared_error: 1623178624.0000 - val_loss: 26192.3438 - val_mean_squared_error: 950839104.0000\n","Epoch 41/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29893.0059 - mean_squared_error: 1637018752.0000 - val_loss: 35456.8516 - val_mean_squared_error: 1861160832.0000\n","Epoch 42/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29625.6582 - mean_squared_error: 1508392064.0000 - val_loss: 36564.1445 - val_mean_squared_error: 1962378112.0000\n","Epoch 43/50\n","96/96 [==============================] - 0s 3ms/step - loss: 27618.7754 - mean_squared_error: 1357550464.0000 - val_loss: 23431.1855 - val_mean_squared_error: 748960768.0000\n","Epoch 44/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29748.3340 - mean_squared_error: 1674654848.0000 - val_loss: 29219.7441 - val_mean_squared_error: 1187372672.0000\n","Epoch 45/50\n","96/96 [==============================] - 0s 3ms/step - loss: 30056.7207 - mean_squared_error: 1615565184.0000 - val_loss: 23431.0801 - val_mean_squared_error: 719019776.0000\n","Epoch 46/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29084.0879 - mean_squared_error: 1553949184.0000 - val_loss: 23431.0645 - val_mean_squared_error: 687895040.0000\n","Epoch 47/50\n","96/96 [==============================] - 0s 3ms/step - loss: 27897.0254 - mean_squared_error: 1443869184.0000 - val_loss: 23431.0938 - val_mean_squared_error: 758833920.0000\n","Epoch 48/50\n","96/96 [==============================] - 0s 3ms/step - loss: 27123.1562 - mean_squared_error: 1452176512.0000 - val_loss: 23431.0527 - val_mean_squared_error: 690173632.0000\n","Epoch 49/50\n","96/96 [==============================] - 0s 3ms/step - loss: 28876.1875 - mean_squared_error: 1579147904.0000 - val_loss: 27102.5098 - val_mean_squared_error: 1223728384.0000\n","Epoch 50/50\n","96/96 [==============================] - 0s 3ms/step - loss: 29450.4863 - mean_squared_error: 1568218240.0000 - val_loss: 23896.2598 - val_mean_squared_error: 809659584.0000\n","WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_13\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_16 (LSTM)               (None, 18, 1024)          4202496   \n","_________________________________________________________________\n","lstm_17 (LSTM)               (None, 18, 512)           3147776   \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 18, 512)           0         \n","_________________________________________________________________\n","lstm_18 (LSTM)               (None, 18, 256)           787456    \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 18, 256)           0         \n","_________________________________________________________________\n","lstm_19 (LSTM)               (None, 18, 128)           197120    \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 18, 128)           0         \n","_________________________________________________________________\n","dense_100 (Dense)            (None, 18, 1024)          132096    \n","_________________________________________________________________\n","dense_101 (Dense)            (None, 18, 512)           524800    \n","_________________________________________________________________\n","dense_102 (Dense)            (None, 18, 256)           131328    \n","_________________________________________________________________\n","dense_103 (Dense)            (None, 18, 128)           32896     \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 18, 128)           0         \n","_________________________________________________________________\n","dense_104 (Dense)            (None, 18, 64)            8256      \n","_________________________________________________________________\n","dense_105 (Dense)            (None, 18, 16)            1040      \n","_________________________________________________________________\n","flatten_13 (Flatten)         (None, 288)               0         \n","_________________________________________________________________\n","dense_106 (Dense)            (None, 1)                 289       \n","=================================================================\n","Total params: 9,165,553\n","Trainable params: 9,165,553\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 9s 65ms/step - loss: 40066.5781 - mean_squared_error: 2889566208.0000 - val_loss: 28337.9707 - val_mean_squared_error: 1110929280.0000\n","Epoch 2/50\n","96/96 [==============================] - 6s 59ms/step - loss: 39865.6758 - mean_squared_error: 2525322240.0000 - val_loss: 29110.2480 - val_mean_squared_error: 1177557248.0000\n","Epoch 3/50\n","96/96 [==============================] - 6s 58ms/step - loss: 39460.4414 - mean_squared_error: 2803521792.0000 - val_loss: 35713.2930 - val_mean_squared_error: 1887725056.0000\n","Epoch 4/50\n","96/96 [==============================] - 6s 59ms/step - loss: 36978.7656 - mean_squared_error: 2273683200.0000 - val_loss: 57013.3867 - val_mean_squared_error: 3928961792.0000\n","Epoch 5/50\n","96/96 [==============================] - 6s 59ms/step - loss: 36795.3125 - mean_squared_error: 2432004096.0000 - val_loss: 27203.7109 - val_mean_squared_error: 1021718720.0000\n","Epoch 6/50\n","96/96 [==============================] - 6s 59ms/step - loss: 39323.1562 - mean_squared_error: 2704403200.0000 - val_loss: 25313.6562 - val_mean_squared_error: 895931072.0000\n","Epoch 7/50\n","96/96 [==============================] - 6s 60ms/step - loss: 34696.4023 - mean_squared_error: 2108771456.0000 - val_loss: 23432.1641 - val_mean_squared_error: 701428608.0000\n","Epoch 8/50\n","96/96 [==============================] - 6s 61ms/step - loss: 37634.1602 - mean_squared_error: 2216435200.0000 - val_loss: 24369.8125 - val_mean_squared_error: 769171008.0000\n","Epoch 9/50\n","96/96 [==============================] - 6s 61ms/step - loss: 36274.3320 - mean_squared_error: 2339033856.0000 - val_loss: 42216.4648 - val_mean_squared_error: 2460662016.0000\n","Epoch 10/50\n","96/96 [==============================] - 6s 61ms/step - loss: 34922.2578 - mean_squared_error: 2149222144.0000 - val_loss: 38375.4648 - val_mean_squared_error: 2122919936.0000\n","Epoch 11/50\n","96/96 [==============================] - 6s 60ms/step - loss: 38704.1836 - mean_squared_error: 2625855744.0000 - val_loss: 31736.0684 - val_mean_squared_error: 1439791488.0000\n","Epoch 12/50\n","96/96 [==============================] - 6s 58ms/step - loss: 32218.3652 - mean_squared_error: 1944156160.0000 - val_loss: 23432.4062 - val_mean_squared_error: 733028032.0000\n","Epoch 13/50\n","96/96 [==============================] - 5s 57ms/step - loss: 45110.9727 - mean_squared_error: 3472338944.0000 - val_loss: 59413.4648 - val_mean_squared_error: 4208395264.0000\n","Epoch 14/50\n","96/96 [==============================] - 6s 59ms/step - loss: 35191.6719 - mean_squared_error: 2665257216.0000 - val_loss: 23432.2363 - val_mean_squared_error: 683079680.0000\n","Epoch 15/50\n","96/96 [==============================] - 6s 58ms/step - loss: 34608.1016 - mean_squared_error: 2064882560.0000 - val_loss: 34769.1367 - val_mean_squared_error: 1791228288.0000\n","Epoch 16/50\n","96/96 [==============================] - 5s 57ms/step - loss: 36480.1016 - mean_squared_error: 2302081280.0000 - val_loss: 24561.7715 - val_mean_squared_error: 853839616.0000\n","Epoch 17/50\n","96/96 [==============================] - 6s 58ms/step - loss: 42238.8984 - mean_squared_error: 2829665536.0000 - val_loss: 53349.1914 - val_mean_squared_error: 3524569344.0000\n","Epoch 18/50\n","96/96 [==============================] - 5s 57ms/step - loss: 39928.8789 - mean_squared_error: 2590402816.0000 - val_loss: 37729.7891 - val_mean_squared_error: 2064625024.0000\n","Epoch 19/50\n","96/96 [==============================] - 6s 61ms/step - loss: 41121.6055 - mean_squared_error: 2683525376.0000 - val_loss: 36158.5156 - val_mean_squared_error: 1927776896.0000\n","Epoch 20/50\n","96/96 [==============================] - 6s 61ms/step - loss: 36798.9531 - mean_squared_error: 2187918080.0000 - val_loss: 30082.6250 - val_mean_squared_error: 1268239104.0000\n","Epoch 21/50\n","96/96 [==============================] - 6s 64ms/step - loss: 33610.5156 - mean_squared_error: 2073364992.0000 - val_loss: 44777.8633 - val_mean_squared_error: 2683489024.0000\n","Epoch 22/50\n","96/96 [==============================] - 6s 62ms/step - loss: 32366.5293 - mean_squared_error: 1624434816.0000 - val_loss: 23432.2266 - val_mean_squared_error: 760325888.0000\n","Epoch 23/50\n","96/96 [==============================] - 6s 61ms/step - loss: 30263.0254 - mean_squared_error: 1671241856.0000 - val_loss: 34304.5117 - val_mean_squared_error: 1745215488.0000\n","Epoch 24/50\n","96/96 [==============================] - 6s 60ms/step - loss: 30748.2441 - mean_squared_error: 1785838720.0000 - val_loss: 42393.4883 - val_mean_squared_error: 2475638528.0000\n","Epoch 25/50\n","96/96 [==============================] - 6s 60ms/step - loss: 32065.4316 - mean_squared_error: 1783842304.0000 - val_loss: 33334.8086 - val_mean_squared_error: 1626475136.0000\n","Epoch 26/50\n","96/96 [==============================] - 6s 59ms/step - loss: 31320.6309 - mean_squared_error: 1562311808.0000 - val_loss: 29044.6504 - val_mean_squared_error: 1171716864.0000\n","Epoch 27/50\n","96/96 [==============================] - 6s 58ms/step - loss: 32212.6309 - mean_squared_error: 1819994112.0000 - val_loss: 32003.8438 - val_mean_squared_error: 1469637632.0000\n","Epoch 28/50\n","96/96 [==============================] - 6s 59ms/step - loss: 32482.6855 - mean_squared_error: 1811000448.0000 - val_loss: 26623.4238 - val_mean_squared_error: 980062528.0000\n","Epoch 29/50\n","96/96 [==============================] - 6s 59ms/step - loss: 33037.8086 - mean_squared_error: 1825520000.0000 - val_loss: 23661.5059 - val_mean_squared_error: 706262784.0000\n","Epoch 30/50\n","96/96 [==============================] - 6s 61ms/step - loss: 32856.7969 - mean_squared_error: 1723904512.0000 - val_loss: 33255.8789 - val_mean_squared_error: 1616777088.0000\n","Epoch 31/50\n","96/96 [==============================] - 6s 61ms/step - loss: 33497.3242 - mean_squared_error: 2085022720.0000 - val_loss: 23432.2266 - val_mean_squared_error: 681761856.0000\n","Epoch 32/50\n","96/96 [==============================] - 6s 61ms/step - loss: 33399.9805 - mean_squared_error: 1902296064.0000 - val_loss: 25936.4434 - val_mean_squared_error: 1036644416.0000\n","Epoch 33/50\n","96/96 [==============================] - 6s 61ms/step - loss: 34460.8008 - mean_squared_error: 1980344704.0000 - val_loss: 23432.2266 - val_mean_squared_error: 716599104.0000\n","Epoch 34/50\n","96/96 [==============================] - 6s 61ms/step - loss: 35231.0703 - mean_squared_error: 2096103424.0000 - val_loss: 23432.2207 - val_mean_squared_error: 737959104.0000\n","Epoch 35/50\n","96/96 [==============================] - 5s 57ms/step - loss: 29701.0918 - mean_squared_error: 1589113216.0000 - val_loss: 23432.2246 - val_mean_squared_error: 678835328.0000\n","Epoch 36/50\n","96/96 [==============================] - 5s 57ms/step - loss: 32366.1582 - mean_squared_error: 1629620608.0000 - val_loss: 48372.8398 - val_mean_squared_error: 3018364160.0000\n","Epoch 37/50\n","96/96 [==============================] - 6s 59ms/step - loss: 31428.0098 - mean_squared_error: 1663280512.0000 - val_loss: 27871.9316 - val_mean_squared_error: 1073031680.0000\n","Epoch 38/50\n","96/96 [==============================] - 5s 56ms/step - loss: 34131.2305 - mean_squared_error: 1914314624.0000 - val_loss: 27821.1035 - val_mean_squared_error: 1069003200.0000\n","Epoch 39/50\n","96/96 [==============================] - 6s 58ms/step - loss: 32141.6191 - mean_squared_error: 1930146304.0000 - val_loss: 27177.9316 - val_mean_squared_error: 1019813952.0000\n","Epoch 40/50\n","96/96 [==============================] - 6s 58ms/step - loss: 31252.6270 - mean_squared_error: 1801701760.0000 - val_loss: 26179.0000 - val_mean_squared_error: 949977664.0000\n","Epoch 41/50\n","96/96 [==============================] - 6s 58ms/step - loss: 36218.3320 - mean_squared_error: 2259851520.0000 - val_loss: 35580.0156 - val_mean_squared_error: 1873859200.0000\n","Epoch 42/50\n","96/96 [==============================] - 6s 60ms/step - loss: 29977.3848 - mean_squared_error: 1538488832.0000 - val_loss: 28737.9473 - val_mean_squared_error: 1144844288.0000\n","Epoch 43/50\n","96/96 [==============================] - 6s 62ms/step - loss: 29965.0469 - mean_squared_error: 1524817792.0000 - val_loss: 23432.2402 - val_mean_squared_error: 685171392.0000\n","Epoch 44/50\n","96/96 [==============================] - 6s 62ms/step - loss: 31430.2109 - mean_squared_error: 1611538560.0000 - val_loss: 40555.9766 - val_mean_squared_error: 2323217664.0000\n","Epoch 45/50\n","96/96 [==============================] - 6s 62ms/step - loss: 31709.4297 - mean_squared_error: 1648518656.0000 - val_loss: 29382.6855 - val_mean_squared_error: 1202203648.0000\n","Epoch 46/50\n","96/96 [==============================] - 6s 60ms/step - loss: 31345.6855 - mean_squared_error: 1591894016.0000 - val_loss: 30890.2754 - val_mean_squared_error: 1349306112.0000\n","Epoch 47/50\n","96/96 [==============================] - 6s 57ms/step - loss: 30671.7637 - mean_squared_error: 1720328064.0000 - val_loss: 24703.1250 - val_mean_squared_error: 811280064.0000\n","Epoch 48/50\n","96/96 [==============================] - 6s 58ms/step - loss: 31283.4590 - mean_squared_error: 1766137216.0000 - val_loss: 42231.8711 - val_mean_squared_error: 2461961984.0000\n","Epoch 49/50\n","96/96 [==============================] - 6s 59ms/step - loss: 30823.2344 - mean_squared_error: 1614890624.0000 - val_loss: 34124.7305 - val_mean_squared_error: 1726258560.0000\n","Epoch 50/50\n","96/96 [==============================] - 5s 57ms/step - loss: 29815.5469 - mean_squared_error: 1595866112.0000 - val_loss: 28189.4922 - val_mean_squared_error: 1098668160.0000\n","                              rmse smape\n","ChangDeokGung                  NaN   NaN\n","ChangGyeongGung                NaN   NaN\n","DuckSooGung                    NaN   NaN\n","GyeongBokGung                  NaN   NaN\n","HeonLeungInReung               NaN   NaN\n","JongMyo                        NaN   NaN\n","SeoDaeMunNaturalHistoryMuseum  NaN   NaN\n","SeoulMuseumOfArt               NaN   NaN\n","SunReungJungReung              NaN   NaN\n","TaeReungGangNeung              NaN   NaN\n","TrickEyeMuseum                 NaN   NaN\n","SeoDaeMunPrisonHistoryMuseum   NaN   NaN\n","NamSanGolHanOkVillage          NaN   NaN\n","NationalMuseumOfKorea          NaN   NaN\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_14\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_107 (Dense)            (None, 1024)              6144      \n","_________________________________________________________________\n","dense_108 (Dense)            (None, 512)               524800    \n","_________________________________________________________________\n","dense_109 (Dense)            (None, 256)               131328    \n","_________________________________________________________________\n","dense_110 (Dense)            (None, 128)               32896     \n","_________________________________________________________________\n","dense_111 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dense_112 (Dense)            (None, 32)                2080      \n","_________________________________________________________________\n","dense_113 (Dense)            (None, 16)                528       \n","_________________________________________________________________\n","flatten_14 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_114 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 706,049\n","Trainable params: 706,049\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 1s 4ms/step - loss: 47914.3711 - mean_squared_error: 5191807488.0000 - val_loss: 111972.9062 - val_mean_squared_error: 15551295488.0000\n","Epoch 2/50\n","96/96 [==============================] - 0s 2ms/step - loss: 47856.8438 - mean_squared_error: 4636939776.0000 - val_loss: 105093.7266 - val_mean_squared_error: 14058053632.0000\n","Epoch 3/50\n","96/96 [==============================] - 0s 2ms/step - loss: 40136.3633 - mean_squared_error: 3751914496.0000 - val_loss: 66179.5938 - val_mean_squared_error: 7393075712.0000\n","Epoch 4/50\n","96/96 [==============================] - 0s 2ms/step - loss: 35667.9414 - mean_squared_error: 3298279424.0000 - val_loss: 98088.3672 - val_mean_squared_error: 12634681344.0000\n","Epoch 5/50\n","96/96 [==============================] - 0s 2ms/step - loss: 42691.1836 - mean_squared_error: 3717516288.0000 - val_loss: 91542.4062 - val_mean_squared_error: 11393364992.0000\n","Epoch 6/50\n","96/96 [==============================] - 0s 3ms/step - loss: 34890.7188 - mean_squared_error: 2956457216.0000 - val_loss: 113103.3047 - val_mean_squared_error: 15805719552.0000\n","Epoch 7/50\n","96/96 [==============================] - 0s 3ms/step - loss: 38059.0820 - mean_squared_error: 3533439744.0000 - val_loss: 95259.8438 - val_mean_squared_error: 12087788544.0000\n","Epoch 8/50\n","96/96 [==============================] - 0s 3ms/step - loss: 36751.3750 - mean_squared_error: 3229446912.0000 - val_loss: 83560.5234 - val_mean_squared_error: 9995708416.0000\n","Epoch 9/50\n","96/96 [==============================] - 0s 2ms/step - loss: 36229.4336 - mean_squared_error: 3383002112.0000 - val_loss: 64752.1289 - val_mean_squared_error: 7175407616.0000\n","Epoch 10/50\n","96/96 [==============================] - 0s 2ms/step - loss: 40642.6562 - mean_squared_error: 3638005760.0000 - val_loss: 75288.9062 - val_mean_squared_error: 8681758720.0000\n","Epoch 11/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37157.7773 - mean_squared_error: 3550029056.0000 - val_loss: 81116.6797 - val_mean_squared_error: 9593259008.0000\n","Epoch 12/50\n","96/96 [==============================] - 0s 2ms/step - loss: 36377.3242 - mean_squared_error: 3284287232.0000 - val_loss: 107138.6875 - val_mean_squared_error: 14492056576.0000\n","Epoch 13/50\n","96/96 [==============================] - 0s 2ms/step - loss: 39538.6484 - mean_squared_error: 3525280000.0000 - val_loss: 90143.7266 - val_mean_squared_error: 11139238912.0000\n","Epoch 14/50\n","96/96 [==============================] - 0s 2ms/step - loss: 39310.7930 - mean_squared_error: 3419287296.0000 - val_loss: 89974.3672 - val_mean_squared_error: 11108732928.0000\n","Epoch 15/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37741.5859 - mean_squared_error: 3407774720.0000 - val_loss: 72897.7422 - val_mean_squared_error: 8327417344.0000\n","Epoch 16/50\n","96/96 [==============================] - 0s 3ms/step - loss: 38412.1602 - mean_squared_error: 3690062848.0000 - val_loss: 74020.3047 - val_mean_squared_error: 8492339200.0000\n","Epoch 17/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37082.8906 - mean_squared_error: 3468966912.0000 - val_loss: 48246.9375 - val_mean_squared_error: 3864305664.0000\n","Epoch 18/50\n","96/96 [==============================] - 0s 2ms/step - loss: 40700.9180 - mean_squared_error: 3656095488.0000 - val_loss: 65671.4609 - val_mean_squared_error: 7318962688.0000\n","Epoch 19/50\n","96/96 [==============================] - 0s 2ms/step - loss: 35980.1992 - mean_squared_error: 3190536960.0000 - val_loss: 85127.4453 - val_mean_squared_error: 10260022272.0000\n","Epoch 20/50\n","96/96 [==============================] - 0s 3ms/step - loss: 41261.2383 - mean_squared_error: 4045568256.0000 - val_loss: 46350.2500 - val_mean_squared_error: 3137848064.0000\n","Epoch 21/50\n","96/96 [==============================] - 0s 3ms/step - loss: 40667.3086 - mean_squared_error: 3991147520.0000 - val_loss: 59710.6367 - val_mean_squared_error: 6368278528.0000\n","Epoch 22/50\n","96/96 [==============================] - 0s 3ms/step - loss: 36393.2617 - mean_squared_error: 3184252160.0000 - val_loss: 94664.3359 - val_mean_squared_error: 11974681600.0000\n","Epoch 23/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37295.0273 - mean_squared_error: 3211718400.0000 - val_loss: 61617.3711 - val_mean_squared_error: 6704175616.0000\n","Epoch 24/50\n","96/96 [==============================] - 0s 3ms/step - loss: 38015.3281 - mean_squared_error: 3213194496.0000 - val_loss: 69386.8672 - val_mean_squared_error: 7827863552.0000\n","Epoch 25/50\n","96/96 [==============================] - 0s 3ms/step - loss: 38196.9727 - mean_squared_error: 3472143360.0000 - val_loss: 77627.6406 - val_mean_squared_error: 9039381504.0000\n","Epoch 26/50\n","96/96 [==============================] - 0s 3ms/step - loss: 38061.9531 - mean_squared_error: 3525614848.0000 - val_loss: 104448.2500 - val_mean_squared_error: 13922784256.0000\n","Epoch 27/50\n","96/96 [==============================] - 0s 2ms/step - loss: 36091.1914 - mean_squared_error: 3388347136.0000 - val_loss: 97250.1016 - val_mean_squared_error: 12470924288.0000\n","Epoch 28/50\n","96/96 [==============================] - 0s 3ms/step - loss: 40771.0117 - mean_squared_error: 3864523520.0000 - val_loss: 95661.4375 - val_mean_squared_error: 12164452352.0000\n","Epoch 29/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37812.8242 - mean_squared_error: 3399447296.0000 - val_loss: 86702.0234 - val_mean_squared_error: 10530577408.0000\n","Epoch 30/50\n","96/96 [==============================] - 0s 2ms/step - loss: 37398.7891 - mean_squared_error: 3430528256.0000 - val_loss: 83723.9766 - val_mean_squared_error: 10023037952.0000\n","Epoch 31/50\n","96/96 [==============================] - 0s 3ms/step - loss: 35840.2422 - mean_squared_error: 3406978304.0000 - val_loss: 91430.8125 - val_mean_squared_error: 11372932096.0000\n","Epoch 32/50\n","96/96 [==============================] - 0s 3ms/step - loss: 42459.4375 - mean_squared_error: 3560011520.0000 - val_loss: 109865.0938 - val_mean_squared_error: 15083691008.0000\n","Epoch 33/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37458.5430 - mean_squared_error: 3487581952.0000 - val_loss: 94575.0000 - val_mean_squared_error: 11957772288.0000\n","Epoch 34/50\n","96/96 [==============================] - 0s 2ms/step - loss: 35989.3516 - mean_squared_error: 3425994496.0000 - val_loss: 68788.5234 - val_mean_squared_error: 7745183232.0000\n","Epoch 35/50\n","96/96 [==============================] - 0s 2ms/step - loss: 37930.5312 - mean_squared_error: 3337419520.0000 - val_loss: 85765.9219 - val_mean_squared_error: 10369126400.0000\n","Epoch 36/50\n","96/96 [==============================] - 0s 3ms/step - loss: 34563.6016 - mean_squared_error: 2958914560.0000 - val_loss: 90808.4922 - val_mean_squared_error: 11259518976.0000\n","Epoch 37/50\n","96/96 [==============================] - 0s 2ms/step - loss: 36953.5430 - mean_squared_error: 3754440960.0000 - val_loss: 89618.0938 - val_mean_squared_error: 11044738048.0000\n","Epoch 38/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37283.5586 - mean_squared_error: 3195603968.0000 - val_loss: 60630.6133 - val_mean_squared_error: 6534989312.0000\n","Epoch 39/50\n","96/96 [==============================] - 0s 3ms/step - loss: 36719.8906 - mean_squared_error: 3569457920.0000 - val_loss: 65906.7969 - val_mean_squared_error: 7356090880.0000\n","Epoch 40/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37047.5078 - mean_squared_error: 3123558400.0000 - val_loss: 84932.9922 - val_mean_squared_error: 10226946048.0000\n","Epoch 41/50\n","96/96 [==============================] - 0s 3ms/step - loss: 38348.4531 - mean_squared_error: 3588143872.0000 - val_loss: 85233.7422 - val_mean_squared_error: 10278121472.0000\n","Epoch 42/50\n","96/96 [==============================] - 0s 3ms/step - loss: 35857.6406 - mean_squared_error: 3256768768.0000 - val_loss: 97913.3828 - val_mean_squared_error: 12600372224.0000\n","Epoch 43/50\n","96/96 [==============================] - 0s 2ms/step - loss: 37259.6250 - mean_squared_error: 3424556032.0000 - val_loss: 51673.3125 - val_mean_squared_error: 4569702912.0000\n","Epoch 44/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37061.4102 - mean_squared_error: 3759282432.0000 - val_loss: 62737.9883 - val_mean_squared_error: 6869369344.0000\n","Epoch 45/50\n","96/96 [==============================] - 0s 3ms/step - loss: 34829.0508 - mean_squared_error: 2905649920.0000 - val_loss: 96777.9453 - val_mean_squared_error: 12379308032.0000\n","Epoch 46/50\n","96/96 [==============================] - 0s 2ms/step - loss: 40185.2383 - mean_squared_error: 3545756928.0000 - val_loss: 97049.8750 - val_mean_squared_error: 12432016384.0000\n","Epoch 47/50\n","96/96 [==============================] - 0s 3ms/step - loss: 37204.8281 - mean_squared_error: 3240879872.0000 - val_loss: 95379.2812 - val_mean_squared_error: 12110544896.0000\n","Epoch 48/50\n","96/96 [==============================] - 0s 3ms/step - loss: 38249.0742 - mean_squared_error: 3171537920.0000 - val_loss: 77581.7266 - val_mean_squared_error: 9032249344.0000\n","Epoch 49/50\n","96/96 [==============================] - 0s 3ms/step - loss: 36489.3789 - mean_squared_error: 3281002240.0000 - val_loss: 73278.3984 - val_mean_squared_error: 8383043072.0000\n","Epoch 50/50\n","96/96 [==============================] - 0s 2ms/step - loss: 39159.6328 - mean_squared_error: 3684997120.0000 - val_loss: 105640.4453 - val_mean_squared_error: 14173248512.0000\n","WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_21 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_22 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_23 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_15\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_20 (LSTM)               (None, 5, 1024)           4202496   \n","_________________________________________________________________\n","lstm_21 (LSTM)               (None, 5, 512)            3147776   \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 5, 512)            0         \n","_________________________________________________________________\n","lstm_22 (LSTM)               (None, 5, 256)            787456    \n","_________________________________________________________________\n","dropout_21 (Dropout)         (None, 5, 256)            0         \n","_________________________________________________________________\n","lstm_23 (LSTM)               (None, 5, 128)            197120    \n","_________________________________________________________________\n","dropout_22 (Dropout)         (None, 5, 128)            0         \n","_________________________________________________________________\n","dense_115 (Dense)            (None, 5, 1024)           132096    \n","_________________________________________________________________\n","dense_116 (Dense)            (None, 5, 512)            524800    \n","_________________________________________________________________\n","dense_117 (Dense)            (None, 5, 256)            131328    \n","_________________________________________________________________\n","dense_118 (Dense)            (None, 5, 128)            32896     \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 5, 128)            0         \n","_________________________________________________________________\n","dense_119 (Dense)            (None, 5, 64)             8256      \n","_________________________________________________________________\n","dense_120 (Dense)            (None, 5, 16)             1040      \n","_________________________________________________________________\n","flatten_15 (Flatten)         (None, 80)                0         \n","_________________________________________________________________\n","dense_121 (Dense)            (None, 1)                 81        \n","=================================================================\n","Total params: 9,165,345\n","Trainable params: 9,165,345\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 6s 27ms/step - loss: 59042.0977 - mean_squared_error: 6583468544.0000 - val_loss: 51634.8281 - val_mean_squared_error: 4560586752.0000\n","Epoch 2/50\n","96/96 [==============================] - 2s 21ms/step - loss: 59668.8125 - mean_squared_error: 6325865984.0000 - val_loss: 122285.9141 - val_mean_squared_error: 17967214592.0000\n","Epoch 3/50\n","96/96 [==============================] - 2s 21ms/step - loss: 55627.7812 - mean_squared_error: 6616066560.0000 - val_loss: 52905.1992 - val_mean_squared_error: 4874932736.0000\n","Epoch 4/50\n","96/96 [==============================] - 2s 21ms/step - loss: 57522.1289 - mean_squared_error: 6377658368.0000 - val_loss: 151869.6562 - val_mean_squared_error: 26077779968.0000\n","Epoch 5/50\n","96/96 [==============================] - 2s 21ms/step - loss: 54547.2812 - mean_squared_error: 6524841984.0000 - val_loss: 107078.2266 - val_mean_squared_error: 14479107072.0000\n","Epoch 6/50\n","96/96 [==============================] - 2s 22ms/step - loss: 54147.2500 - mean_squared_error: 5872977920.0000 - val_loss: 122839.9453 - val_mean_squared_error: 18103021568.0000\n","Epoch 7/50\n","96/96 [==============================] - 2s 21ms/step - loss: 51165.2930 - mean_squared_error: 5708812800.0000 - val_loss: 154295.5938 - val_mean_squared_error: 26820517888.0000\n","Epoch 8/50\n","96/96 [==============================] - 2s 20ms/step - loss: 52034.5820 - mean_squared_error: 5403283968.0000 - val_loss: 85678.4531 - val_mean_squared_error: 10354146304.0000\n","Epoch 9/50\n","96/96 [==============================] - 2s 20ms/step - loss: 52411.1055 - mean_squared_error: 5428108288.0000 - val_loss: 111209.0625 - val_mean_squared_error: 15380816896.0000\n","Epoch 10/50\n","96/96 [==============================] - 2s 21ms/step - loss: 52083.8398 - mean_squared_error: 5853759488.0000 - val_loss: 101501.9688 - val_mean_squared_error: 13316006912.0000\n","Epoch 11/50\n","96/96 [==============================] - 2s 20ms/step - loss: 44140.1758 - mean_squared_error: 4008937728.0000 - val_loss: 127924.8750 - val_mean_squared_error: 19378149376.0000\n","Epoch 12/50\n","96/96 [==============================] - 2s 22ms/step - loss: 43862.3906 - mean_squared_error: 4678869504.0000 - val_loss: 101096.8047 - val_mean_squared_error: 13233918976.0000\n","Epoch 13/50\n","96/96 [==============================] - 2s 22ms/step - loss: 44615.3320 - mean_squared_error: 5029111296.0000 - val_loss: 124491.6328 - val_mean_squared_error: 18511538176.0000\n","Epoch 14/50\n","96/96 [==============================] - 2s 22ms/step - loss: 54793.1250 - mean_squared_error: 6495181312.0000 - val_loss: 114881.5234 - val_mean_squared_error: 16211131392.0000\n","Epoch 15/50\n","96/96 [==============================] - 2s 22ms/step - loss: 46980.2852 - mean_squared_error: 4690967040.0000 - val_loss: 81956.8047 - val_mean_squared_error: 9730264064.0000\n","Epoch 16/50\n","96/96 [==============================] - 2s 21ms/step - loss: 43836.4492 - mean_squared_error: 4330089984.0000 - val_loss: 57306.3281 - val_mean_squared_error: 5834346496.0000\n","Epoch 17/50\n","96/96 [==============================] - 2s 22ms/step - loss: 45821.1523 - mean_squared_error: 4614349312.0000 - val_loss: 103100.7891 - val_mean_squared_error: 13643131904.0000\n","Epoch 18/50\n","96/96 [==============================] - 2s 21ms/step - loss: 50791.4883 - mean_squared_error: 5790340608.0000 - val_loss: 109161.2109 - val_mean_squared_error: 14929530880.0000\n","Epoch 19/50\n","96/96 [==============================] - 2s 21ms/step - loss: 46416.9648 - mean_squared_error: 4398825984.0000 - val_loss: 109153.0078 - val_mean_squared_error: 14927744000.0000\n","Epoch 20/50\n","96/96 [==============================] - 2s 21ms/step - loss: 45067.9648 - mean_squared_error: 4505388544.0000 - val_loss: 106593.5625 - val_mean_squared_error: 14375546880.0000\n","Epoch 21/50\n","96/96 [==============================] - 2s 21ms/step - loss: 43907.7344 - mean_squared_error: 4065702656.0000 - val_loss: 76822.6016 - val_mean_squared_error: 8915055616.0000\n","Epoch 22/50\n","96/96 [==============================] - 2s 21ms/step - loss: 47943.1445 - mean_squared_error: 4698685952.0000 - val_loss: 90056.3984 - val_mean_squared_error: 11123508224.0000\n","Epoch 23/50\n","96/96 [==============================] - 2s 21ms/step - loss: 44928.9219 - mean_squared_error: 4356080128.0000 - val_loss: 89484.8438 - val_mean_squared_error: 11020876800.0000\n","Epoch 24/50\n","96/96 [==============================] - 2s 22ms/step - loss: 41886.4922 - mean_squared_error: 4206575872.0000 - val_loss: 127223.8359 - val_mean_squared_error: 19199277056.0000\n","Epoch 25/50\n","96/96 [==============================] - 2s 20ms/step - loss: 47630.0312 - mean_squared_error: 4710836736.0000 - val_loss: 51277.8125 - val_mean_squared_error: 4477473792.0000\n","Epoch 26/50\n","96/96 [==============================] - 2s 20ms/step - loss: 58748.2227 - mean_squared_error: 6704453120.0000 - val_loss: 145433.8281 - val_mean_squared_error: 24164386816.0000\n","Epoch 27/50\n","96/96 [==============================] - 2s 20ms/step - loss: 39542.2266 - mean_squared_error: 3935585280.0000 - val_loss: 124654.6641 - val_mean_squared_error: 18552158208.0000\n","Epoch 28/50\n","96/96 [==============================] - 2s 20ms/step - loss: 44166.5898 - mean_squared_error: 4459736064.0000 - val_loss: 97861.7578 - val_mean_squared_error: 12590279680.0000\n","Epoch 29/50\n","96/96 [==============================] - 2s 20ms/step - loss: 43373.9727 - mean_squared_error: 4201356544.0000 - val_loss: 127948.6641 - val_mean_squared_error: 19384231936.0000\n","Epoch 30/50\n","96/96 [==============================] - 2s 20ms/step - loss: 41687.5938 - mean_squared_error: 4121243904.0000 - val_loss: 111496.0625 - val_mean_squared_error: 15444739072.0000\n","Epoch 31/50\n","96/96 [==============================] - 2s 20ms/step - loss: 40998.4766 - mean_squared_error: 3649198336.0000 - val_loss: 120881.1797 - val_mean_squared_error: 17625628672.0000\n","Epoch 32/50\n","96/96 [==============================] - 2s 20ms/step - loss: 42931.2461 - mean_squared_error: 4061427968.0000 - val_loss: 86026.1250 - val_mean_squared_error: 10413843456.0000\n","Epoch 33/50\n","96/96 [==============================] - 2s 20ms/step - loss: 44709.3867 - mean_squared_error: 4869601280.0000 - val_loss: 80394.0859 - val_mean_squared_error: 9476555776.0000\n","Epoch 34/50\n","96/96 [==============================] - 2s 20ms/step - loss: 39125.4961 - mean_squared_error: 3588537344.0000 - val_loss: 114792.0938 - val_mean_squared_error: 16190590976.0000\n","Epoch 35/50\n","96/96 [==============================] - 2s 20ms/step - loss: 42849.1133 - mean_squared_error: 3903027456.0000 - val_loss: 123878.8438 - val_mean_squared_error: 18359334912.0000\n","Epoch 36/50\n","96/96 [==============================] - 2s 20ms/step - loss: 44256.7812 - mean_squared_error: 4001865984.0000 - val_loss: 96545.3203 - val_mean_squared_error: 12334354432.0000\n","Epoch 37/50\n","96/96 [==============================] - 2s 20ms/step - loss: 39770.4805 - mean_squared_error: 3832129792.0000 - val_loss: 132795.7969 - val_mean_squared_error: 20648097792.0000\n","Epoch 38/50\n","96/96 [==============================] - 2s 21ms/step - loss: 42264.7422 - mean_squared_error: 4587719680.0000 - val_loss: 80555.7891 - val_mean_squared_error: 9502581760.0000\n","Epoch 39/50\n","96/96 [==============================] - 2s 20ms/step - loss: 44594.4336 - mean_squared_error: 4519993856.0000 - val_loss: 58002.2773 - val_mean_squared_error: 5984140800.0000\n","Epoch 40/50\n","96/96 [==============================] - 2s 21ms/step - loss: 41186.2773 - mean_squared_error: 3381832448.0000 - val_loss: 93557.0391 - val_mean_squared_error: 11766273024.0000\n","Epoch 41/50\n","96/96 [==============================] - 2s 20ms/step - loss: 40162.9883 - mean_squared_error: 3786961920.0000 - val_loss: 82943.3359 - val_mean_squared_error: 9892945920.0000\n","Epoch 42/50\n","96/96 [==============================] - 2s 20ms/step - loss: 46069.8398 - mean_squared_error: 4589558272.0000 - val_loss: 103214.8750 - val_mean_squared_error: 13666668544.0000\n","Epoch 43/50\n","96/96 [==============================] - 2s 21ms/step - loss: 42001.8906 - mean_squared_error: 4097557760.0000 - val_loss: 115116.4141 - val_mean_squared_error: 16265153536.0000\n","Epoch 44/50\n","96/96 [==============================] - 2s 21ms/step - loss: 41441.6484 - mean_squared_error: 3735711744.0000 - val_loss: 84745.5625 - val_mean_squared_error: 10195158016.0000\n","Epoch 45/50\n","96/96 [==============================] - 2s 22ms/step - loss: 45684.2969 - mean_squared_error: 4516169728.0000 - val_loss: 114181.8359 - val_mean_squared_error: 16050859008.0000\n","Epoch 46/50\n","96/96 [==============================] - 2s 21ms/step - loss: 38796.7891 - mean_squared_error: 3632395520.0000 - val_loss: 132491.4844 - val_mean_squared_error: 20567367680.0000\n","Epoch 47/50\n","96/96 [==============================] - 2s 22ms/step - loss: 42552.1055 - mean_squared_error: 4105827328.0000 - val_loss: 95659.7891 - val_mean_squared_error: 12164150272.0000\n","Epoch 48/50\n","96/96 [==============================] - 2s 22ms/step - loss: 40923.1602 - mean_squared_error: 3661723392.0000 - val_loss: 93491.3438 - val_mean_squared_error: 11753985024.0000\n","Epoch 49/50\n","96/96 [==============================] - 2s 22ms/step - loss: 41699.6289 - mean_squared_error: 4061425664.0000 - val_loss: 88297.1250 - val_mean_squared_error: 10809732096.0000\n","Epoch 50/50\n","96/96 [==============================] - 2s 21ms/step - loss: 42316.9531 - mean_squared_error: 3936872704.0000 - val_loss: 91009.7266 - val_mean_squared_error: 11296121856.0000\n","                              rmse smape\n","ChangDeokGung                  NaN   NaN\n","ChangGyeongGung                NaN   NaN\n","DuckSooGung                    NaN   NaN\n","GyeongBokGung                  NaN   NaN\n","HeonLeungInReung               NaN   NaN\n","JongMyo                        NaN   NaN\n","SeoDaeMunNaturalHistoryMuseum  NaN   NaN\n","SeoulMuseumOfArt               NaN   NaN\n","SunReungJungReung              NaN   NaN\n","TaeReungGangNeung              NaN   NaN\n","TrickEyeMuseum                 NaN   NaN\n","SeoDaeMunPrisonHistoryMuseum   NaN   NaN\n","NamSanGolHanOkVillage          NaN   NaN\n","NationalMuseumOfKorea          NaN   NaN\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_122 (Dense)            (None, 1024)              6144      \n","_________________________________________________________________\n","dense_123 (Dense)            (None, 512)               524800    \n","_________________________________________________________________\n","dense_124 (Dense)            (None, 256)               131328    \n","_________________________________________________________________\n","dense_125 (Dense)            (None, 128)               32896     \n","_________________________________________________________________\n","dense_126 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dense_127 (Dense)            (None, 32)                2080      \n","_________________________________________________________________\n","dense_128 (Dense)            (None, 16)                528       \n","_________________________________________________________________\n","flatten_16 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_129 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 706,049\n","Trainable params: 706,049\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 1s 4ms/step - loss: 295510.8438 - mean_squared_error: 110427496448.0000 - val_loss: 313297.0312 - val_mean_squared_error: 108704522240.0000\n","Epoch 2/50\n","96/96 [==============================] - 0s 3ms/step - loss: 157752.5781 - mean_squared_error: 40765255680.0000 - val_loss: 147519.0156 - val_mean_squared_error: 28728276992.0000\n","Epoch 3/50\n","96/96 [==============================] - 0s 3ms/step - loss: 102081.7188 - mean_squared_error: 17864873984.0000 - val_loss: 98561.2188 - val_mean_squared_error: 11865027584.0000\n","Epoch 4/50\n","96/96 [==============================] - 0s 3ms/step - loss: 99333.6172 - mean_squared_error: 18568853504.0000 - val_loss: 93404.9141 - val_mean_squared_error: 12622785536.0000\n","Epoch 5/50\n","96/96 [==============================] - 0s 3ms/step - loss: 107795.2812 - mean_squared_error: 20488921088.0000 - val_loss: 110917.6484 - val_mean_squared_error: 16702129152.0000\n","Epoch 6/50\n","96/96 [==============================] - 0s 3ms/step - loss: 98905.7109 - mean_squared_error: 17598631936.0000 - val_loss: 95635.7812 - val_mean_squared_error: 12223822848.0000\n","Epoch 7/50\n","96/96 [==============================] - 0s 3ms/step - loss: 149547.5156 - mean_squared_error: 120189214720.0000 - val_loss: 80815.2891 - val_mean_squared_error: 9495478272.0000\n","Epoch 8/50\n","96/96 [==============================] - 0s 3ms/step - loss: 103501.5938 - mean_squared_error: 17850990592.0000 - val_loss: 123827.2578 - val_mean_squared_error: 21117661184.0000\n","Epoch 9/50\n","96/96 [==============================] - 0s 3ms/step - loss: 109300.4141 - mean_squared_error: 21243824128.0000 - val_loss: 105729.4297 - val_mean_squared_error: 17565972480.0000\n","Epoch 10/50\n","96/96 [==============================] - 0s 3ms/step - loss: 95684.0078 - mean_squared_error: 17148477440.0000 - val_loss: 91022.6328 - val_mean_squared_error: 10769219584.0000\n","Epoch 11/50\n","96/96 [==============================] - 0s 3ms/step - loss: 97016.2422 - mean_squared_error: 17463939072.0000 - val_loss: 86908.3984 - val_mean_squared_error: 10825000960.0000\n","Epoch 12/50\n","96/96 [==============================] - 0s 3ms/step - loss: 96500.8359 - mean_squared_error: 16697138176.0000 - val_loss: 106795.6250 - val_mean_squared_error: 15287865344.0000\n","Epoch 13/50\n","96/96 [==============================] - 0s 3ms/step - loss: 93540.2500 - mean_squared_error: 16319581184.0000 - val_loss: 89036.2188 - val_mean_squared_error: 12892685312.0000\n","Epoch 14/50\n","96/96 [==============================] - 0s 3ms/step - loss: 100073.4062 - mean_squared_error: 17801791488.0000 - val_loss: 97452.7266 - val_mean_squared_error: 12649024512.0000\n","Epoch 15/50\n","96/96 [==============================] - 0s 3ms/step - loss: 97750.2734 - mean_squared_error: 17998209024.0000 - val_loss: 104092.2734 - val_mean_squared_error: 15605964800.0000\n","Epoch 16/50\n","96/96 [==============================] - 0s 3ms/step - loss: 95927.8125 - mean_squared_error: 16930615296.0000 - val_loss: 75280.6484 - val_mean_squared_error: 7769600000.0000\n","Epoch 17/50\n","96/96 [==============================] - 0s 3ms/step - loss: 97340.9141 - mean_squared_error: 16996242432.0000 - val_loss: 80530.7266 - val_mean_squared_error: 8929370112.0000\n","Epoch 18/50\n","96/96 [==============================] - 0s 3ms/step - loss: 96416.5000 - mean_squared_error: 16228832256.0000 - val_loss: 83129.1250 - val_mean_squared_error: 9503799296.0000\n","Epoch 19/50\n","96/96 [==============================] - 0s 3ms/step - loss: 95980.4375 - mean_squared_error: 15751897088.0000 - val_loss: 127139.2891 - val_mean_squared_error: 24064874496.0000\n","Epoch 20/50\n","96/96 [==============================] - 0s 3ms/step - loss: 97505.4688 - mean_squared_error: 17203857408.0000 - val_loss: 86919.3203 - val_mean_squared_error: 11110080512.0000\n","Epoch 21/50\n","96/96 [==============================] - 0s 3ms/step - loss: 87195.6719 - mean_squared_error: 14606263296.0000 - val_loss: 123281.1328 - val_mean_squared_error: 21273466880.0000\n","Epoch 22/50\n","96/96 [==============================] - 0s 3ms/step - loss: 94062.8047 - mean_squared_error: 16154428416.0000 - val_loss: 75579.2812 - val_mean_squared_error: 10257208320.0000\n","Epoch 23/50\n","96/96 [==============================] - 0s 3ms/step - loss: 90729.9375 - mean_squared_error: 15235245056.0000 - val_loss: 105128.7578 - val_mean_squared_error: 16602131456.0000\n","Epoch 24/50\n","96/96 [==============================] - 0s 3ms/step - loss: 91084.1172 - mean_squared_error: 14961013760.0000 - val_loss: 131434.2656 - val_mean_squared_error: 23356047360.0000\n","Epoch 25/50\n","96/96 [==============================] - 0s 3ms/step - loss: 93134.8359 - mean_squared_error: 16723225600.0000 - val_loss: 84981.1562 - val_mean_squared_error: 11679788032.0000\n","Epoch 26/50\n","96/96 [==============================] - 0s 3ms/step - loss: 91930.1328 - mean_squared_error: 15628610560.0000 - val_loss: 114310.6328 - val_mean_squared_error: 18798782464.0000\n","Epoch 27/50\n","96/96 [==============================] - 0s 3ms/step - loss: 88306.1953 - mean_squared_error: 16209640448.0000 - val_loss: 134927.2344 - val_mean_squared_error: 24582447104.0000\n","Epoch 28/50\n","96/96 [==============================] - 0s 3ms/step - loss: 91812.7500 - mean_squared_error: 16440294400.0000 - val_loss: 98630.4141 - val_mean_squared_error: 14707428352.0000\n","Epoch 29/50\n","96/96 [==============================] - 0s 3ms/step - loss: 92331.1328 - mean_squared_error: 16527195136.0000 - val_loss: 82162.1094 - val_mean_squared_error: 8842815488.0000\n","Epoch 30/50\n","96/96 [==============================] - 0s 3ms/step - loss: 90741.2578 - mean_squared_error: 16528121856.0000 - val_loss: 87390.1484 - val_mean_squared_error: 11468492800.0000\n","Epoch 31/50\n","96/96 [==============================] - 0s 3ms/step - loss: 91779.0547 - mean_squared_error: 15727627264.0000 - val_loss: 89834.2891 - val_mean_squared_error: 11036369920.0000\n","Epoch 32/50\n","96/96 [==============================] - 0s 3ms/step - loss: 92476.3203 - mean_squared_error: 15852688384.0000 - val_loss: 84491.1250 - val_mean_squared_error: 10865145856.0000\n","Epoch 33/50\n","96/96 [==============================] - 0s 3ms/step - loss: 94350.1016 - mean_squared_error: 16389694464.0000 - val_loss: 111450.4766 - val_mean_squared_error: 18320545792.0000\n","Epoch 34/50\n","96/96 [==============================] - 0s 3ms/step - loss: 94523.1797 - mean_squared_error: 15074934784.0000 - val_loss: 89321.6953 - val_mean_squared_error: 12259752960.0000\n","Epoch 35/50\n","96/96 [==============================] - 0s 3ms/step - loss: 92579.7188 - mean_squared_error: 17059901440.0000 - val_loss: 84813.9922 - val_mean_squared_error: 10939965440.0000\n","Epoch 36/50\n","96/96 [==============================] - 0s 3ms/step - loss: 91148.5000 - mean_squared_error: 16034743296.0000 - val_loss: 87236.0859 - val_mean_squared_error: 10418521088.0000\n","Epoch 37/50\n","96/96 [==============================] - 0s 3ms/step - loss: 95082.8438 - mean_squared_error: 16627798016.0000 - val_loss: 87776.1875 - val_mean_squared_error: 10171867136.0000\n","Epoch 38/50\n","96/96 [==============================] - 0s 3ms/step - loss: 93692.4297 - mean_squared_error: 15654040576.0000 - val_loss: 82140.8203 - val_mean_squared_error: 9485854720.0000\n","Epoch 39/50\n","96/96 [==============================] - 0s 3ms/step - loss: 98939.4688 - mean_squared_error: 17444020224.0000 - val_loss: 90899.1953 - val_mean_squared_error: 13498434560.0000\n","Epoch 40/50\n","96/96 [==============================] - 0s 3ms/step - loss: 91993.2500 - mean_squared_error: 15811134464.0000 - val_loss: 90636.8516 - val_mean_squared_error: 12009786368.0000\n","Epoch 41/50\n","96/96 [==============================] - 0s 3ms/step - loss: 93207.8828 - mean_squared_error: 15619842048.0000 - val_loss: 89074.2500 - val_mean_squared_error: 12515877888.0000\n","Epoch 42/50\n","96/96 [==============================] - 0s 3ms/step - loss: 91070.0625 - mean_squared_error: 15714061312.0000 - val_loss: 91039.6562 - val_mean_squared_error: 13125248000.0000\n","Epoch 43/50\n","96/96 [==============================] - 0s 3ms/step - loss: 90016.4141 - mean_squared_error: 14920372224.0000 - val_loss: 95043.7500 - val_mean_squared_error: 14864408576.0000\n","Epoch 44/50\n","96/96 [==============================] - 0s 3ms/step - loss: 87836.1328 - mean_squared_error: 14995055616.0000 - val_loss: 97783.5547 - val_mean_squared_error: 15013080064.0000\n","Epoch 45/50\n","96/96 [==============================] - 0s 3ms/step - loss: 87635.1250 - mean_squared_error: 14654083072.0000 - val_loss: 85948.6562 - val_mean_squared_error: 11296386048.0000\n","Epoch 46/50\n","96/96 [==============================] - 0s 3ms/step - loss: 90088.4922 - mean_squared_error: 15109415936.0000 - val_loss: 86772.3984 - val_mean_squared_error: 11188190208.0000\n","Epoch 47/50\n","96/96 [==============================] - 0s 3ms/step - loss: 87481.7891 - mean_squared_error: 15255441408.0000 - val_loss: 93304.9766 - val_mean_squared_error: 13336425472.0000\n","Epoch 48/50\n","96/96 [==============================] - 0s 3ms/step - loss: 87369.1484 - mean_squared_error: 15104207872.0000 - val_loss: 111097.7578 - val_mean_squared_error: 17981675520.0000\n","Epoch 49/50\n","96/96 [==============================] - 0s 3ms/step - loss: 86750.6328 - mean_squared_error: 14346493952.0000 - val_loss: 65842.8828 - val_mean_squared_error: 5692217856.0000\n","Epoch 50/50\n","96/96 [==============================] - 0s 3ms/step - loss: 87941.3828 - mean_squared_error: 15741402112.0000 - val_loss: 92478.6250 - val_mean_squared_error: 13433988096.0000\n","WARNING:tensorflow:Layer lstm_24 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_25 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_26 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_27 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_17\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_24 (LSTM)               (None, 5, 1024)           4202496   \n","_________________________________________________________________\n","lstm_25 (LSTM)               (None, 5, 512)            3147776   \n","_________________________________________________________________\n","dropout_24 (Dropout)         (None, 5, 512)            0         \n","_________________________________________________________________\n","lstm_26 (LSTM)               (None, 5, 256)            787456    \n","_________________________________________________________________\n","dropout_25 (Dropout)         (None, 5, 256)            0         \n","_________________________________________________________________\n","lstm_27 (LSTM)               (None, 5, 128)            197120    \n","_________________________________________________________________\n","dropout_26 (Dropout)         (None, 5, 128)            0         \n","_________________________________________________________________\n","dense_130 (Dense)            (None, 5, 1024)           132096    \n","_________________________________________________________________\n","dense_131 (Dense)            (None, 5, 512)            524800    \n","_________________________________________________________________\n","dense_132 (Dense)            (None, 5, 256)            131328    \n","_________________________________________________________________\n","dense_133 (Dense)            (None, 5, 128)            32896     \n","_________________________________________________________________\n","dropout_27 (Dropout)         (None, 5, 128)            0         \n","_________________________________________________________________\n","dense_134 (Dense)            (None, 5, 64)             8256      \n","_________________________________________________________________\n","dense_135 (Dense)            (None, 5, 16)             1040      \n","_________________________________________________________________\n","flatten_17 (Flatten)         (None, 80)                0         \n","_________________________________________________________________\n","dense_136 (Dense)            (None, 1)                 81        \n","=================================================================\n","Total params: 9,165,345\n","Trainable params: 9,165,345\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 5s 26ms/step - loss: 530892.8125 - mean_squared_error: 2622571413504.0000 - val_loss: 306590.8125 - val_mean_squared_error: 107538227200.0000\n","Epoch 2/50\n","96/96 [==============================] - 2s 20ms/step - loss: 296677.3438 - mean_squared_error: 191143018496.0000 - val_loss: 284564.2812 - val_mean_squared_error: 103661510656.0000\n","Epoch 3/50\n","96/96 [==============================] - 2s 20ms/step - loss: 274809.5312 - mean_squared_error: 124250005504.0000 - val_loss: 311816.7812 - val_mean_squared_error: 109305225216.0000\n","Epoch 4/50\n","96/96 [==============================] - 2s 20ms/step - loss: 271345.3438 - mean_squared_error: 98543296512.0000 - val_loss: 286160.5938 - val_mean_squared_error: 103671504896.0000\n","Epoch 5/50\n","96/96 [==============================] - 2s 21ms/step - loss: 302966.6875 - mean_squared_error: 147533103104.0000 - val_loss: 317573.0312 - val_mean_squared_error: 111473041408.0000\n","Epoch 6/50\n","96/96 [==============================] - 2s 20ms/step - loss: 304858.8438 - mean_squared_error: 151614488576.0000 - val_loss: 315409.8438 - val_mean_squared_error: 110389141504.0000\n","Epoch 7/50\n","96/96 [==============================] - 2s 20ms/step - loss: 256776.4375 - mean_squared_error: 87031996416.0000 - val_loss: 295050.2188 - val_mean_squared_error: 100639154176.0000\n","Epoch 8/50\n","96/96 [==============================] - 2s 20ms/step - loss: 439441.9688 - mean_squared_error: 1268760444928.0000 - val_loss: 289526.5938 - val_mean_squared_error: 100051656704.0000\n","Epoch 9/50\n","96/96 [==============================] - 2s 20ms/step - loss: 241907.3125 - mean_squared_error: 80111181824.0000 - val_loss: 284279.8125 - val_mean_squared_error: 94187888640.0000\n","Epoch 10/50\n","96/96 [==============================] - 2s 21ms/step - loss: 233259.8281 - mean_squared_error: 80203931648.0000 - val_loss: 229768.8906 - val_mean_squared_error: 69376253952.0000\n","Epoch 11/50\n","96/96 [==============================] - 2s 21ms/step - loss: 151460.0000 - mean_squared_error: 39003746304.0000 - val_loss: 83314.9297 - val_mean_squared_error: 13206384640.0000\n","Epoch 12/50\n","96/96 [==============================] - 2s 21ms/step - loss: 118828.6875 - mean_squared_error: 28750198784.0000 - val_loss: 93865.2891 - val_mean_squared_error: 16175913984.0000\n","Epoch 13/50\n","96/96 [==============================] - 2s 20ms/step - loss: 105514.5312 - mean_squared_error: 21746999296.0000 - val_loss: 79931.8516 - val_mean_squared_error: 10751565824.0000\n","Epoch 14/50\n","96/96 [==============================] - 2s 22ms/step - loss: 89415.5625 - mean_squared_error: 14748789760.0000 - val_loss: 78405.1484 - val_mean_squared_error: 8877362176.0000\n","Epoch 15/50\n","96/96 [==============================] - 2s 22ms/step - loss: 85904.6797 - mean_squared_error: 13561768960.0000 - val_loss: 80328.4922 - val_mean_squared_error: 10916600832.0000\n","Epoch 16/50\n","96/96 [==============================] - 2s 22ms/step - loss: 86756.8359 - mean_squared_error: 14269658112.0000 - val_loss: 71990.6484 - val_mean_squared_error: 9593594880.0000\n","Epoch 17/50\n","96/96 [==============================] - 2s 22ms/step - loss: 87743.8750 - mean_squared_error: 14559306752.0000 - val_loss: 61537.9258 - val_mean_squared_error: 5943075328.0000\n","Epoch 18/50\n","96/96 [==============================] - 2s 22ms/step - loss: 76237.9453 - mean_squared_error: 11154867200.0000 - val_loss: 60461.0156 - val_mean_squared_error: 5195550720.0000\n","Epoch 19/50\n","96/96 [==============================] - 2s 22ms/step - loss: 88572.5391 - mean_squared_error: 14501450752.0000 - val_loss: 73293.2891 - val_mean_squared_error: 7907452928.0000\n","Epoch 20/50\n","96/96 [==============================] - 2s 22ms/step - loss: 84719.7266 - mean_squared_error: 13444430848.0000 - val_loss: 99001.3359 - val_mean_squared_error: 13397750784.0000\n","Epoch 21/50\n","96/96 [==============================] - 2s 22ms/step - loss: 82073.2891 - mean_squared_error: 13367185408.0000 - val_loss: 92516.5078 - val_mean_squared_error: 13133214720.0000\n","Epoch 22/50\n","96/96 [==============================] - 2s 22ms/step - loss: 77900.0391 - mean_squared_error: 11121939456.0000 - val_loss: 99066.2500 - val_mean_squared_error: 11063962624.0000\n","Epoch 23/50\n","96/96 [==============================] - 2s 22ms/step - loss: 81794.5078 - mean_squared_error: 12688433152.0000 - val_loss: 72104.5938 - val_mean_squared_error: 6820608000.0000\n","Epoch 24/50\n","96/96 [==============================] - 2s 22ms/step - loss: 76182.6328 - mean_squared_error: 11382848512.0000 - val_loss: 51809.0938 - val_mean_squared_error: 5313799680.0000\n","Epoch 25/50\n","96/96 [==============================] - 2s 22ms/step - loss: 71818.5625 - mean_squared_error: 10936101888.0000 - val_loss: 76508.8984 - val_mean_squared_error: 7129684480.0000\n","Epoch 26/50\n","96/96 [==============================] - 2s 21ms/step - loss: 69970.7031 - mean_squared_error: 9610388480.0000 - val_loss: 54005.0117 - val_mean_squared_error: 4280283136.0000\n","Epoch 27/50\n","96/96 [==============================] - 2s 20ms/step - loss: 74511.8828 - mean_squared_error: 11651096576.0000 - val_loss: 90210.5391 - val_mean_squared_error: 9825464320.0000\n","Epoch 28/50\n","96/96 [==============================] - 2s 20ms/step - loss: 70979.1562 - mean_squared_error: 9467709440.0000 - val_loss: 56008.8008 - val_mean_squared_error: 4808473088.0000\n","Epoch 29/50\n","96/96 [==============================] - 2s 21ms/step - loss: 67582.9688 - mean_squared_error: 9498057728.0000 - val_loss: 87108.0234 - val_mean_squared_error: 9294480384.0000\n","Epoch 30/50\n","96/96 [==============================] - 2s 22ms/step - loss: 74719.4609 - mean_squared_error: 11016367104.0000 - val_loss: 75296.9453 - val_mean_squared_error: 6722416128.0000\n","Epoch 31/50\n","96/96 [==============================] - 2s 21ms/step - loss: 75019.6328 - mean_squared_error: 10080596992.0000 - val_loss: 51248.2305 - val_mean_squared_error: 3564702464.0000\n","Epoch 32/50\n","96/96 [==============================] - 2s 21ms/step - loss: 69188.4375 - mean_squared_error: 9955240960.0000 - val_loss: 75369.1250 - val_mean_squared_error: 8476667392.0000\n","Epoch 33/50\n","96/96 [==============================] - 2s 21ms/step - loss: 69571.6641 - mean_squared_error: 9416352768.0000 - val_loss: 55524.5469 - val_mean_squared_error: 4428131328.0000\n","Epoch 34/50\n","96/96 [==============================] - 2s 20ms/step - loss: 75978.2188 - mean_squared_error: 11317328896.0000 - val_loss: 36520.0195 - val_mean_squared_error: 1877352832.0000\n","Epoch 35/50\n","96/96 [==============================] - 2s 20ms/step - loss: 71864.7422 - mean_squared_error: 9753297920.0000 - val_loss: 101257.4609 - val_mean_squared_error: 13199375360.0000\n","Epoch 36/50\n","96/96 [==============================] - 2s 21ms/step - loss: 60702.5195 - mean_squared_error: 7247769600.0000 - val_loss: 81396.6172 - val_mean_squared_error: 10049285120.0000\n","Epoch 37/50\n","96/96 [==============================] - 2s 20ms/step - loss: 61911.5469 - mean_squared_error: 7360448000.0000 - val_loss: 59881.5430 - val_mean_squared_error: 5022407168.0000\n","Epoch 38/50\n","96/96 [==============================] - 2s 20ms/step - loss: 301084.4688 - mean_squared_error: 5276926738432.0000 - val_loss: 58488.8594 - val_mean_squared_error: 4511921664.0000\n","Epoch 39/50\n","96/96 [==============================] - 2s 20ms/step - loss: 69364.6172 - mean_squared_error: 8752842752.0000 - val_loss: 66147.1250 - val_mean_squared_error: 8169172480.0000\n","Epoch 40/50\n","96/96 [==============================] - 2s 20ms/step - loss: 70652.1094 - mean_squared_error: 8827262976.0000 - val_loss: 62446.9219 - val_mean_squared_error: 6045767168.0000\n","Epoch 41/50\n","96/96 [==============================] - 2s 21ms/step - loss: 66180.9688 - mean_squared_error: 8396979712.0000 - val_loss: 82932.6172 - val_mean_squared_error: 10781631488.0000\n","Epoch 42/50\n","96/96 [==============================] - 2s 21ms/step - loss: 67108.9062 - mean_squared_error: 9412804608.0000 - val_loss: 60802.6055 - val_mean_squared_error: 4584120832.0000\n","Epoch 43/50\n","96/96 [==============================] - 2s 20ms/step - loss: 63884.4336 - mean_squared_error: 8053305856.0000 - val_loss: 59451.9180 - val_mean_squared_error: 6600813056.0000\n","Epoch 44/50\n","96/96 [==============================] - 2s 20ms/step - loss: 67247.1328 - mean_squared_error: 7964445184.0000 - val_loss: 67303.5000 - val_mean_squared_error: 7498959360.0000\n","Epoch 45/50\n","96/96 [==============================] - 2s 20ms/step - loss: 65988.0781 - mean_squared_error: 9215411200.0000 - val_loss: 47608.2031 - val_mean_squared_error: 3861185280.0000\n","Epoch 46/50\n","96/96 [==============================] - 2s 20ms/step - loss: 63207.1562 - mean_squared_error: 7507346944.0000 - val_loss: 70613.1719 - val_mean_squared_error: 8399864320.0000\n","Epoch 47/50\n","96/96 [==============================] - 2s 22ms/step - loss: 71769.9922 - mean_squared_error: 10721298432.0000 - val_loss: 47233.9102 - val_mean_squared_error: 4218422016.0000\n","Epoch 48/50\n","96/96 [==============================] - 2s 22ms/step - loss: 62637.1523 - mean_squared_error: 8225342976.0000 - val_loss: 70985.7734 - val_mean_squared_error: 6499403776.0000\n","Epoch 49/50\n","96/96 [==============================] - 2s 21ms/step - loss: 67164.3672 - mean_squared_error: 8536754688.0000 - val_loss: 74952.5078 - val_mean_squared_error: 8217411072.0000\n","Epoch 50/50\n","96/96 [==============================] - 2s 22ms/step - loss: 57625.0586 - mean_squared_error: 6648495616.0000 - val_loss: 58915.8945 - val_mean_squared_error: 6706489856.0000\n","                              rmse smape\n","ChangDeokGung                  NaN   NaN\n","ChangGyeongGung                NaN   NaN\n","DuckSooGung                    NaN   NaN\n","GyeongBokGung                  NaN   NaN\n","HeonLeungInReung               NaN   NaN\n","JongMyo                        NaN   NaN\n","SeoDaeMunNaturalHistoryMuseum  NaN   NaN\n","SeoulMuseumOfArt               NaN   NaN\n","SunReungJungReung              NaN   NaN\n","TaeReungGangNeung              NaN   NaN\n","TrickEyeMuseum                 NaN   NaN\n","SeoDaeMunPrisonHistoryMuseum   NaN   NaN\n","NamSanGolHanOkVillage          NaN   NaN\n","NationalMuseumOfKorea          NaN   NaN\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_18\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_137 (Dense)            (None, 1024)              3072      \n","_________________________________________________________________\n","dense_138 (Dense)            (None, 512)               524800    \n","_________________________________________________________________\n","dense_139 (Dense)            (None, 256)               131328    \n","_________________________________________________________________\n","dense_140 (Dense)            (None, 128)               32896     \n","_________________________________________________________________\n","dense_141 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dense_142 (Dense)            (None, 32)                2080      \n","_________________________________________________________________\n","dense_143 (Dense)            (None, 16)                528       \n","_________________________________________________________________\n","flatten_18 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_144 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 702,977\n","Trainable params: 702,977\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 1s 4ms/step - loss: 2106.0144 - mean_squared_error: 7268562.0000 - val_loss: 1689.3717 - val_mean_squared_error: 4469422.5000\n","Epoch 2/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1503.3213 - mean_squared_error: 4036130.0000 - val_loss: 1693.2133 - val_mean_squared_error: 4615609.0000\n","Epoch 3/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1580.8032 - mean_squared_error: 4690114.0000 - val_loss: 1615.7291 - val_mean_squared_error: 4338944.5000\n","Epoch 4/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1555.1698 - mean_squared_error: 4352345.5000 - val_loss: 1906.1035 - val_mean_squared_error: 6147325.5000\n","Epoch 5/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1509.6984 - mean_squared_error: 3993596.0000 - val_loss: 1721.8599 - val_mean_squared_error: 5014498.5000\n","Epoch 6/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1553.8661 - mean_squared_error: 4428755.5000 - val_loss: 1959.2915 - val_mean_squared_error: 6354393.5000\n","Epoch 7/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1560.9556 - mean_squared_error: 4456420.0000 - val_loss: 1506.5792 - val_mean_squared_error: 4298038.5000\n","Epoch 8/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1488.2643 - mean_squared_error: 3964082.2500 - val_loss: 2122.7537 - val_mean_squared_error: 7071882.0000\n","Epoch 9/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1467.9009 - mean_squared_error: 3924489.0000 - val_loss: 1583.0736 - val_mean_squared_error: 4958180.5000\n","Epoch 10/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1536.1237 - mean_squared_error: 4217801.5000 - val_loss: 1617.3213 - val_mean_squared_error: 5272984.5000\n","Epoch 11/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1520.8477 - mean_squared_error: 4109649.0000 - val_loss: 1470.1852 - val_mean_squared_error: 3742098.2500\n","Epoch 12/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1458.4899 - mean_squared_error: 3915960.7500 - val_loss: 1460.7251 - val_mean_squared_error: 3702095.2500\n","Epoch 13/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1514.9731 - mean_squared_error: 4442082.0000 - val_loss: 1494.1217 - val_mean_squared_error: 3795097.2500\n","Epoch 14/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1338.0663 - mean_squared_error: 3313214.2500 - val_loss: 1561.8009 - val_mean_squared_error: 4836272.0000\n","Epoch 15/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1451.8776 - mean_squared_error: 4059379.2500 - val_loss: 1405.9069 - val_mean_squared_error: 3435687.2500\n","Epoch 16/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1404.2338 - mean_squared_error: 3676003.0000 - val_loss: 1639.0424 - val_mean_squared_error: 4595135.5000\n","Epoch 17/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1332.8292 - mean_squared_error: 3181674.7500 - val_loss: 1771.3126 - val_mean_squared_error: 5297206.0000\n","Epoch 18/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1446.1807 - mean_squared_error: 3801008.2500 - val_loss: 1634.5762 - val_mean_squared_error: 4434365.0000\n","Epoch 19/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1430.6040 - mean_squared_error: 3599948.2500 - val_loss: 1587.8945 - val_mean_squared_error: 4281674.5000\n","Epoch 20/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1298.1217 - mean_squared_error: 2937133.7500 - val_loss: 1307.8827 - val_mean_squared_error: 2926479.0000\n","Epoch 21/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1284.0316 - mean_squared_error: 3035513.2500 - val_loss: 1587.6382 - val_mean_squared_error: 4455613.0000\n","Epoch 22/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1214.4862 - mean_squared_error: 2665040.7500 - val_loss: 1638.8086 - val_mean_squared_error: 4770449.5000\n","Epoch 23/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1310.1840 - mean_squared_error: 2828846.7500 - val_loss: 1550.6040 - val_mean_squared_error: 4121011.2500\n","Epoch 24/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1305.7587 - mean_squared_error: 3010422.0000 - val_loss: 1293.1327 - val_mean_squared_error: 2969802.7500\n","Epoch 25/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1141.8661 - mean_squared_error: 2374434.2500 - val_loss: 1578.9818 - val_mean_squared_error: 4362305.5000\n","Epoch 26/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1233.8910 - mean_squared_error: 2621980.7500 - val_loss: 1229.3368 - val_mean_squared_error: 2469781.5000\n","Epoch 27/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1250.2097 - mean_squared_error: 2649526.2500 - val_loss: 1255.5538 - val_mean_squared_error: 2389601.5000\n","Epoch 28/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1125.8861 - mean_squared_error: 2372863.2500 - val_loss: 1276.6210 - val_mean_squared_error: 2628113.0000\n","Epoch 29/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1328.0060 - mean_squared_error: 3323840.0000 - val_loss: 1382.6030 - val_mean_squared_error: 3317238.2500\n","Epoch 30/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1309.3381 - mean_squared_error: 3110332.2500 - val_loss: 1587.2075 - val_mean_squared_error: 4357122.0000\n","Epoch 31/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1204.6427 - mean_squared_error: 2824352.0000 - val_loss: 1828.5348 - val_mean_squared_error: 5532097.0000\n","Epoch 32/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1283.9252 - mean_squared_error: 2723884.2500 - val_loss: 1801.3160 - val_mean_squared_error: 5509766.5000\n","Epoch 33/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1144.1710 - mean_squared_error: 2374361.2500 - val_loss: 1215.4489 - val_mean_squared_error: 2424343.5000\n","Epoch 34/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1122.4362 - mean_squared_error: 2280343.5000 - val_loss: 1222.4399 - val_mean_squared_error: 2668027.7500\n","Epoch 35/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1195.6869 - mean_squared_error: 2595904.7500 - val_loss: 1514.0863 - val_mean_squared_error: 4073942.7500\n","Epoch 36/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1171.6273 - mean_squared_error: 2699561.2500 - val_loss: 1491.3990 - val_mean_squared_error: 4126184.7500\n","Epoch 37/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1124.8981 - mean_squared_error: 2306485.7500 - val_loss: 1154.8964 - val_mean_squared_error: 2626712.7500\n","Epoch 38/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1126.6735 - mean_squared_error: 2283041.0000 - val_loss: 1420.6949 - val_mean_squared_error: 3733381.2500\n","Epoch 39/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1125.4193 - mean_squared_error: 2188094.2500 - val_loss: 1195.6564 - val_mean_squared_error: 2859925.7500\n","Epoch 40/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1081.3490 - mean_squared_error: 2078293.1250 - val_loss: 1315.2314 - val_mean_squared_error: 3544308.7500\n","Epoch 41/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1098.5150 - mean_squared_error: 2179491.7500 - val_loss: 1322.1937 - val_mean_squared_error: 3503997.7500\n","Epoch 42/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1074.8458 - mean_squared_error: 2020885.5000 - val_loss: 1203.0621 - val_mean_squared_error: 3178653.2500\n","Epoch 43/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1112.4779 - mean_squared_error: 2347692.2500 - val_loss: 1294.2717 - val_mean_squared_error: 3140590.0000\n","Epoch 44/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1218.9696 - mean_squared_error: 2533995.7500 - val_loss: 1134.1951 - val_mean_squared_error: 2485885.2500\n","Epoch 45/50\n","96/96 [==============================] - 0s 3ms/step - loss: 930.6179 - mean_squared_error: 1645525.6250 - val_loss: 1204.8070 - val_mean_squared_error: 3047222.7500\n","Epoch 46/50\n","96/96 [==============================] - 0s 3ms/step - loss: 988.4183 - mean_squared_error: 1726028.8750 - val_loss: 1083.2433 - val_mean_squared_error: 2695290.5000\n","Epoch 47/50\n","96/96 [==============================] - 0s 3ms/step - loss: 992.2490 - mean_squared_error: 1906772.6250 - val_loss: 1254.6544 - val_mean_squared_error: 2572481.7500\n","Epoch 48/50\n","96/96 [==============================] - 0s 3ms/step - loss: 924.0764 - mean_squared_error: 1688317.1250 - val_loss: 1479.7098 - val_mean_squared_error: 4080215.7500\n","Epoch 49/50\n","96/96 [==============================] - 0s 3ms/step - loss: 1119.7452 - mean_squared_error: 2080960.5000 - val_loss: 1289.1135 - val_mean_squared_error: 3234459.7500\n","Epoch 50/50\n","96/96 [==============================] - 0s 3ms/step - loss: 900.7222 - mean_squared_error: 1539689.3750 - val_loss: 1004.0462 - val_mean_squared_error: 2201823.5000\n","WARNING:tensorflow:Layer lstm_28 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_29 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_30 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_31 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_19\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_28 (LSTM)               (None, 2, 1024)           4202496   \n","_________________________________________________________________\n","lstm_29 (LSTM)               (None, 2, 512)            3147776   \n","_________________________________________________________________\n","dropout_28 (Dropout)         (None, 2, 512)            0         \n","_________________________________________________________________\n","lstm_30 (LSTM)               (None, 2, 256)            787456    \n","_________________________________________________________________\n","dropout_29 (Dropout)         (None, 2, 256)            0         \n","_________________________________________________________________\n","lstm_31 (LSTM)               (None, 2, 128)            197120    \n","_________________________________________________________________\n","dropout_30 (Dropout)         (None, 2, 128)            0         \n","_________________________________________________________________\n","dense_145 (Dense)            (None, 2, 1024)           132096    \n","_________________________________________________________________\n","dense_146 (Dense)            (None, 2, 512)            524800    \n","_________________________________________________________________\n","dense_147 (Dense)            (None, 2, 256)            131328    \n","_________________________________________________________________\n","dense_148 (Dense)            (None, 2, 128)            32896     \n","_________________________________________________________________\n","dropout_31 (Dropout)         (None, 2, 128)            0         \n","_________________________________________________________________\n","dense_149 (Dense)            (None, 2, 64)             8256      \n","_________________________________________________________________\n","dense_150 (Dense)            (None, 2, 16)             1040      \n","_________________________________________________________________\n","flatten_19 (Flatten)         (None, 32)                0         \n","_________________________________________________________________\n","dense_151 (Dense)            (None, 1)                 33        \n","=================================================================\n","Total params: 9,165,297\n","Trainable params: 9,165,297\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 5s 18ms/step - loss: 3318.4727 - mean_squared_error: 20923232.0000 - val_loss: 2494.6550 - val_mean_squared_error: 9043418.0000\n","Epoch 2/50\n","96/96 [==============================] - 1s 12ms/step - loss: 2183.5835 - mean_squared_error: 7583328.5000 - val_loss: 2182.7341 - val_mean_squared_error: 6973796.0000\n","Epoch 3/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1898.3785 - mean_squared_error: 6385698.5000 - val_loss: 2487.6233 - val_mean_squared_error: 9246584.0000\n","Epoch 4/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1516.4227 - mean_squared_error: 4020276.2500 - val_loss: 1169.0380 - val_mean_squared_error: 2655670.5000\n","Epoch 5/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1343.7318 - mean_squared_error: 3154156.2500 - val_loss: 1283.8384 - val_mean_squared_error: 3350442.2500\n","Epoch 6/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1463.5787 - mean_squared_error: 3769271.0000 - val_loss: 3103.1748 - val_mean_squared_error: 13122405.0000\n","Epoch 7/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1516.7196 - mean_squared_error: 3742841.2500 - val_loss: 1166.7096 - val_mean_squared_error: 2895066.2500\n","Epoch 8/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1414.3799 - mean_squared_error: 3532686.0000 - val_loss: 1757.7153 - val_mean_squared_error: 5082683.5000\n","Epoch 9/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1640.8317 - mean_squared_error: 4862914.5000 - val_loss: 1323.2987 - val_mean_squared_error: 3394418.2500\n","Epoch 10/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1707.8495 - mean_squared_error: 4799490.0000 - val_loss: 1490.9213 - val_mean_squared_error: 4135085.7500\n","Epoch 11/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1302.4521 - mean_squared_error: 3181930.2500 - val_loss: 1538.6447 - val_mean_squared_error: 4221098.0000\n","Epoch 12/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1226.5931 - mean_squared_error: 2922502.0000 - val_loss: 1139.6226 - val_mean_squared_error: 2683369.2500\n","Epoch 13/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1357.8026 - mean_squared_error: 3583330.2500 - val_loss: 1033.0626 - val_mean_squared_error: 2153225.2500\n","Epoch 14/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1316.8250 - mean_squared_error: 3398125.2500 - val_loss: 1270.2421 - val_mean_squared_error: 2960702.0000\n","Epoch 15/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1272.3431 - mean_squared_error: 2638433.0000 - val_loss: 2186.2771 - val_mean_squared_error: 7627412.0000\n","Epoch 16/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1305.0338 - mean_squared_error: 3020787.0000 - val_loss: 1363.2032 - val_mean_squared_error: 3429615.2500\n","Epoch 17/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1463.8164 - mean_squared_error: 3984216.7500 - val_loss: 1359.8503 - val_mean_squared_error: 3415544.2500\n","Epoch 18/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1369.0737 - mean_squared_error: 3055511.2500 - val_loss: 2169.0332 - val_mean_squared_error: 7403862.0000\n","Epoch 19/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1391.1823 - mean_squared_error: 3198307.7500 - val_loss: 1019.8735 - val_mean_squared_error: 2041880.0000\n","Epoch 20/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1436.0978 - mean_squared_error: 3904493.2500 - val_loss: 1133.2607 - val_mean_squared_error: 2284350.2500\n","Epoch 21/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1267.6696 - mean_squared_error: 2795434.2500 - val_loss: 1911.8394 - val_mean_squared_error: 5800328.0000\n","Epoch 22/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1411.3164 - mean_squared_error: 3767964.0000 - val_loss: 1015.4691 - val_mean_squared_error: 2005927.3750\n","Epoch 23/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1496.9315 - mean_squared_error: 4110106.2500 - val_loss: 2940.8103 - val_mean_squared_error: 11835799.0000\n","Epoch 24/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1661.9664 - mean_squared_error: 5583620.5000 - val_loss: 2551.6213 - val_mean_squared_error: 9477493.0000\n","Epoch 25/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1497.1608 - mean_squared_error: 3962267.0000 - val_loss: 980.5049 - val_mean_squared_error: 1933269.3750\n","Epoch 26/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1352.8696 - mean_squared_error: 3422024.0000 - val_loss: 2076.9614 - val_mean_squared_error: 7088284.5000\n","Epoch 27/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1353.9442 - mean_squared_error: 3553333.7500 - val_loss: 1078.1935 - val_mean_squared_error: 2032532.1250\n","Epoch 28/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1525.3008 - mean_squared_error: 3944162.7500 - val_loss: 1900.9824 - val_mean_squared_error: 6160578.5000\n","Epoch 29/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1383.9845 - mean_squared_error: 3614489.2500 - val_loss: 974.0532 - val_mean_squared_error: 1850225.6250\n","Epoch 30/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1218.3300 - mean_squared_error: 2848478.7500 - val_loss: 996.8533 - val_mean_squared_error: 1848533.1250\n","Epoch 31/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1335.8436 - mean_squared_error: 3320222.0000 - val_loss: 1642.2476 - val_mean_squared_error: 4675255.5000\n","Epoch 32/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1411.7067 - mean_squared_error: 3423726.7500 - val_loss: 2201.7131 - val_mean_squared_error: 7644048.5000\n","Epoch 33/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1373.3676 - mean_squared_error: 3697723.2500 - val_loss: 2098.9272 - val_mean_squared_error: 6888340.5000\n","Epoch 34/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1215.9167 - mean_squared_error: 2530883.7500 - val_loss: 969.6682 - val_mean_squared_error: 1620828.0000\n","Epoch 35/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1145.6676 - mean_squared_error: 2109367.5000 - val_loss: 880.5842 - val_mean_squared_error: 1688711.5000\n","Epoch 36/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1237.2883 - mean_squared_error: 2821261.2500 - val_loss: 1828.2015 - val_mean_squared_error: 5556259.5000\n","Epoch 37/50\n","96/96 [==============================] - 1s 13ms/step - loss: 952.7593 - mean_squared_error: 1734943.3750 - val_loss: 1076.6598 - val_mean_squared_error: 1694896.8750\n","Epoch 38/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1161.8717 - mean_squared_error: 2369674.5000 - val_loss: 1812.7782 - val_mean_squared_error: 5251721.5000\n","Epoch 39/50\n","96/96 [==============================] - 1s 13ms/step - loss: 962.4329 - mean_squared_error: 1747216.0000 - val_loss: 1263.6874 - val_mean_squared_error: 3125888.0000\n","Epoch 40/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1061.3171 - mean_squared_error: 2238964.2500 - val_loss: 1206.1268 - val_mean_squared_error: 3071898.2500\n","Epoch 41/50\n","96/96 [==============================] - 1s 13ms/step - loss: 953.6099 - mean_squared_error: 1682708.0000 - val_loss: 1771.3398 - val_mean_squared_error: 4952227.5000\n","Epoch 42/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1079.4188 - mean_squared_error: 2061651.5000 - val_loss: 1246.6713 - val_mean_squared_error: 2888390.7500\n","Epoch 43/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1102.1254 - mean_squared_error: 2273699.0000 - val_loss: 1113.0876 - val_mean_squared_error: 2356462.7500\n","Epoch 44/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1126.6680 - mean_squared_error: 2244967.7500 - val_loss: 904.1567 - val_mean_squared_error: 1492381.8750\n","Epoch 45/50\n","96/96 [==============================] - 1s 13ms/step - loss: 973.6507 - mean_squared_error: 1712707.0000 - val_loss: 1217.1583 - val_mean_squared_error: 2848224.2500\n","Epoch 46/50\n","96/96 [==============================] - 1s 13ms/step - loss: 868.0212 - mean_squared_error: 1552764.1250 - val_loss: 967.7513 - val_mean_squared_error: 1630669.6250\n","Epoch 47/50\n","96/96 [==============================] - 1s 13ms/step - loss: 1230.0483 - mean_squared_error: 2925615.2500 - val_loss: 963.8397 - val_mean_squared_error: 1739681.5000\n","Epoch 48/50\n","96/96 [==============================] - 1s 12ms/step - loss: 933.0080 - mean_squared_error: 1774722.6250 - val_loss: 2011.6593 - val_mean_squared_error: 6081009.5000\n","Epoch 49/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1129.7357 - mean_squared_error: 2324889.0000 - val_loss: 1241.4806 - val_mean_squared_error: 2688225.7500\n","Epoch 50/50\n","96/96 [==============================] - 1s 12ms/step - loss: 1143.1493 - mean_squared_error: 2305813.0000 - val_loss: 925.3730 - val_mean_squared_error: 1576664.1250\n","                              rmse smape\n","ChangDeokGung                  NaN   NaN\n","ChangGyeongGung                NaN   NaN\n","DuckSooGung                    NaN   NaN\n","GyeongBokGung                  NaN   NaN\n","HeonLeungInReung               NaN   NaN\n","JongMyo                        NaN   NaN\n","SeoDaeMunNaturalHistoryMuseum  NaN   NaN\n","SeoulMuseumOfArt               NaN   NaN\n","SunReungJungReung              NaN   NaN\n","TaeReungGangNeung              NaN   NaN\n","TrickEyeMuseum                 NaN   NaN\n","SeoDaeMunPrisonHistoryMuseum   NaN   NaN\n","NamSanGolHanOkVillage          NaN   NaN\n","NationalMuseumOfKorea          NaN   NaN\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_20\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_152 (Dense)            (None, 1024)              10240     \n","_________________________________________________________________\n","dense_153 (Dense)            (None, 512)               524800    \n","_________________________________________________________________\n","dense_154 (Dense)            (None, 256)               131328    \n","_________________________________________________________________\n","dense_155 (Dense)            (None, 128)               32896     \n","_________________________________________________________________\n","dense_156 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dense_157 (Dense)            (None, 32)                2080      \n","_________________________________________________________________\n","dense_158 (Dense)            (None, 16)                528       \n","_________________________________________________________________\n","flatten_20 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_159 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 710,145\n","Trainable params: 710,145\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 1s 5ms/step - loss: 14382.7178 - mean_squared_error: 381140864.0000 - val_loss: 16195.9248 - val_mean_squared_error: 372539168.0000\n","Epoch 2/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11753.0928 - mean_squared_error: 285457792.0000 - val_loss: 22851.6621 - val_mean_squared_error: 636935424.0000\n","Epoch 3/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11653.0234 - mean_squared_error: 321665760.0000 - val_loss: 14711.3242 - val_mean_squared_error: 303700448.0000\n","Epoch 4/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11531.6807 - mean_squared_error: 305135488.0000 - val_loss: 10749.8193 - val_mean_squared_error: 175785008.0000\n","Epoch 5/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11271.5439 - mean_squared_error: 323924448.0000 - val_loss: 10366.1787 - val_mean_squared_error: 165474368.0000\n","Epoch 6/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11738.9297 - mean_squared_error: 294326880.0000 - val_loss: 16464.6738 - val_mean_squared_error: 359335072.0000\n","Epoch 7/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10554.2090 - mean_squared_error: 294336608.0000 - val_loss: 20446.2363 - val_mean_squared_error: 533919520.0000\n","Epoch 8/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11258.0312 - mean_squared_error: 308471520.0000 - val_loss: 18749.2285 - val_mean_squared_error: 462777120.0000\n","Epoch 9/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11673.9229 - mean_squared_error: 342596672.0000 - val_loss: 8883.7695 - val_mean_squared_error: 126710880.0000\n","Epoch 10/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11143.9697 - mean_squared_error: 304415008.0000 - val_loss: 12131.5557 - val_mean_squared_error: 206756976.0000\n","Epoch 11/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10674.8506 - mean_squared_error: 275017600.0000 - val_loss: 16249.1494 - val_mean_squared_error: 357586400.0000\n","Epoch 12/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10833.5049 - mean_squared_error: 312221472.0000 - val_loss: 15743.7666 - val_mean_squared_error: 324762464.0000\n","Epoch 13/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10189.8252 - mean_squared_error: 287410112.0000 - val_loss: 12860.6953 - val_mean_squared_error: 223760304.0000\n","Epoch 14/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11107.8037 - mean_squared_error: 264060672.0000 - val_loss: 18202.3652 - val_mean_squared_error: 438594304.0000\n","Epoch 15/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10251.0967 - mean_squared_error: 273610688.0000 - val_loss: 16836.3125 - val_mean_squared_error: 374696928.0000\n","Epoch 16/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10460.9463 - mean_squared_error: 278724288.0000 - val_loss: 15789.8555 - val_mean_squared_error: 322020736.0000\n","Epoch 17/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10544.8789 - mean_squared_error: 279965216.0000 - val_loss: 11193.3701 - val_mean_squared_error: 177069632.0000\n","Epoch 18/50\n","96/96 [==============================] - 0s 3ms/step - loss: 11036.9307 - mean_squared_error: 298267488.0000 - val_loss: 15564.5674 - val_mean_squared_error: 328978912.0000\n","Epoch 19/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10746.9854 - mean_squared_error: 284592736.0000 - val_loss: 13396.4170 - val_mean_squared_error: 242309968.0000\n","Epoch 20/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10686.7314 - mean_squared_error: 292153088.0000 - val_loss: 17610.8398 - val_mean_squared_error: 407399584.0000\n","Epoch 21/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10497.3799 - mean_squared_error: 270177984.0000 - val_loss: 18321.5957 - val_mean_squared_error: 438915040.0000\n","Epoch 22/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10300.5625 - mean_squared_error: 288602976.0000 - val_loss: 15960.7471 - val_mean_squared_error: 342377888.0000\n","Epoch 23/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10209.9395 - mean_squared_error: 274069696.0000 - val_loss: 16378.6748 - val_mean_squared_error: 354892128.0000\n","Epoch 24/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9931.8623 - mean_squared_error: 263708800.0000 - val_loss: 13326.8115 - val_mean_squared_error: 241803664.0000\n","Epoch 25/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10255.9561 - mean_squared_error: 262676864.0000 - val_loss: 13054.7344 - val_mean_squared_error: 222343104.0000\n","Epoch 26/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10370.2637 - mean_squared_error: 293952160.0000 - val_loss: 13676.3115 - val_mean_squared_error: 247802608.0000\n","Epoch 27/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10521.4854 - mean_squared_error: 288857120.0000 - val_loss: 15337.8643 - val_mean_squared_error: 315701472.0000\n","Epoch 28/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10018.6611 - mean_squared_error: 253654336.0000 - val_loss: 17295.5918 - val_mean_squared_error: 394900896.0000\n","Epoch 29/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10189.5010 - mean_squared_error: 283112096.0000 - val_loss: 14758.8350 - val_mean_squared_error: 295863072.0000\n","Epoch 30/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10285.8086 - mean_squared_error: 271057152.0000 - val_loss: 14596.8838 - val_mean_squared_error: 285651488.0000\n","Epoch 31/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10338.3125 - mean_squared_error: 252687440.0000 - val_loss: 13447.4424 - val_mean_squared_error: 242437296.0000\n","Epoch 32/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10420.9229 - mean_squared_error: 248842096.0000 - val_loss: 19618.2363 - val_mean_squared_error: 497493280.0000\n","Epoch 33/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10415.7256 - mean_squared_error: 266765712.0000 - val_loss: 14327.1055 - val_mean_squared_error: 279130592.0000\n","Epoch 34/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10838.8193 - mean_squared_error: 281785088.0000 - val_loss: 12262.9297 - val_mean_squared_error: 204080256.0000\n","Epoch 35/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9768.5068 - mean_squared_error: 231232192.0000 - val_loss: 16253.6611 - val_mean_squared_error: 354747616.0000\n","Epoch 36/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9781.1514 - mean_squared_error: 253492416.0000 - val_loss: 14338.4609 - val_mean_squared_error: 276690912.0000\n","Epoch 37/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9893.0107 - mean_squared_error: 239475664.0000 - val_loss: 15171.5029 - val_mean_squared_error: 314520608.0000\n","Epoch 38/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9923.0586 - mean_squared_error: 269079904.0000 - val_loss: 13392.7920 - val_mean_squared_error: 246060144.0000\n","Epoch 39/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9921.7412 - mean_squared_error: 264496368.0000 - val_loss: 11392.4658 - val_mean_squared_error: 182759488.0000\n","Epoch 40/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10741.7871 - mean_squared_error: 272824800.0000 - val_loss: 17719.1738 - val_mean_squared_error: 415191648.0000\n","Epoch 41/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10482.6318 - mean_squared_error: 283150496.0000 - val_loss: 15699.1094 - val_mean_squared_error: 326285888.0000\n","Epoch 42/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9534.3955 - mean_squared_error: 228392848.0000 - val_loss: 8630.7168 - val_mean_squared_error: 100873336.0000\n","Epoch 43/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10369.3320 - mean_squared_error: 257839184.0000 - val_loss: 16030.4609 - val_mean_squared_error: 339234464.0000\n","Epoch 44/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9877.5820 - mean_squared_error: 248340336.0000 - val_loss: 16913.1543 - val_mean_squared_error: 383675008.0000\n","Epoch 45/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10113.2461 - mean_squared_error: 238211408.0000 - val_loss: 12645.6904 - val_mean_squared_error: 219893552.0000\n","Epoch 46/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9670.9248 - mean_squared_error: 248389568.0000 - val_loss: 16702.2148 - val_mean_squared_error: 374341728.0000\n","Epoch 47/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10179.8398 - mean_squared_error: 250709120.0000 - val_loss: 16384.2871 - val_mean_squared_error: 359038208.0000\n","Epoch 48/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10046.7158 - mean_squared_error: 253778416.0000 - val_loss: 16508.9746 - val_mean_squared_error: 370777760.0000\n","Epoch 49/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9597.0703 - mean_squared_error: 224059952.0000 - val_loss: 16402.2930 - val_mean_squared_error: 365105408.0000\n","Epoch 50/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9627.5957 - mean_squared_error: 231581552.0000 - val_loss: 15756.4053 - val_mean_squared_error: 344304608.0000\n","WARNING:tensorflow:Layer lstm_32 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_33 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_34 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_35 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_21\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_32 (LSTM)               (None, 9, 1024)           4202496   \n","_________________________________________________________________\n","lstm_33 (LSTM)               (None, 9, 512)            3147776   \n","_________________________________________________________________\n","dropout_32 (Dropout)         (None, 9, 512)            0         \n","_________________________________________________________________\n","lstm_34 (LSTM)               (None, 9, 256)            787456    \n","_________________________________________________________________\n","dropout_33 (Dropout)         (None, 9, 256)            0         \n","_________________________________________________________________\n","lstm_35 (LSTM)               (None, 9, 128)            197120    \n","_________________________________________________________________\n","dropout_34 (Dropout)         (None, 9, 128)            0         \n","_________________________________________________________________\n","dense_160 (Dense)            (None, 9, 1024)           132096    \n","_________________________________________________________________\n","dense_161 (Dense)            (None, 9, 512)            524800    \n","_________________________________________________________________\n","dense_162 (Dense)            (None, 9, 256)            131328    \n","_________________________________________________________________\n","dense_163 (Dense)            (None, 9, 128)            32896     \n","_________________________________________________________________\n","dropout_35 (Dropout)         (None, 9, 128)            0         \n","_________________________________________________________________\n","dense_164 (Dense)            (None, 9, 64)             8256      \n","_________________________________________________________________\n","dense_165 (Dense)            (None, 9, 16)             1040      \n","_________________________________________________________________\n","flatten_21 (Flatten)         (None, 144)               0         \n","_________________________________________________________________\n","dense_166 (Dense)            (None, 1)                 145       \n","=================================================================\n","Total params: 9,165,409\n","Trainable params: 9,165,409\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 7s 43ms/step - loss: 16605.6328 - mean_squared_error: 496354080.0000 - val_loss: 12180.7217 - val_mean_squared_error: 220423744.0000\n","Epoch 2/50\n","96/96 [==============================] - 3s 33ms/step - loss: 12661.0049 - mean_squared_error: 342955712.0000 - val_loss: 13913.4209 - val_mean_squared_error: 275952608.0000\n","Epoch 3/50\n","96/96 [==============================] - 3s 33ms/step - loss: 12450.1357 - mean_squared_error: 330393216.0000 - val_loss: 20836.3633 - val_mean_squared_error: 549581760.0000\n","Epoch 4/50\n","96/96 [==============================] - 3s 33ms/step - loss: 12817.2891 - mean_squared_error: 329741056.0000 - val_loss: 13824.6016 - val_mean_squared_error: 269916736.0000\n","Epoch 5/50\n","96/96 [==============================] - 3s 33ms/step - loss: 13774.0186 - mean_squared_error: 402001952.0000 - val_loss: 22107.8203 - val_mean_squared_error: 603048448.0000\n","Epoch 6/50\n","96/96 [==============================] - 3s 33ms/step - loss: 13856.7920 - mean_squared_error: 389016416.0000 - val_loss: 19130.4160 - val_mean_squared_error: 484035808.0000\n","Epoch 7/50\n","96/96 [==============================] - 3s 33ms/step - loss: 12604.7002 - mean_squared_error: 340661792.0000 - val_loss: 14252.3271 - val_mean_squared_error: 282821376.0000\n","Epoch 8/50\n","96/96 [==============================] - 3s 34ms/step - loss: 14600.7188 - mean_squared_error: 412999040.0000 - val_loss: 19935.1465 - val_mean_squared_error: 526563936.0000\n","Epoch 9/50\n","96/96 [==============================] - 3s 33ms/step - loss: 11530.9580 - mean_squared_error: 341168032.0000 - val_loss: 12673.5498 - val_mean_squared_error: 230265936.0000\n","Epoch 10/50\n","96/96 [==============================] - 3s 35ms/step - loss: 13323.2139 - mean_squared_error: 367462144.0000 - val_loss: 24687.9316 - val_mean_squared_error: 729591488.0000\n","Epoch 11/50\n","96/96 [==============================] - 3s 36ms/step - loss: 12937.2705 - mean_squared_error: 326007968.0000 - val_loss: 18341.2715 - val_mean_squared_error: 456982752.0000\n","Epoch 12/50\n","96/96 [==============================] - 3s 36ms/step - loss: 12532.5508 - mean_squared_error: 359924128.0000 - val_loss: 17473.7656 - val_mean_squared_error: 417782368.0000\n","Epoch 13/50\n","96/96 [==============================] - 3s 35ms/step - loss: 12131.5811 - mean_squared_error: 327704128.0000 - val_loss: 21311.2305 - val_mean_squared_error: 576690880.0000\n","Epoch 14/50\n","96/96 [==============================] - 3s 36ms/step - loss: 13057.1084 - mean_squared_error: 340163680.0000 - val_loss: 11086.7109 - val_mean_squared_error: 184861696.0000\n","Epoch 15/50\n","96/96 [==============================] - 3s 36ms/step - loss: 13000.6562 - mean_squared_error: 382476704.0000 - val_loss: 12250.4229 - val_mean_squared_error: 212836240.0000\n","Epoch 16/50\n","96/96 [==============================] - 3s 36ms/step - loss: 12406.8799 - mean_squared_error: 330744224.0000 - val_loss: 23827.6426 - val_mean_squared_error: 688387264.0000\n","Epoch 17/50\n","96/96 [==============================] - 3s 35ms/step - loss: 11598.9102 - mean_squared_error: 344063936.0000 - val_loss: 16234.6045 - val_mean_squared_error: 355905856.0000\n","Epoch 18/50\n","96/96 [==============================] - 3s 34ms/step - loss: 11863.7734 - mean_squared_error: 318074144.0000 - val_loss: 16019.6611 - val_mean_squared_error: 343700608.0000\n","Epoch 19/50\n","96/96 [==============================] - 3s 33ms/step - loss: 12228.0693 - mean_squared_error: 327614208.0000 - val_loss: 18938.3086 - val_mean_squared_error: 476232064.0000\n","Epoch 20/50\n","96/96 [==============================] - 3s 34ms/step - loss: 12465.3096 - mean_squared_error: 361688736.0000 - val_loss: 17368.9453 - val_mean_squared_error: 406040160.0000\n","Epoch 21/50\n","96/96 [==============================] - 3s 34ms/step - loss: 13546.7227 - mean_squared_error: 410308960.0000 - val_loss: 17802.3262 - val_mean_squared_error: 426784256.0000\n","Epoch 22/50\n","96/96 [==============================] - 3s 34ms/step - loss: 11342.3506 - mean_squared_error: 307082592.0000 - val_loss: 17054.9609 - val_mean_squared_error: 391772256.0000\n","Epoch 23/50\n","96/96 [==============================] - 3s 33ms/step - loss: 11782.7100 - mean_squared_error: 318661216.0000 - val_loss: 11538.1094 - val_mean_squared_error: 191386448.0000\n","Epoch 24/50\n","96/96 [==============================] - 3s 33ms/step - loss: 11633.9287 - mean_squared_error: 327961440.0000 - val_loss: 18107.6191 - val_mean_squared_error: 438797440.0000\n","Epoch 25/50\n","96/96 [==============================] - 3s 33ms/step - loss: 12326.0039 - mean_squared_error: 341905280.0000 - val_loss: 12850.2803 - val_mean_squared_error: 224210480.0000\n","Epoch 26/50\n","96/96 [==============================] - 3s 34ms/step - loss: 11551.7256 - mean_squared_error: 282790048.0000 - val_loss: 17077.3984 - val_mean_squared_error: 385146240.0000\n","Epoch 27/50\n","96/96 [==============================] - 3s 33ms/step - loss: 11312.5908 - mean_squared_error: 300464928.0000 - val_loss: 19872.2754 - val_mean_squared_error: 516401792.0000\n","Epoch 28/50\n","96/96 [==============================] - 3s 33ms/step - loss: 12266.4531 - mean_squared_error: 315305824.0000 - val_loss: 20139.4551 - val_mean_squared_error: 525694976.0000\n","Epoch 29/50\n","96/96 [==============================] - 3s 34ms/step - loss: 11348.9209 - mean_squared_error: 333079200.0000 - val_loss: 24096.0059 - val_mean_squared_error: 696689856.0000\n","Epoch 30/50\n","96/96 [==============================] - 3s 36ms/step - loss: 12107.8086 - mean_squared_error: 337479456.0000 - val_loss: 13253.1221 - val_mean_squared_error: 232714576.0000\n","Epoch 31/50\n","96/96 [==============================] - 3s 36ms/step - loss: 10895.1367 - mean_squared_error: 295574592.0000 - val_loss: 14153.2627 - val_mean_squared_error: 264138416.0000\n","Epoch 32/50\n","96/96 [==============================] - 3s 35ms/step - loss: 10741.1982 - mean_squared_error: 266868240.0000 - val_loss: 10652.6201 - val_mean_squared_error: 165126944.0000\n","Epoch 33/50\n","96/96 [==============================] - 3s 36ms/step - loss: 10705.4453 - mean_squared_error: 273413856.0000 - val_loss: 17088.8965 - val_mean_squared_error: 387875296.0000\n","Epoch 34/50\n","96/96 [==============================] - 3s 36ms/step - loss: 10569.0049 - mean_squared_error: 292610720.0000 - val_loss: 15634.9717 - val_mean_squared_error: 320368256.0000\n","Epoch 35/50\n","96/96 [==============================] - 3s 35ms/step - loss: 10521.6748 - mean_squared_error: 276155616.0000 - val_loss: 16749.5293 - val_mean_squared_error: 372749920.0000\n","Epoch 36/50\n","96/96 [==============================] - 3s 36ms/step - loss: 10838.4473 - mean_squared_error: 281541152.0000 - val_loss: 13206.7344 - val_mean_squared_error: 230090624.0000\n","Epoch 37/50\n","96/96 [==============================] - 3s 34ms/step - loss: 11370.0498 - mean_squared_error: 307229504.0000 - val_loss: 11410.8486 - val_mean_squared_error: 182081072.0000\n","Epoch 38/50\n","96/96 [==============================] - 3s 34ms/step - loss: 10591.5439 - mean_squared_error: 281953408.0000 - val_loss: 15011.4873 - val_mean_squared_error: 292527072.0000\n","Epoch 39/50\n","96/96 [==============================] - 3s 35ms/step - loss: 11371.4658 - mean_squared_error: 308034368.0000 - val_loss: 11536.9414 - val_mean_squared_error: 184642112.0000\n","Epoch 40/50\n","96/96 [==============================] - 3s 34ms/step - loss: 11072.6631 - mean_squared_error: 300226720.0000 - val_loss: 17475.0898 - val_mean_squared_error: 405341984.0000\n","Epoch 41/50\n","96/96 [==============================] - 3s 34ms/step - loss: 10317.8877 - mean_squared_error: 274746400.0000 - val_loss: 16034.6182 - val_mean_squared_error: 340336864.0000\n","Epoch 42/50\n","96/96 [==============================] - 3s 34ms/step - loss: 11325.3936 - mean_squared_error: 313623008.0000 - val_loss: 19530.2637 - val_mean_squared_error: 495643264.0000\n","Epoch 43/50\n","96/96 [==============================] - 3s 34ms/step - loss: 10913.1426 - mean_squared_error: 276213984.0000 - val_loss: 14326.5342 - val_mean_squared_error: 264775616.0000\n","Epoch 44/50\n","96/96 [==============================] - 3s 34ms/step - loss: 10863.5479 - mean_squared_error: 282447680.0000 - val_loss: 14846.1562 - val_mean_squared_error: 290088608.0000\n","Epoch 45/50\n","96/96 [==============================] - 3s 33ms/step - loss: 10268.7939 - mean_squared_error: 269272416.0000 - val_loss: 15533.0547 - val_mean_squared_error: 321502080.0000\n","Epoch 46/50\n","96/96 [==============================] - 3s 34ms/step - loss: 10097.6279 - mean_squared_error: 239008400.0000 - val_loss: 8208.9766 - val_mean_squared_error: 99417280.0000\n","Epoch 47/50\n","96/96 [==============================] - 3s 34ms/step - loss: 12057.8447 - mean_squared_error: 313724672.0000 - val_loss: 20431.7676 - val_mean_squared_error: 534347168.0000\n","Epoch 48/50\n","96/96 [==============================] - 3s 34ms/step - loss: 11746.4463 - mean_squared_error: 302129024.0000 - val_loss: 21553.7832 - val_mean_squared_error: 577135680.0000\n","Epoch 49/50\n","96/96 [==============================] - 3s 35ms/step - loss: 10545.0283 - mean_squared_error: 274308256.0000 - val_loss: 17474.4590 - val_mean_squared_error: 401849696.0000\n","Epoch 50/50\n","96/96 [==============================] - 3s 36ms/step - loss: 11448.0244 - mean_squared_error: 300464512.0000 - val_loss: 17056.8652 - val_mean_squared_error: 384600352.0000\n","                              rmse smape\n","ChangDeokGung                  NaN   NaN\n","ChangGyeongGung                NaN   NaN\n","DuckSooGung                    NaN   NaN\n","GyeongBokGung                  NaN   NaN\n","HeonLeungInReung               NaN   NaN\n","JongMyo                        NaN   NaN\n","SeoDaeMunNaturalHistoryMuseum  NaN   NaN\n","SeoulMuseumOfArt               NaN   NaN\n","SunReungJungReung              NaN   NaN\n","TaeReungGangNeung              NaN   NaN\n","TrickEyeMuseum                 NaN   NaN\n","SeoDaeMunPrisonHistoryMuseum   NaN   NaN\n","NamSanGolHanOkVillage          NaN   NaN\n","NationalMuseumOfKorea          NaN   NaN\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_22\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_167 (Dense)            (None, 1024)              11264     \n","_________________________________________________________________\n","dense_168 (Dense)            (None, 512)               524800    \n","_________________________________________________________________\n","dense_169 (Dense)            (None, 256)               131328    \n","_________________________________________________________________\n","dense_170 (Dense)            (None, 128)               32896     \n","_________________________________________________________________\n","dense_171 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dense_172 (Dense)            (None, 32)                2080      \n","_________________________________________________________________\n","dense_173 (Dense)            (None, 16)                528       \n","_________________________________________________________________\n","flatten_22 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_174 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 711,169\n","Trainable params: 711,169\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 1s 5ms/step - loss: 97793.8359 - mean_squared_error: 22286180352.0000 - val_loss: 51933.6602 - val_mean_squared_error: 4278904576.0000\n","Epoch 2/50\n","96/96 [==============================] - 0s 3ms/step - loss: 36485.7617 - mean_squared_error: 2595860992.0000 - val_loss: 8972.3496 - val_mean_squared_error: 96207144.0000\n","Epoch 3/50\n","96/96 [==============================] - 0s 3ms/step - loss: 26894.3262 - mean_squared_error: 1321329536.0000 - val_loss: 49720.2188 - val_mean_squared_error: 2569518848.0000\n","Epoch 4/50\n","96/96 [==============================] - 0s 3ms/step - loss: 13553.7148 - mean_squared_error: 328230336.0000 - val_loss: 20356.1348 - val_mean_squared_error: 478102880.0000\n","Epoch 5/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8649.0479 - mean_squared_error: 136794832.0000 - val_loss: 5421.2930 - val_mean_squared_error: 45283260.0000\n","Epoch 6/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8894.6982 - mean_squared_error: 125835704.0000 - val_loss: 12761.4736 - val_mean_squared_error: 230786960.0000\n","Epoch 7/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8785.4062 - mean_squared_error: 131089736.0000 - val_loss: 7908.9146 - val_mean_squared_error: 82498560.0000\n","Epoch 8/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9379.6846 - mean_squared_error: 145301392.0000 - val_loss: 7924.1021 - val_mean_squared_error: 82264104.0000\n","Epoch 9/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7742.9102 - mean_squared_error: 113119304.0000 - val_loss: 8467.7607 - val_mean_squared_error: 84949496.0000\n","Epoch 10/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7685.0293 - mean_squared_error: 108458792.0000 - val_loss: 5292.1089 - val_mean_squared_error: 41827820.0000\n","Epoch 11/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7178.8237 - mean_squared_error: 99128992.0000 - val_loss: 5346.3359 - val_mean_squared_error: 38580280.0000\n","Epoch 12/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7372.8594 - mean_squared_error: 109557760.0000 - val_loss: 8578.5322 - val_mean_squared_error: 98813688.0000\n","Epoch 13/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7788.7051 - mean_squared_error: 111496728.0000 - val_loss: 6454.5063 - val_mean_squared_error: 49119820.0000\n","Epoch 14/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7071.4790 - mean_squared_error: 96952200.0000 - val_loss: 5153.2964 - val_mean_squared_error: 45968576.0000\n","Epoch 15/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7380.1528 - mean_squared_error: 100247368.0000 - val_loss: 5781.8633 - val_mean_squared_error: 45224464.0000\n","Epoch 16/50\n","96/96 [==============================] - 0s 3ms/step - loss: 6832.4585 - mean_squared_error: 88374552.0000 - val_loss: 8104.6504 - val_mean_squared_error: 84675904.0000\n","Epoch 17/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7098.1724 - mean_squared_error: 103685624.0000 - val_loss: 4904.0044 - val_mean_squared_error: 35072284.0000\n","Epoch 18/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7601.6206 - mean_squared_error: 98745592.0000 - val_loss: 4774.6655 - val_mean_squared_error: 34488992.0000\n","Epoch 19/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7110.9902 - mean_squared_error: 91726528.0000 - val_loss: 6738.8159 - val_mean_squared_error: 59593260.0000\n","Epoch 20/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7245.4370 - mean_squared_error: 101470600.0000 - val_loss: 6389.0142 - val_mean_squared_error: 49017456.0000\n","Epoch 21/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7884.5137 - mean_squared_error: 114832224.0000 - val_loss: 12432.9658 - val_mean_squared_error: 181767616.0000\n","Epoch 22/50\n","96/96 [==============================] - 0s 3ms/step - loss: 6624.7051 - mean_squared_error: 96811624.0000 - val_loss: 7565.0728 - val_mean_squared_error: 72484792.0000\n","Epoch 23/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7439.5044 - mean_squared_error: 105784864.0000 - val_loss: 10889.0117 - val_mean_squared_error: 137134192.0000\n","Epoch 24/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8938.3018 - mean_squared_error: 145014864.0000 - val_loss: 5233.2930 - val_mean_squared_error: 54312576.0000\n","Epoch 25/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8193.9463 - mean_squared_error: 106416088.0000 - val_loss: 8698.6787 - val_mean_squared_error: 101897152.0000\n","Epoch 26/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7527.8145 - mean_squared_error: 114245848.0000 - val_loss: 11057.8955 - val_mean_squared_error: 177462704.0000\n","Epoch 27/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7836.8579 - mean_squared_error: 106160512.0000 - val_loss: 6086.8145 - val_mean_squared_error: 51039404.0000\n","Epoch 28/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8155.4766 - mean_squared_error: 126197752.0000 - val_loss: 7961.2905 - val_mean_squared_error: 78581872.0000\n","Epoch 29/50\n","96/96 [==============================] - 0s 3ms/step - loss: 6746.2896 - mean_squared_error: 85838544.0000 - val_loss: 6996.5962 - val_mean_squared_error: 62402868.0000\n","Epoch 30/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7375.3203 - mean_squared_error: 97069760.0000 - val_loss: 7146.2622 - val_mean_squared_error: 60647648.0000\n","Epoch 31/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8352.5273 - mean_squared_error: 127629760.0000 - val_loss: 7165.8906 - val_mean_squared_error: 65788236.0000\n","Epoch 32/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7394.3359 - mean_squared_error: 104603136.0000 - val_loss: 12460.5977 - val_mean_squared_error: 195707824.0000\n","Epoch 33/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9624.8066 - mean_squared_error: 189802176.0000 - val_loss: 6472.6636 - val_mean_squared_error: 52731920.0000\n","Epoch 34/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9651.6826 - mean_squared_error: 151039824.0000 - val_loss: 9480.6250 - val_mean_squared_error: 122099544.0000\n","Epoch 35/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9679.1602 - mean_squared_error: 158434896.0000 - val_loss: 8946.5752 - val_mean_squared_error: 103210432.0000\n","Epoch 36/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8036.7163 - mean_squared_error: 123886792.0000 - val_loss: 16717.6973 - val_mean_squared_error: 360523520.0000\n","Epoch 37/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7541.5405 - mean_squared_error: 105057576.0000 - val_loss: 6369.9434 - val_mean_squared_error: 53455312.0000\n","Epoch 38/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7293.1187 - mean_squared_error: 102805728.0000 - val_loss: 5570.3149 - val_mean_squared_error: 47246612.0000\n","Epoch 39/50\n","96/96 [==============================] - 0s 3ms/step - loss: 9818.1064 - mean_squared_error: 172816448.0000 - val_loss: 17396.7188 - val_mean_squared_error: 437162528.0000\n","Epoch 40/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8836.3018 - mean_squared_error: 147474464.0000 - val_loss: 4490.6162 - val_mean_squared_error: 43580972.0000\n","Epoch 41/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7942.1030 - mean_squared_error: 128054088.0000 - val_loss: 5946.9468 - val_mean_squared_error: 43075236.0000\n","Epoch 42/50\n","96/96 [==============================] - 0s 3ms/step - loss: 10059.4336 - mean_squared_error: 153889968.0000 - val_loss: 13785.9570 - val_mean_squared_error: 248476624.0000\n","Epoch 43/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7513.0474 - mean_squared_error: 108328872.0000 - val_loss: 10774.6172 - val_mean_squared_error: 147428272.0000\n","Epoch 44/50\n","96/96 [==============================] - 0s 3ms/step - loss: 6644.8906 - mean_squared_error: 97083360.0000 - val_loss: 4687.3638 - val_mean_squared_error: 40881688.0000\n","Epoch 45/50\n","96/96 [==============================] - 0s 3ms/step - loss: 8241.8848 - mean_squared_error: 126433816.0000 - val_loss: 5551.2896 - val_mean_squared_error: 43065936.0000\n","Epoch 46/50\n","96/96 [==============================] - 0s 3ms/step - loss: 6918.8677 - mean_squared_error: 98123456.0000 - val_loss: 6028.0371 - val_mean_squared_error: 46447492.0000\n","Epoch 47/50\n","96/96 [==============================] - 0s 3ms/step - loss: 6345.8516 - mean_squared_error: 87553784.0000 - val_loss: 5286.0591 - val_mean_squared_error: 42197916.0000\n","Epoch 48/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7258.4434 - mean_squared_error: 104009000.0000 - val_loss: 5759.5083 - val_mean_squared_error: 40825948.0000\n","Epoch 49/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7480.4199 - mean_squared_error: 109854216.0000 - val_loss: 8611.8057 - val_mean_squared_error: 98918208.0000\n","Epoch 50/50\n","96/96 [==============================] - 0s 3ms/step - loss: 7104.2827 - mean_squared_error: 102216864.0000 - val_loss: 8227.5068 - val_mean_squared_error: 82024608.0000\n","WARNING:tensorflow:Layer lstm_36 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_37 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_38 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_39 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_23\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_36 (LSTM)               (None, 10, 1024)          4202496   \n","_________________________________________________________________\n","lstm_37 (LSTM)               (None, 10, 512)           3147776   \n","_________________________________________________________________\n","dropout_36 (Dropout)         (None, 10, 512)           0         \n","_________________________________________________________________\n","lstm_38 (LSTM)               (None, 10, 256)           787456    \n","_________________________________________________________________\n","dropout_37 (Dropout)         (None, 10, 256)           0         \n","_________________________________________________________________\n","lstm_39 (LSTM)               (None, 10, 128)           197120    \n","_________________________________________________________________\n","dropout_38 (Dropout)         (None, 10, 128)           0         \n","_________________________________________________________________\n","dense_175 (Dense)            (None, 10, 1024)          132096    \n","_________________________________________________________________\n","dense_176 (Dense)            (None, 10, 512)           524800    \n","_________________________________________________________________\n","dense_177 (Dense)            (None, 10, 256)           131328    \n","_________________________________________________________________\n","dense_178 (Dense)            (None, 10, 128)           32896     \n","_________________________________________________________________\n","dropout_39 (Dropout)         (None, 10, 128)           0         \n","_________________________________________________________________\n","dense_179 (Dense)            (None, 10, 64)            8256      \n","_________________________________________________________________\n","dense_180 (Dense)            (None, 10, 16)            1040      \n","_________________________________________________________________\n","flatten_23 (Flatten)         (None, 160)               0         \n","_________________________________________________________________\n","dense_181 (Dense)            (None, 1)                 161       \n","=================================================================\n","Total params: 9,165,425\n","Trainable params: 9,165,425\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 7s 43ms/step - loss: 25546.8984 - mean_squared_error: 1760945664.0000 - val_loss: 9663.9639 - val_mean_squared_error: 150186928.0000\n","Epoch 2/50\n","96/96 [==============================] - 4s 37ms/step - loss: 17603.0410 - mean_squared_error: 547561024.0000 - val_loss: 18142.0410 - val_mean_squared_error: 480223392.0000\n","Epoch 3/50\n","96/96 [==============================] - 4s 38ms/step - loss: 13766.1924 - mean_squared_error: 311254848.0000 - val_loss: 8780.0176 - val_mean_squared_error: 90762168.0000\n","Epoch 4/50\n","96/96 [==============================] - 4s 37ms/step - loss: 14399.8174 - mean_squared_error: 430053664.0000 - val_loss: 14322.3828 - val_mean_squared_error: 239045312.0000\n","Epoch 5/50\n","96/96 [==============================] - 3s 36ms/step - loss: 15203.3701 - mean_squared_error: 432689536.0000 - val_loss: 7245.4272 - val_mean_squared_error: 86745200.0000\n","Epoch 6/50\n","96/96 [==============================] - 4s 37ms/step - loss: 15282.0430 - mean_squared_error: 419709472.0000 - val_loss: 8592.6377 - val_mean_squared_error: 87975880.0000\n","Epoch 7/50\n","96/96 [==============================] - 4s 36ms/step - loss: 12926.6064 - mean_squared_error: 276498464.0000 - val_loss: 11289.0127 - val_mean_squared_error: 160765712.0000\n","Epoch 8/50\n","96/96 [==============================] - 3s 36ms/step - loss: 13617.1455 - mean_squared_error: 295583968.0000 - val_loss: 6753.9517 - val_mean_squared_error: 75216688.0000\n","Epoch 9/50\n","96/96 [==============================] - 4s 37ms/step - loss: 14055.7627 - mean_squared_error: 333051712.0000 - val_loss: 10142.1152 - val_mean_squared_error: 143361440.0000\n","Epoch 10/50\n","96/96 [==============================] - 4s 37ms/step - loss: 15171.9365 - mean_squared_error: 422874912.0000 - val_loss: 11981.4893 - val_mean_squared_error: 177363792.0000\n","Epoch 11/50\n","96/96 [==============================] - 4s 39ms/step - loss: 13636.9648 - mean_squared_error: 313175968.0000 - val_loss: 8185.4009 - val_mean_squared_error: 85251608.0000\n","Epoch 12/50\n","96/96 [==============================] - 4s 40ms/step - loss: 15902.6396 - mean_squared_error: 424093056.0000 - val_loss: 7743.6147 - val_mean_squared_error: 104350472.0000\n","Epoch 13/50\n","96/96 [==============================] - 4s 40ms/step - loss: 16008.0039 - mean_squared_error: 447686752.0000 - val_loss: 17020.0723 - val_mean_squared_error: 322816256.0000\n","Epoch 14/50\n","96/96 [==============================] - 4s 39ms/step - loss: 17353.3340 - mean_squared_error: 543294848.0000 - val_loss: 13247.9570 - val_mean_squared_error: 211510480.0000\n","Epoch 15/50\n","96/96 [==============================] - 4s 39ms/step - loss: 19203.6621 - mean_squared_error: 549891840.0000 - val_loss: 5816.9653 - val_mean_squared_error: 45537116.0000\n","Epoch 16/50\n","96/96 [==============================] - 4s 39ms/step - loss: 13791.7812 - mean_squared_error: 362904736.0000 - val_loss: 4984.4746 - val_mean_squared_error: 35518060.0000\n","Epoch 17/50\n","96/96 [==============================] - 4s 39ms/step - loss: 12882.4775 - mean_squared_error: 274092544.0000 - val_loss: 10396.7256 - val_mean_squared_error: 146860256.0000\n","Epoch 18/50\n","96/96 [==============================] - 4s 37ms/step - loss: 12157.1846 - mean_squared_error: 254997392.0000 - val_loss: 9457.2803 - val_mean_squared_error: 122614504.0000\n","Epoch 19/50\n","96/96 [==============================] - 3s 36ms/step - loss: 8770.5420 - mean_squared_error: 128450336.0000 - val_loss: 4997.8408 - val_mean_squared_error: 35295936.0000\n","Epoch 20/50\n","96/96 [==============================] - 4s 37ms/step - loss: 10078.2861 - mean_squared_error: 179811584.0000 - val_loss: 11814.4248 - val_mean_squared_error: 173364912.0000\n","Epoch 21/50\n","96/96 [==============================] - 4s 37ms/step - loss: 8957.3652 - mean_squared_error: 139663280.0000 - val_loss: 5166.3369 - val_mean_squared_error: 47671920.0000\n","Epoch 22/50\n","96/96 [==============================] - 3s 36ms/step - loss: 11600.4678 - mean_squared_error: 227981008.0000 - val_loss: 7450.8833 - val_mean_squared_error: 71237000.0000\n","Epoch 23/50\n","96/96 [==============================] - 4s 38ms/step - loss: 11626.4385 - mean_squared_error: 233480896.0000 - val_loss: 9899.2734 - val_mean_squared_error: 115760760.0000\n","Epoch 24/50\n","96/96 [==============================] - 4s 37ms/step - loss: 20669.5566 - mean_squared_error: 1062933504.0000 - val_loss: 14252.0127 - val_mean_squared_error: 238044416.0000\n","Epoch 25/50\n","96/96 [==============================] - 3s 36ms/step - loss: 15569.3438 - mean_squared_error: 436534656.0000 - val_loss: 10620.4248 - val_mean_squared_error: 149723216.0000\n","Epoch 26/50\n","96/96 [==============================] - 4s 37ms/step - loss: 17513.6426 - mean_squared_error: 447702176.0000 - val_loss: 19652.2246 - val_mean_squared_error: 483295648.0000\n","Epoch 27/50\n","96/96 [==============================] - 4s 37ms/step - loss: 12182.6797 - mean_squared_error: 235321488.0000 - val_loss: 6326.8608 - val_mean_squared_error: 50602800.0000\n","Epoch 28/50\n","96/96 [==============================] - 4s 37ms/step - loss: 14645.2744 - mean_squared_error: 358231936.0000 - val_loss: 9893.2959 - val_mean_squared_error: 135497680.0000\n","Epoch 29/50\n","96/96 [==============================] - 4s 40ms/step - loss: 17911.9375 - mean_squared_error: 462540800.0000 - val_loss: 4924.8320 - val_mean_squared_error: 48694684.0000\n","Epoch 30/50\n","96/96 [==============================] - 4s 40ms/step - loss: 14691.6182 - mean_squared_error: 338587296.0000 - val_loss: 4682.7559 - val_mean_squared_error: 44209212.0000\n","Epoch 31/50\n","96/96 [==============================] - 4s 40ms/step - loss: 13022.9385 - mean_squared_error: 294619424.0000 - val_loss: 9390.4990 - val_mean_squared_error: 123259832.0000\n","Epoch 32/50\n","96/96 [==============================] - 4s 39ms/step - loss: 10065.3838 - mean_squared_error: 171853648.0000 - val_loss: 12397.0498 - val_mean_squared_error: 186915504.0000\n","Epoch 33/50\n","96/96 [==============================] - 4s 39ms/step - loss: 11145.2119 - mean_squared_error: 207864432.0000 - val_loss: 6140.5601 - val_mean_squared_error: 50275872.0000\n","Epoch 34/50\n","96/96 [==============================] - 4s 39ms/step - loss: 7619.9487 - mean_squared_error: 121287384.0000 - val_loss: 5004.6016 - val_mean_squared_error: 36211424.0000\n","Epoch 35/50\n","96/96 [==============================] - 4s 39ms/step - loss: 6411.7446 - mean_squared_error: 88456136.0000 - val_loss: 7380.1523 - val_mean_squared_error: 69087552.0000\n","Epoch 36/50\n","96/96 [==============================] - 4s 37ms/step - loss: 6358.3711 - mean_squared_error: 88345912.0000 - val_loss: 4326.6719 - val_mean_squared_error: 34297100.0000\n","Epoch 37/50\n","96/96 [==============================] - 4s 37ms/step - loss: 6910.2358 - mean_squared_error: 93104000.0000 - val_loss: 4634.6572 - val_mean_squared_error: 33591188.0000\n","Epoch 38/50\n","96/96 [==============================] - 4s 39ms/step - loss: 6706.9121 - mean_squared_error: 97075928.0000 - val_loss: 10720.7666 - val_mean_squared_error: 134635568.0000\n","Epoch 39/50\n","96/96 [==============================] - 4s 40ms/step - loss: 6574.2969 - mean_squared_error: 91306176.0000 - val_loss: 9194.2158 - val_mean_squared_error: 120518584.0000\n","Epoch 40/50\n","96/96 [==============================] - 4s 39ms/step - loss: 7017.1035 - mean_squared_error: 91682808.0000 - val_loss: 5056.3384 - val_mean_squared_error: 36766380.0000\n","Epoch 41/50\n","96/96 [==============================] - 4s 39ms/step - loss: 7298.8931 - mean_squared_error: 108477576.0000 - val_loss: 5226.6890 - val_mean_squared_error: 38620732.0000\n","Epoch 42/50\n","96/96 [==============================] - 4s 40ms/step - loss: 6509.8228 - mean_squared_error: 92815040.0000 - val_loss: 4301.8130 - val_mean_squared_error: 35000464.0000\n","Epoch 43/50\n","96/96 [==============================] - 4s 39ms/step - loss: 6490.9766 - mean_squared_error: 90521704.0000 - val_loss: 6738.9116 - val_mean_squared_error: 58736404.0000\n","Epoch 44/50\n","96/96 [==============================] - 4s 38ms/step - loss: 6712.8218 - mean_squared_error: 82552528.0000 - val_loss: 4525.3320 - val_mean_squared_error: 33306168.0000\n","Epoch 45/50\n","96/96 [==============================] - 4s 37ms/step - loss: 7260.3228 - mean_squared_error: 107086464.0000 - val_loss: 6496.0962 - val_mean_squared_error: 54765648.0000\n","Epoch 46/50\n","96/96 [==============================] - 4s 37ms/step - loss: 6721.1831 - mean_squared_error: 96966880.0000 - val_loss: 4377.2593 - val_mean_squared_error: 33165622.0000\n","Epoch 47/50\n","96/96 [==============================] - 3s 36ms/step - loss: 6516.4067 - mean_squared_error: 93310072.0000 - val_loss: 5728.0024 - val_mean_squared_error: 43902688.0000\n","Epoch 48/50\n","96/96 [==============================] - 4s 37ms/step - loss: 6376.8892 - mean_squared_error: 82667192.0000 - val_loss: 5968.6030 - val_mean_squared_error: 46751276.0000\n","Epoch 49/50\n","96/96 [==============================] - 4s 37ms/step - loss: 6405.1172 - mean_squared_error: 83490184.0000 - val_loss: 4914.4062 - val_mean_squared_error: 34743100.0000\n","Epoch 50/50\n","96/96 [==============================] - 4s 38ms/step - loss: 6102.5288 - mean_squared_error: 83381320.0000 - val_loss: 6492.1831 - val_mean_squared_error: 54481700.0000\n","                              rmse smape\n","ChangDeokGung                  NaN   NaN\n","ChangGyeongGung                NaN   NaN\n","DuckSooGung                    NaN   NaN\n","GyeongBokGung                  NaN   NaN\n","HeonLeungInReung               NaN   NaN\n","JongMyo                        NaN   NaN\n","SeoDaeMunNaturalHistoryMuseum  NaN   NaN\n","SeoulMuseumOfArt               NaN   NaN\n","SunReungJungReung              NaN   NaN\n","TaeReungGangNeung              NaN   NaN\n","TrickEyeMuseum                 NaN   NaN\n","SeoDaeMunPrisonHistoryMuseum   NaN   NaN\n","NamSanGolHanOkVillage          NaN   NaN\n","NationalMuseumOfKorea          NaN   NaN\n","------------------------- LSTM ---------------------------------------------\n","Model: \"sequential_24\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_182 (Dense)            (None, 1024)              8192      \n","_________________________________________________________________\n","dense_183 (Dense)            (None, 512)               524800    \n","_________________________________________________________________\n","dense_184 (Dense)            (None, 256)               131328    \n","_________________________________________________________________\n","dense_185 (Dense)            (None, 128)               32896     \n","_________________________________________________________________\n","dense_186 (Dense)            (None, 64)                8256      \n","_________________________________________________________________\n","dense_187 (Dense)            (None, 32)                2080      \n","_________________________________________________________________\n","dense_188 (Dense)            (None, 16)                528       \n","_________________________________________________________________\n","flatten_24 (Flatten)         (None, 16)                0         \n","_________________________________________________________________\n","dense_189 (Dense)            (None, 1)                 17        \n","=================================================================\n","Total params: 708,097\n","Trainable params: 708,097\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/50\n","96/96 [==============================] - 1s 9ms/step - loss: 76340.7344 - mean_squared_error: 9845496832.0000 - val_loss: 52197.6406 - val_mean_squared_error: 6484697600.0000\n","Epoch 2/50\n","96/96 [==============================] - 0s 3ms/step - loss: 59829.4648 - mean_squared_error: 5922993664.0000 - val_loss: 64831.1875 - val_mean_squared_error: 8846118912.0000\n","Epoch 3/50\n","96/96 [==============================] - 0s 3ms/step - loss: 62638.9023 - mean_squared_error: 6832074752.0000 - val_loss: 56380.4062 - val_mean_squared_error: 5336219136.0000\n","Epoch 4/50\n","96/96 [==============================] - 0s 3ms/step - loss: 52835.7461 - mean_squared_error: 5292973568.0000 - val_loss: 50840.2461 - val_mean_squared_error: 5713150464.0000\n","Epoch 5/50\n","96/96 [==============================] - 0s 3ms/step - loss: 49111.6523 - mean_squared_error: 4534891008.0000 - val_loss: 80626.6641 - val_mean_squared_error: 11452832768.0000\n","Epoch 6/50\n","96/96 [==============================] - 0s 3ms/step - loss: 50576.4219 - mean_squared_error: 4854750720.0000 - val_loss: 79144.4141 - val_mean_squared_error: 11177661440.0000\n","Epoch 7/50\n","96/96 [==============================] - 0s 3ms/step - loss: 48666.7695 - mean_squared_error: 4619278336.0000 - val_loss: 85403.2891 - val_mean_squared_error: 12382612480.0000\n","Epoch 8/50\n","96/96 [==============================] - 0s 3ms/step - loss: 48548.2383 - mean_squared_error: 4273330176.0000 - val_loss: 87831.7422 - val_mean_squared_error: 12880514048.0000\n","Epoch 9/50\n","96/96 [==============================] - 0s 3ms/step - loss: 48000.8867 - mean_squared_error: 4805226496.0000 - val_loss: 84009.0859 - val_mean_squared_error: 12104437760.0000\n","Epoch 10/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47578.6836 - mean_squared_error: 4230798592.0000 - val_loss: 71590.3359 - val_mean_squared_error: 9873615872.0000\n","Epoch 11/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46634.8867 - mean_squared_error: 4202456832.0000 - val_loss: 81510.2734 - val_mean_squared_error: 11619871744.0000\n","Epoch 12/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46963.6914 - mean_squared_error: 4931573248.0000 - val_loss: 65977.7891 - val_mean_squared_error: 9011147776.0000\n","Epoch 13/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45320.9102 - mean_squared_error: 4351739392.0000 - val_loss: 80447.9688 - val_mean_squared_error: 11419316224.0000\n","Epoch 14/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45712.3867 - mean_squared_error: 4142787328.0000 - val_loss: 84446.1094 - val_mean_squared_error: 12191027200.0000\n","Epoch 15/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46163.8125 - mean_squared_error: 4499353600.0000 - val_loss: 52842.3398 - val_mean_squared_error: 6619803648.0000\n","Epoch 16/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45827.8555 - mean_squared_error: 4729281024.0000 - val_loss: 86088.5000 - val_mean_squared_error: 12521370624.0000\n","Epoch 17/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46644.5000 - mean_squared_error: 4253221888.0000 - val_loss: 93281.6797 - val_mean_squared_error: 14032949248.0000\n","Epoch 18/50\n","96/96 [==============================] - 0s 3ms/step - loss: 48566.1133 - mean_squared_error: 4595034624.0000 - val_loss: 89279.8984 - val_mean_squared_error: 13185500160.0000\n","Epoch 19/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47812.1055 - mean_squared_error: 4811075584.0000 - val_loss: 87509.1875 - val_mean_squared_error: 12813388800.0000\n","Epoch 20/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46678.0312 - mean_squared_error: 4286289152.0000 - val_loss: 81502.3359 - val_mean_squared_error: 11618345984.0000\n","Epoch 21/50\n","96/96 [==============================] - 0s 3ms/step - loss: 49181.9492 - mean_squared_error: 4649164288.0000 - val_loss: 78149.2188 - val_mean_squared_error: 7277185536.0000\n","Epoch 22/50\n","96/96 [==============================] - 0s 3ms/step - loss: 48259.5977 - mean_squared_error: 4817873408.0000 - val_loss: 77362.6641 - val_mean_squared_error: 10855247872.0000\n","Epoch 23/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47187.7969 - mean_squared_error: 4722758144.0000 - val_loss: 67067.3203 - val_mean_squared_error: 9171450880.0000\n","Epoch 24/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46118.8477 - mean_squared_error: 4391180288.0000 - val_loss: 67706.0469 - val_mean_squared_error: 9267035136.0000\n","Epoch 25/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46125.2539 - mean_squared_error: 4297777664.0000 - val_loss: 61835.6562 - val_mean_squared_error: 8432792064.0000\n","Epoch 26/50\n","96/96 [==============================] - 0s 3ms/step - loss: 44871.9648 - mean_squared_error: 4208505856.0000 - val_loss: 76390.8438 - val_mean_squared_error: 10683259904.0000\n","Epoch 27/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46415.2188 - mean_squared_error: 4583112192.0000 - val_loss: 74858.4375 - val_mean_squared_error: 10417589248.0000\n","Epoch 28/50\n","96/96 [==============================] - 0s 3ms/step - loss: 51630.8438 - mean_squared_error: 4925378048.0000 - val_loss: 65243.0312 - val_mean_squared_error: 8904924160.0000\n","Epoch 29/50\n","96/96 [==============================] - 0s 3ms/step - loss: 57747.5273 - mean_squared_error: 6160293888.0000 - val_loss: 87122.8984 - val_mean_squared_error: 12733389824.0000\n","Epoch 30/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46775.6133 - mean_squared_error: 4559563776.0000 - val_loss: 66747.6016 - val_mean_squared_error: 9124031488.0000\n","Epoch 31/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46206.7852 - mean_squared_error: 4174952192.0000 - val_loss: 78155.6328 - val_mean_squared_error: 10997580800.0000\n","Epoch 32/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45384.2031 - mean_squared_error: 4388095488.0000 - val_loss: 73433.3984 - val_mean_squared_error: 10176579584.0000\n","Epoch 33/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46321.7031 - mean_squared_error: 4240275712.0000 - val_loss: 94503.8516 - val_mean_squared_error: 14262424576.0000\n","Epoch 34/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45663.2539 - mean_squared_error: 4404850688.0000 - val_loss: 62740.7695 - val_mean_squared_error: 8554928128.0000\n","Epoch 35/50\n","96/96 [==============================] - 0s 3ms/step - loss: 44821.8008 - mean_squared_error: 4323090944.0000 - val_loss: 93275.8984 - val_mean_squared_error: 14031840256.0000\n","Epoch 36/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47251.4180 - mean_squared_error: 4388139520.0000 - val_loss: 89301.7734 - val_mean_squared_error: 13190128640.0000\n","Epoch 37/50\n","96/96 [==============================] - 0s 3ms/step - loss: 44584.1523 - mean_squared_error: 4409861632.0000 - val_loss: 55224.5977 - val_mean_squared_error: 7183943680.0000\n","Epoch 38/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46266.8164 - mean_squared_error: 4700741120.0000 - val_loss: 53123.0039 - val_mean_squared_error: 6680965632.0000\n","Epoch 39/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45928.3633 - mean_squared_error: 4195676928.0000 - val_loss: 85643.9297 - val_mean_squared_error: 12431156224.0000\n","Epoch 40/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47994.8867 - mean_squared_error: 4914165248.0000 - val_loss: 52565.0938 - val_mean_squared_error: 5415758848.0000\n","Epoch 41/50\n","96/96 [==============================] - 0s 3ms/step - loss: 48385.9805 - mean_squared_error: 4475116032.0000 - val_loss: 70794.2812 - val_mean_squared_error: 9745718272.0000\n","Epoch 42/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46389.9492 - mean_squared_error: 4599560192.0000 - val_loss: 82250.3984 - val_mean_squared_error: 11761476608.0000\n","Epoch 43/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45972.9531 - mean_squared_error: 4448907776.0000 - val_loss: 61914.6367 - val_mean_squared_error: 8443328512.0000\n","Epoch 44/50\n","96/96 [==============================] - 0s 3ms/step - loss: 50985.5938 - mean_squared_error: 4667835904.0000 - val_loss: 54756.7852 - val_mean_squared_error: 5334445568.0000\n","Epoch 45/50\n","96/96 [==============================] - 0s 3ms/step - loss: 50763.2539 - mean_squared_error: 4952048128.0000 - val_loss: 81309.6484 - val_mean_squared_error: 11581688832.0000\n","Epoch 46/50\n","96/96 [==============================] - 0s 3ms/step - loss: 46650.3320 - mean_squared_error: 4610278400.0000 - val_loss: 58514.8477 - val_mean_squared_error: 7821861376.0000\n","Epoch 47/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47492.9102 - mean_squared_error: 4314255872.0000 - val_loss: 54665.0742 - val_mean_squared_error: 7042277888.0000\n","Epoch 48/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45944.2617 - mean_squared_error: 4374413312.0000 - val_loss: 53597.6250 - val_mean_squared_error: 6787614720.0000\n","Epoch 49/50\n","96/96 [==============================] - 0s 3ms/step - loss: 45963.4727 - mean_squared_error: 4206090240.0000 - val_loss: 79802.3125 - val_mean_squared_error: 11298958336.0000\n","Epoch 50/50\n","96/96 [==============================] - 0s 3ms/step - loss: 47186.4688 - mean_squared_error: 4398694912.0000 - val_loss: 92386.3828 - val_mean_squared_error: 13860101120.0000\n","WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-140-0ce5f6933f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeep_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-139-8511b7782878>\u001b[0m in \u001b[0;36mfinal_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0;31m# 위의 함수들을 전부 불러온다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0mcnn_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_smape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m       \u001b[0mlstm_rmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_smape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeep_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;31m# 저장할 공간을 만들어서 데이터 프레임으로 만들어 주자.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-139-8511b7782878>\u001b[0m in \u001b[0;36mlstm\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 970\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1106\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1108\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    876\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2625\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2626\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2367\u001b[0;31m         caching_device=default_caching_device)\n\u001b[0m\u001b[1;32m   2368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    656\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    137\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2624\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2626\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2627\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m     return variables.RefVariable(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1593\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m   def _init_from_args(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1720\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;31m# Compute the qr factorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_linalg_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m     \u001b[0;31m# Make Q uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_diag_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36mqr\u001b[0;34m(input, full_matrices, name)\u001b[0m\n\u001b[1;32m   2066\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 2068\u001b[0;31m         _ctx, \"Qr\", name, input, \"full_matrices\", full_matrices)\n\u001b[0m\u001b[1;32m   2069\u001b[0m       \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_QrOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"91BkUI3yqhdX"},"source":["y_pred = model.predict(X_test_t)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oM5kwCoProCV","executionInfo":{"status":"ok","timestamp":1626746653035,"user_tz":-540,"elapsed":10,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"daa482a1-e0af-4cd4-cbf1-66d412e7320d"},"source":["modeling.rmse(y_test, y_pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["77832.86031008865"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"Ql600rs8ro1e"},"source":["y_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"spHiNjq1YnEt"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2m-LIzqNsCWd"},"source":["data = pd.read_csv('/content/drive/MyDrive/Proj_WT/DataSets/박정열/DuckSooGung.csv')\n","minmax = pd.read_csv('/content/drive/MyDrive/sd솔데스크/팀 프로젝트/DuckSooGung_minmax.csv')\n","robust = pd.read_csv('/content/drive/MyDrive/sd솔데스크/팀 프로젝트/DuckSooGung_robust.csv')\n","standard = pd.read_csv('/content/drive/MyDrive/sd솔데스크/팀 프로젝트/DuckSooGung_standard.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-u7EJKQ8lGM"},"source":["final_model.run(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1E2TtMX9b8P"},"source":["final_model.run(minmax)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UzujvtyC9jq_"},"source":["final_model.run(robust)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gG2yU1KM9nke"},"source":["final_model.run(standard)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jh1zabyiqGV4"},"source":["# 덕수궁"]},{"cell_type":"code","metadata":{"id":"LOlGlxQ89r7K"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","data = pd.read_csv('/content/drive/MyDrive/Proj_WT/DataSets/Seoul/DuckSooGung.csv')\n","data = data.rename(columns = {'덕수궁': 'target'})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inYgxkFnqbSA","executionInfo":{"status":"ok","timestamp":1626797842578,"user_tz":-540,"elapsed":460,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"a7db5868-5125-4f25-d7b7-753da9d0eae2"},"source":["class_all_model.run(data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[16:17:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["({'ada': 224585.722496841,\n","  'gb': 77063.6067796669,\n","  'lasso': 70501.39790144832,\n","  'lgb': 51185.51714162037,\n","  'lr': 74242.29232787085,\n","  'rfg': 141060.59677013435,\n","  'ridge': 71322.55389608078,\n","  'xgb': 183519.7032949889},\n"," {'ada': -14.730353456857591,\n","  'gb': -0.8521359293379394,\n","  'lasso': -0.5501354584667435,\n","  'lgb': 0.18291284173092925,\n","  'lr': -0.7190042077287433,\n","  'rfg': -5.2056264248762165,\n","  'ridge': -0.5864557598997424,\n","  'xgb': -9.50363425623923},\n"," {'ada': AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n","                    n_estimators=50, random_state=42),\n","  'gb': GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n","                            init=None, learning_rate=0.1, loss='ls', max_depth=3,\n","                            max_features=None, max_leaf_nodes=None,\n","                            min_impurity_decrease=0.0, min_impurity_split=None,\n","                            min_samples_leaf=1, min_samples_split=2,\n","                            min_weight_fraction_leaf=0.0, n_estimators=100,\n","                            n_iter_no_change=None, presort='deprecated',\n","                            random_state=42, subsample=1.0, tol=0.0001,\n","                            validation_fraction=0.1, verbose=0, warm_start=False),\n","  'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n","        normalize=False, positive=False, precompute=False, random_state=None,\n","        selection='cyclic', tol=0.0001, warm_start=False),\n","  'lgb': LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n","                importance_type='split', learning_rate=0.1, max_depth=-1,\n","                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n","                n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n","                random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n","                subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n","  'lr': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n","  'rfg': RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n","                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                        max_samples=None, min_impurity_decrease=0.0,\n","                        min_impurity_split=None, min_samples_leaf=1,\n","                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n","                        n_estimators=100, n_jobs=None, oob_score=False,\n","                        random_state=42, verbose=0, warm_start=False),\n","  'ridge': Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n","        normalize=False, random_state=42, solver='auto', tol=0.001),\n","  'xgb': XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","               colsample_bynode=1, colsample_bytree=1, gamma=0,\n","               importance_type='gain', learning_rate=0.1, max_delta_step=0,\n","               max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n","               n_jobs=1, nthread=None, objective='reg:linear', random_state=42,\n","               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n","               silent=None, subsample=1, tree_method='gpu_hist', verbosity=1)})"]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBr3goPqil1u","executionInfo":{"status":"ok","timestamp":1626797845909,"user_tz":-540,"elapsed":3335,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"972ccd46-78b4-4b75-b4c1-d10d6995fb39"},"source":["!pip install smogn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: smogn in /usr/local/lib/python3.7/dist-packages (0.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from smogn) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from smogn) (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from smogn) (4.41.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->smogn) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->smogn) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->smogn) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qf3EFjCDhq_6"},"source":["import smogn\n","\n","train = data[data['date'] < 201901]\n","test = data[data['date'] >= 201901]\n","train = train.drop(['month','date'], axis = 1)\n","test = test.drop(['month','date'], axis = 1)\n","X_train ,y_train = train.drop('target', axis = 1), train['target']\n","X_test, y_test = test.drop('target', axis = 1), test['target']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrYW5L-q54LD","executionInfo":{"status":"ok","timestamp":1626797848228,"user_tz":-540,"elapsed":561,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"9d096c21-8b06-43f9-bdae-6f074a7a8f82"},"source":["models = class_all_model.models()\n","\n","model_rmse = {}\n","model_score = {}\n","for i, j in models.items():\n","  # 각 모델의 y_pred를 구한다.\n","  model = j\n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  \n","  # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","  model_rmse[i] = mean_squared_error(y_test, y_pred)** 0.5\n","  model_score[i] = model.score(X_test, y_test)\n","  \n","print('model_rmse :', model_rmse)\n","print('model_score :', model_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[16:17:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","model_rmse : {'lr': 74160.00019264375, 'lgb': 61057.23322236646, 'xgb': 66278.76019361427, 'lasso': 75045.11085195819, 'ridge': 74389.146065587, 'ada': 74795.60547318045, 'rfg': 65733.30726960927, 'gb': 70187.26446845564}\n","model_score : {'lr': -0.8250846109029204, 'lgb': -0.23713701109674679, 'xgb': -0.4577810837277827, 'lasso': -0.8689099040519177, 'ridge': -0.8363806388590809, 'ada': -0.856503288875875, 'rfg': -0.43388567488821095, 'gb': -0.6347832943427236}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oSreAdLYiidk","executionInfo":{"status":"ok","timestamp":1626797923729,"user_tz":-540,"elapsed":994,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"e75a57c7-1012-4d3d-d8b1-f8fc6b213a04"},"source":["## SMOTE를 사용해서 해주기\n","덕수궁_data = smogn.smoter(data = train, y = 'target', k = 10, samp_method = 'extreme', rel_thres = 0.70, rel_method = 'auto', rel_xtrm_type = 'high', rel_coef = 3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dist_matrix: 100%|##########| 7/7 [00:00<00:00, 193.08it/s]\n","synth_matrix: 100%|##########| 7/7 [00:00<00:00, 24.46it/s]\n","r_index: 100%|##########| 4/4 [00:00<00:00, 227.80it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"AS3axsjasRQo","executionInfo":{"status":"ok","timestamp":1626797924313,"user_tz":-540,"elapsed":7,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"8228377d-7679-48b7-def6-3f23d3595c7b"},"source":["덕수궁_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>최고 기온(°C)</th>\n","      <th>평균 기온(°C)</th>\n","      <th>최소 상대습도(%)</th>\n","      <th>평균 상대습도(%)</th>\n","      <th>일강수량(mm)</th>\n","      <th>평균 풍속(m/s)</th>\n","      <th>합계 일조 시간(hr)</th>\n","      <th>최대 풍속(m/s)</th>\n","      <th>합계 일사량(MJ/m2)</th>\n","      <th>0.5m 지중온도(°C)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>22.356044</td>\n","      <td>16.585903</td>\n","      <td>32.527937</td>\n","      <td>56.655448</td>\n","      <td>11.966790</td>\n","      <td>2.449521</td>\n","      <td>8.421721</td>\n","      <td>5.266968</td>\n","      <td>16.655951</td>\n","      <td>17.018869</td>\n","      <td>163876</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25.630284</td>\n","      <td>19.497720</td>\n","      <td>31.241502</td>\n","      <td>56.216743</td>\n","      <td>14.567704</td>\n","      <td>2.379419</td>\n","      <td>9.069953</td>\n","      <td>5.137819</td>\n","      <td>19.165195</td>\n","      <td>18.672576</td>\n","      <td>163122</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25.595532</td>\n","      <td>19.577032</td>\n","      <td>31.298650</td>\n","      <td>56.286808</td>\n","      <td>14.612368</td>\n","      <td>2.364609</td>\n","      <td>9.066910</td>\n","      <td>5.146405</td>\n","      <td>19.232720</td>\n","      <td>18.806395</td>\n","      <td>163450</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>25.845810</td>\n","      <td>19.555478</td>\n","      <td>31.310623</td>\n","      <td>56.209844</td>\n","      <td>14.554236</td>\n","      <td>2.370855</td>\n","      <td>9.052139</td>\n","      <td>5.139776</td>\n","      <td>19.195267</td>\n","      <td>18.735464</td>\n","      <td>164776</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25.756218</td>\n","      <td>19.752679</td>\n","      <td>31.188856</td>\n","      <td>56.279086</td>\n","      <td>14.534488</td>\n","      <td>2.366888</td>\n","      <td>9.057407</td>\n","      <td>5.157907</td>\n","      <td>19.082977</td>\n","      <td>18.686121</td>\n","      <td>158103</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>33.303226</td>\n","      <td>28.761290</td>\n","      <td>45.161290</td>\n","      <td>64.719355</td>\n","      <td>12.662500</td>\n","      <td>1.690323</td>\n","      <td>7.500000</td>\n","      <td>4.006452</td>\n","      <td>16.682581</td>\n","      <td>28.416129</td>\n","      <td>69297</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>26.040000</td>\n","      <td>21.496667</td>\n","      <td>38.900000</td>\n","      <td>60.660000</td>\n","      <td>5.708333</td>\n","      <td>1.563333</td>\n","      <td>7.290000</td>\n","      <td>3.450000</td>\n","      <td>15.698667</td>\n","      <td>24.016667</td>\n","      <td>184077</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>18.612903</td>\n","      <td>13.054839</td>\n","      <td>34.354839</td>\n","      <td>59.348387</td>\n","      <td>10.954545</td>\n","      <td>1.545161</td>\n","      <td>7.803226</td>\n","      <td>3.829032</td>\n","      <td>13.010968</td>\n","      <td>17.600000</td>\n","      <td>179495</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>13.153333</td>\n","      <td>7.793333</td>\n","      <td>32.733333</td>\n","      <td>57.480000</td>\n","      <td>8.788889</td>\n","      <td>1.396667</td>\n","      <td>5.920000</td>\n","      <td>3.496667</td>\n","      <td>8.845000</td>\n","      <td>11.693333</td>\n","      <td>141650</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>4.087097</td>\n","      <td>-0.606452</td>\n","      <td>26.483871</td>\n","      <td>45.758065</td>\n","      <td>2.733333</td>\n","      <td>1.803226</td>\n","      <td>6.448387</td>\n","      <td>3.900000</td>\n","      <td>8.181935</td>\n","      <td>5.051613</td>\n","      <td>129213</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>169 rows × 11 columns</p>\n","</div>"],"text/plain":["    최고 기온(°C)  평균 기온(°C)  최소 상대습도(%)  ...  합계 일사량(MJ/m2)  0.5m 지중온도(°C)  target\n","0   22.356044  16.585903   32.527937  ...      16.655951      17.018869  163876\n","1   25.630284  19.497720   31.241502  ...      19.165195      18.672576  163122\n","2   25.595532  19.577032   31.298650  ...      19.232720      18.806395  163450\n","3   25.845810  19.555478   31.310623  ...      19.195267      18.735464  164776\n","4   25.756218  19.752679   31.188856  ...      19.082977      18.686121  158103\n","..        ...        ...         ...  ...            ...            ...     ...\n","91  33.303226  28.761290   45.161290  ...      16.682581      28.416129   69297\n","92  26.040000  21.496667   38.900000  ...      15.698667      24.016667  184077\n","93  18.612903  13.054839   34.354839  ...      13.010968      17.600000  179495\n","94  13.153333   7.793333   32.733333  ...       8.845000      11.693333  141650\n","95   4.087097  -0.606452   26.483871  ...       8.181935       5.051613  129213\n","\n","[169 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52R9Zp95i7XO","executionInfo":{"status":"ok","timestamp":1626797929609,"user_tz":-540,"elapsed":939,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"9852157a-064d-4383-bad8-52413fc8c783"},"source":["X_train , y_train = 덕수궁_data.drop('target', axis = 1), 덕수궁_data['target']\n","\n","models = class_all_model.models()\n","\n","model_rmse = {}\n","model_score = {}\n","for i, j in models.items():\n","  # 각 모델의 y_pred를 구한다.\n","  model = j\n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  \n","  # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","  model_rmse[i] = mean_squared_error(y_test, y_pred)** 0.5\n","  model_score[i] = model.score(X_test, y_test)\n","  \n","print('model_rmse :', model_rmse)\n","print('model_score :', model_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[16:18:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","model_rmse : {'lr': 54944.17555566142, 'lgb': 64415.05119181698, 'xgb': 67445.72865591424, 'lasso': 57706.800975326325, 'ridge': 54773.176520593595, 'ada': 70598.26190525935, 'rfg': 71104.28279485994, 'gb': 70020.03075601942}\n","model_score : {'lr': -0.0018135025668910565, 'lgb': -0.37695031951477387, 'xgb': -0.5095672336619534, 'lasso': -0.10508976751182031, 'ridge': 0.004412546458634314, 'ada': -0.6539850385910821, 'rfg': -0.6777802547207312, 'gb': -0.6270022480211994}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"5nU4EuM_qd37","executionInfo":{"status":"ok","timestamp":1626769881918,"user_tz":-540,"elapsed":829,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"8f0bc03d-69f6-425f-ff50-739893ae5908"},"source":["sns.distplot(data['target'])\n","plt.title('target')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'target')"]},"metadata":{"tags":[]},"execution_count":127},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"O6VYWeIfsN0v","executionInfo":{"status":"ok","timestamp":1626769920870,"user_tz":-540,"elapsed":270,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"0066b497-58ba-4d42-f584-6932857a9673"},"source":["sns.boxenplot(data['target'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f56a5477d50>"]},"metadata":{"tags":[]},"execution_count":133},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YqlsiF6IwjDY","executionInfo":{"status":"ok","timestamp":1626770268581,"user_tz":-540,"elapsed":4563,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"8df183b7-4bc2-46e7-9dcf-c898e9254666"},"source":["!pip install smogn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting smogn\n","  Downloading smogn-0.1.2-py3-none-any.whl (30 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from smogn) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from smogn) (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from smogn) (4.41.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->smogn) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->smogn) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->smogn) (1.15.0)\n","Installing collected packages: smogn\n","Successfully installed smogn-0.1.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GaJm5YljwF3g"},"source":["import smogn\n","덕수궁_data = smogn.smoter(data = data, y = 'target', k = 9, samp_method = 'extreme', rel_thres = 0.70, rel_method = 'auto', rel_xtrm_type = 'high', rel_coef = 3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FYKiW0SwiHs","executionInfo":{"status":"ok","timestamp":1626769929873,"user_tz":-540,"elapsed":235,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"839c95a3-1dcc-487d-c8d6-a1c4f7a35f0a"},"source":["print(덕수궁_data.columns, data.columns)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Index(['date', 'month', '최고 기온(°C)', '평균 기온(°C)', '최소 상대습도(%)', '평균 상대습도(%)',\n","       '일강수량(mm)', '평균 풍속(m/s)', '합계 일조 시간(hr)', '최대 풍속(m/s)', '합계 일사량(MJ/m2)',\n","       '0.5m 지중온도(°C)', 'target'],\n","      dtype='object') Index(['date', 'month', '최고 기온(°C)', '평균 기온(°C)', '최소 상대습도(%)', '평균 상대습도(%)',\n","       '일강수량(mm)', '평균 풍속(m/s)', '합계 일조 시간(hr)', '최대 풍속(m/s)', '합계 일사량(MJ/m2)',\n","       '0.5m 지중온도(°C)', 'target'],\n","      dtype='object')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N66PAM23w1Gp"},"source":["smote_data = 덕수궁_data.drop(['date','month'], axis = 1)\n","data = data.drop(['date','month'], axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3NQDa83zl-j","executionInfo":{"status":"ok","timestamp":1626769940798,"user_tz":-540,"elapsed":908,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"3f0112fd-8219-4903-f718-c340130e8487"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis = 1), data['target'], test_size = 0.2, random_state = 42)\n","models = class_all_model.models()\n","\n","model_rmse = {}\n","model_score = {}\n","for i, j in models.items():\n","  # 각 모델의 y_pred를 구한다.\n","  model = j\n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  \n","  # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","  model_rmse[i] = mean_squared_error(y_test, y_pred)** 0.5\n","  model_score[i] = model.score(X_test, y_test)\n","  \n","print('model_rmse :', model_rmse)\n","print('model_score :', model_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[08:32:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","model_rmse : {'lr': 79300.66804903092, 'lgb': 80968.60870346827, 'xgb': 73455.44681995378, 'lasso': 81249.32036725024, 'ridge': 79933.77961976793, 'ada': 78369.53155930391, 'rfg': 76764.38330608635}\n","model_score : {'lr': 0.26421035309247476, 'lgb': 0.23293293811343685, 'xgb': 0.36868226386151876, 'lasso': 0.2276049985255012, 'ridge': 0.2524148285822103, 'ada': 0.2813879712492471, 'rfg': 0.31052343153634154}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYRcVk6-zx05","executionInfo":{"status":"ok","timestamp":1626769948588,"user_tz":-540,"elapsed":885,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"5bbab85c-aba2-4fe3-af51-ae09e74a56bb"},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(smote_data.drop('target', axis = 1), smote_data['target'], test_size = 0.2, random_state = 42)\n","models = class_all_model.models()\n","\n","model_rmse = {}\n","model_score = {}\n","for i, j in models.items():\n","  # 각 모델의 y_pred를 구한다.\n","  model = j\n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  \n","  # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","  model_rmse[i] = mean_squared_error(y_test, y_pred)** 0.5\n","  model_score[i] = model.score(X_test, y_test)\n","  \n","print('model_rmse :', model_rmse)\n","print('model_score :', model_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[08:32:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","model_rmse : {'lr': 68034.33828752104, 'lgb': 35624.69545478687, 'xgb': 63182.06585008357, 'lasso': 68551.0885325801, 'ridge': 65516.28248361572, 'ada': 37628.51850506677, 'rfg': 47581.73238033091}\n","model_score : {'lr': 0.7619087176564602, 'lgb': 0.9347185962364397, 'xgb': 0.7946594090651985, 'lasso': 0.7582781693535003, 'ridge': 0.7792068185315907, 'ada': 0.9271681396315093, 'rfg': 0.8835424460969743}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":526},"id":"RlPv3EaDz2ST","executionInfo":{"status":"ok","timestamp":1626769957184,"user_tz":-540,"elapsed":823,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"d14c8516-f0c3-47d9-fbc5-7d2ba3b1d0e5"},"source":["# target변수를 분포로 살펴보기\n","fig, ax = plt.subplots(ncols = 2, figsize = (16,8))\n","sns.distplot(smote_data['target'], ax = ax[0])\n","sns.distplot(data['target'], ax = ax[1])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f56a435fa90>"]},"metadata":{"tags":[]},"execution_count":143},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1152x576 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"HMeRJUcVCSSI"},"source":["# 서울시립미술관"]},{"cell_type":"code","metadata":{"id":"RRSMf6Q13lUq"},"source":["import pandas as pd\n","import smogn\n","data = pd.read_csv('/content/drive/MyDrive/Proj_WT/DataSets/Seoul/SeoulMuseumOfArt.csv')\n","data = data.rename(columns = {'서울시립미술관 본관': 'target'})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"-_VLNpGzDZc6","executionInfo":{"status":"ok","timestamp":1626797981329,"user_tz":-540,"elapsed":7,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"52906a72-6d2c-41be-a58e-4faddf707da8"},"source":["data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>month</th>\n","      <th>최고 기온(°C)</th>\n","      <th>평균 기온(°C)</th>\n","      <th>최소 상대습도(%)</th>\n","      <th>평균 상대습도(%)</th>\n","      <th>일강수량(mm)</th>\n","      <th>평균 풍속(m/s)</th>\n","      <th>합계 일조 시간(hr)</th>\n","      <th>최저 기온(°C)</th>\n","      <th>최대 풍속(m/s)</th>\n","      <th>평균 해면기압(hPa)</th>\n","      <th>1시간 최다 일사량(MJ/m2)</th>\n","      <th>최저 초상온도(°C)</th>\n","      <th>평균 5cm 지중온도(°C)</th>\n","      <th>평균 30cm 지중온도(°C)</th>\n","      <th>5.0cm 지중온도(°C)</th>\n","      <th>9-9강수(mm)</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>201101</td>\n","      <td>1</td>\n","      <td>-3.406452</td>\n","      <td>-7.183871</td>\n","      <td>35.129032</td>\n","      <td>53.829032</td>\n","      <td>1.112500</td>\n","      <td>2.796774</td>\n","      <td>7.048387</td>\n","      <td>-10.522581</td>\n","      <td>5.593548</td>\n","      <td>1027.322581</td>\n","      <td>1.791935</td>\n","      <td>-16.083871</td>\n","      <td>-3.261290</td>\n","      <td>-1.077419</td>\n","      <td>17.183871</td>\n","      <td>0.741667</td>\n","      <td>234587</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>201102</td>\n","      <td>2</td>\n","      <td>5.864286</td>\n","      <td>1.221429</td>\n","      <td>32.000000</td>\n","      <td>55.228571</td>\n","      <td>9.700000</td>\n","      <td>2.553571</td>\n","      <td>5.950000</td>\n","      <td>-2.460714</td>\n","      <td>5.239286</td>\n","      <td>1022.085714</td>\n","      <td>1.841786</td>\n","      <td>-9.564286</td>\n","      <td>0.578571</td>\n","      <td>0.350000</td>\n","      <td>15.900000</td>\n","      <td>7.850000</td>\n","      <td>171376</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>201103</td>\n","      <td>3</td>\n","      <td>8.345161</td>\n","      <td>3.616129</td>\n","      <td>25.258065</td>\n","      <td>51.112903</td>\n","      <td>2.085714</td>\n","      <td>3.406452</td>\n","      <td>7.748387</td>\n","      <td>-0.119355</td>\n","      <td>6.877419</td>\n","      <td>1021.383871</td>\n","      <td>2.541290</td>\n","      <td>-5.006452</td>\n","      <td>5.216129</td>\n","      <td>5.422581</td>\n","      <td>14.677419</td>\n","      <td>1.537500</td>\n","      <td>260687</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>201104</td>\n","      <td>4</td>\n","      <td>15.596667</td>\n","      <td>10.720000</td>\n","      <td>28.666667</td>\n","      <td>54.240000</td>\n","      <td>10.009091</td>\n","      <td>3.243333</td>\n","      <td>6.736667</td>\n","      <td>6.773333</td>\n","      <td>6.650000</td>\n","      <td>1014.123333</td>\n","      <td>2.452333</td>\n","      <td>1.116667</td>\n","      <td>12.206667</td>\n","      <td>11.726667</td>\n","      <td>13.470000</td>\n","      <td>7.346667</td>\n","      <td>56024</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>201105</td>\n","      <td>5</td>\n","      <td>22.983871</td>\n","      <td>17.925806</td>\n","      <td>32.161290</td>\n","      <td>56.416129</td>\n","      <td>4.107692</td>\n","      <td>2.832258</td>\n","      <td>5.819355</td>\n","      <td>13.570968</td>\n","      <td>6.235484</td>\n","      <td>1010.735484</td>\n","      <td>2.402258</td>\n","      <td>8.935484</td>\n","      <td>19.396774</td>\n","      <td>18.174194</td>\n","      <td>13.241935</td>\n","      <td>5.278571</td>\n","      <td>279310</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     date  month  최고 기온(°C)  ...  5.0cm 지중온도(°C)  9-9강수(mm)  target\n","0  201101      1  -3.406452  ...       17.183871   0.741667  234587\n","1  201102      2   5.864286  ...       15.900000   7.850000  171376\n","2  201103      3   8.345161  ...       14.677419   1.537500  260687\n","3  201104      4  15.596667  ...       13.470000   7.346667   56024\n","4  201105      5  22.983871  ...       13.241935   5.278571  279310\n","\n","[5 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":134}]},{"cell_type":"code","metadata":{"id":"XJbtUo5JDwM-"},"source":["train = data[data['date'] < 201901]\n","test = data[data['date'] >= 201901]\n","train = train.drop(['month','date'], axis = 1)\n","test = test.drop(['month','date'], axis = 1)\n","X_train ,y_train = train.drop('target', axis = 1), train['target']\n","X_test, y_test = test.drop('target', axis = 1), test['target']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h6-Trt7aMvjV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626797981902,"user_tz":-540,"elapsed":577,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"825bc26d-6628-4b4c-e29f-81d790c7c5ec"},"source":["models = class_all_model.models()\n","\n","model_rmse = {}\n","model_score = {}\n","for i, j in models.items():\n","  # 각 모델의 y_pred를 구한다.\n","  model = j\n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  \n","  # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","  model_rmse[i] = mean_squared_error(y_test, y_pred)** 0.5\n","  model_score[i] = model.score(X_test, y_test)\n","  \n","print('model_rmse :', model_rmse)\n","print('model_score :', model_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[16:19:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","model_rmse : {'lr': 78325.09827240679, 'lgb': 75797.89955561589, 'xgb': 81680.24470263226, 'lasso': 78750.1097076197, 'ridge': 78184.71111877357, 'ada': 76621.93861409236, 'rfg': 72377.93977676617, 'gb': 80910.46144019102}\n","model_score : {'lr': -0.150674833387618, 'lgb': -0.07761855277210472, 'xgb': -0.25136723095120317, 'lasso': -0.16319640888495338, 'ridge': -0.14655367174470535, 'ada': -0.10117663922297715, 'rfg': 0.017430788675574904, 'gb': -0.22789172836122829}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kfEKcnnCMvhR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626797993031,"user_tz":-540,"elapsed":526,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"2a56b4ee-cda2-4116-97f2-4550c630158a"},"source":["## SMOTE를 사용해서 해주기\n","서울시립미술관_data = smogn.smoter(data = train, y = 'target', k = 10, samp_method = 'extreme', rel_thres = 0.80, rel_method = 'auto', rel_xtrm_type = 'high', rel_coef = 1.5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dist_matrix: 100%|##########| 7/7 [00:00<00:00, 204.03it/s]\n","synth_matrix: 100%|##########| 7/7 [00:00<00:00, 16.04it/s]\n","r_index: 100%|##########| 4/4 [00:00<00:00, 151.94it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pFadqJXoAur","executionInfo":{"status":"ok","timestamp":1626797994979,"user_tz":-540,"elapsed":474,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"7a2fccb5-b73f-47cc-8670-258c861ec166"},"source":["len(서울시립미술관_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["169"]},"metadata":{"tags":[]},"execution_count":141}]},{"cell_type":"code","metadata":{"id":"iNNN_srs463y"},"source":["X_train,y_train = 서울시립미술관_data.drop('target', axis = 1),서울시립미술관_data['target']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSub__QcoSTY"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9yYb8xXDRIe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626797998809,"user_tz":-540,"elapsed":587,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"bea9234c-2bd9-4ad6-8fc2-bfc1dafbb3ff"},"source":["models = class_all_model.models()\n","\n","model_rmse = {}\n","model_score = {}\n","for i, j in models.items():\n","  # 각 모델의 y_pred를 구한다.\n","  model = j\n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  \n","  # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","  model_rmse[i] = mean_squared_error(y_test, y_pred)** 0.5\n","  model_score[i] = model.score(X_test, y_test)\n","  \n","print('model_rmse :', model_rmse)\n","print('model_score :', model_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[16:19:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","model_rmse : {'lr': 83253.47239947671, 'lgb': 80834.97292681097, 'xgb': 79390.60248636309, 'lasso': 85893.88748581575, 'ridge': 83149.61125778813, 'ada': 73685.25865121876, 'rfg': 67120.98889430737, 'gb': 79200.49851589596}\n","model_score : {'lr': -0.30003615533273686, 'lgb': -0.22560157998310393, 'xgb': -0.18219444223567183, 'lasso': -0.383806084224797, 'ridge': -0.2967945123665001, 'ada': -0.01838487931667587, 'rfg': 0.15497917804063546, 'gb': -0.17653959705203115}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c8j9BBhpnP8d"},"source":["# 경복궁"]},{"cell_type":"code","metadata":{"id":"89gZfc8Ym09I"},"source":["data = pd.read_csv('/content/drive/MyDrive/Proj_WT/DataSets/Seoul/GyeongBokGung.csv')\n","data = data.rename(columns = {'경복궁': 'target'})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbqNGm75nz8f"},"source":["train = data[data['date'] < 201901]\n","test = data[data['date'] >= 201901]\n","train = train.drop(['month','date'], axis = 1)\n","test = test.drop(['month','date'], axis = 1)\n","X_train ,y_train = train.drop('target', axis = 1), train['target']\n","X_test, y_test = test.drop('target', axis = 1), test['target']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BYm-I_HzqG9S","executionInfo":{"status":"ok","timestamp":1626798029318,"user_tz":-540,"elapsed":1092,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"5d3b58ed-0cce-4c7e-f33a-91e22b4e4f7d"},"source":["models = class_all_model.models()\n","\n","model_rmse = {}\n","model_score = {}\n","for i, j in models.items():\n","  # 각 모델의 y_pred를 구한다.\n","  model = j\n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  \n","  # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","  model_rmse[i] = mean_squared_error(y_test, y_pred)** 0.5\n","  model_score[i] = model.score(X_test, y_test)\n","  \n","print('model_rmse :', model_rmse)\n","print('model_score :', model_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[16:20:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","model_rmse : {'lr': 113466.05981809794, 'lgb': 72864.56654139927, 'xgb': 62668.28873539363, 'lasso': 106193.02728398898, 'ridge': 108698.3800747375, 'ada': 72342.57191211899, 'rfg': 65222.95697591882, 'gb': 76287.11312130559}\n","model_score : {'lr': -0.3011013835798064, 'lgb': 0.46344782194693956, 'xgb': 0.6031056996846185, 'lasso': -0.13964921028689448, 'ridge': -0.1940577575923188, 'ada': 0.47110789995540664, 'rfg': 0.5700874142747832, 'gb': 0.4118588698025424}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LH0B-jErOmp","executionInfo":{"status":"ok","timestamp":1626798047336,"user_tz":-540,"elapsed":1098,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"e36e082b-7598-4c07-b74f-f28b912fd320"},"source":["# SMOTE 사용하기\n","경복궁_data = smogn.smoter(data = train, y = 'target', k = 10, samp_method = 'extreme', rel_thres = 0.80, rel_method = 'auto', rel_xtrm_type = 'high', rel_coef = 2.8)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dist_matrix: 100%|##########| 10/10 [00:00<00:00, 140.26it/s]\n","synth_matrix: 100%|##########| 10/10 [00:00<00:00, 24.17it/s]\n","r_index: 100%|##########| 5/5 [00:00<00:00, 167.14it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9pee-w2rrXY3"},"source":["X_train, y_train = 경복궁_data.drop('target', axis = 1), 경복궁_data['target']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gk-h02l-raBy","executionInfo":{"status":"ok","timestamp":1626798052670,"user_tz":-540,"elapsed":981,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}},"outputId":"ae83024d-d454-4881-968e-b9663b33cf2d"},"source":["models = class_all_model.models()\n","\n","model_rmse = {}\n","model_score = {}\n","for i, j in models.items():\n","  # 각 모델의 y_pred를 구한다.\n","  model = j\n","  model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  \n","  # 전체 모델을 돌려서 각 모델별로 rmse, score,model을 저장한다.\n","  model_rmse[i] = mean_squared_error(y_test, y_pred)** 0.5\n","  model_score[i] = model.score(X_test, y_test)\n","  \n","print('model_rmse :', model_rmse)\n","print('model_score :', model_score)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[16:20:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","model_rmse : {'lr': 90026.53575988422, 'lgb': 88389.10815244715, 'xgb': 75116.17925164873, 'lasso': 77919.644863906, 'ridge': 82938.8636391086, 'ada': 70529.92006662916, 'rfg': 76463.87560731353, 'gb': 75944.55936822902}\n","model_score : {'lr': 0.18093141667156754, 'lgb': 0.210455351016531, 'xgb': 0.42977511008663505, 'lasso': 0.3864172808386567, 'ridge': 0.30482306852602037, 'ada': 0.49728021913626064, 'rfg': 0.4091301853166584, 'gb': 0.41712889800831504}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UCrOuX7JwdiB"},"source":["# TSAUG (Time Series Data Augmentation)\n","\n"]},{"cell_type":"code","metadata":{"id":"zzekFW4TwuHE","executionInfo":{"status":"ok","timestamp":1626973559752,"user_tz":-540,"elapsed":495,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# !pip install tsaug"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"id":"qhvxhBxkryvc","executionInfo":{"status":"ok","timestamp":1626973560205,"user_tz":-540,"elapsed":8,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# import numpy as np\n","# import pandas as pd\n","# import matplotlib.pyplot as plt\n","# import seaborn as sns\n","\n","# from tsaug import TimeWarp, Crop, Quantize, Drift, Reverse\n","# my_augmenter = (\n","#     TimeWarp() * 5 # random time warping 5 times in parallel\n","#     +Crop(size = 300) # random crop subsequences with Length 300\n","#     +Quantize(n_levels = [10,20,30]) # random quantize to 10-, 20-, or 30- Level sets\n","#     +Drift(max_drift = (0.1,0.5)) @ 0.8 # with 80% probability, random drift the signal up to 10%\n","#     +Reverse()@0.5) # with 50% probability, reverse the sequence)"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"id":"DLOFMfd1Z5As","executionInfo":{"status":"ok","timestamp":1626973560207,"user_tz":-540,"elapsed":6,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# 경복궁 데이터로 시험해보기\n","# data.head()"],"execution_count":122,"outputs":[]},{"cell_type":"code","metadata":{"id":"UrT8jBOFjKIm","executionInfo":{"status":"ok","timestamp":1626973560208,"user_tz":-540,"elapsed":6,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# !git clone https://github.com/arundo/tsaug.git\n","# !cd tsaug/\n","# !git checkout develope"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"id":"qy2JCjcziI3F","executionInfo":{"status":"ok","timestamp":1626973560874,"user_tz":-540,"elapsed":7,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# train = data[data['date'] < 201901]\n","# test = data[data['date'] >= 201901]\n","# train = train.drop(['date'], axis = 1)\n","# test = test.drop(['date'], axis = 1)\n","# X_train ,y_train = train.drop('target', axis = 1), train['target']\n","# X_test, y_test = test.drop('target', axis = 1), test['target']"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"7c7ndfaxiums","executionInfo":{"status":"ok","timestamp":1626973560875,"user_tz":-540,"elapsed":6,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# X_train = X_train.values\n","# y_train = y_train.values"],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"id":"lxzvNgaNi5Nl","executionInfo":{"status":"ok","timestamp":1626973560875,"user_tz":-540,"elapsed":5,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# print(X_train.shape,y_train.shape)"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyGQ7pXULGWR","executionInfo":{"status":"ok","timestamp":1626973560876,"user_tz":-540,"elapsed":5,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# X_aug, Y_aug = my_augmenter.augment(X_train, y_train)\n","# plot(X_aug, Y_aug)"],"execution_count":127,"outputs":[]},{"cell_type":"code","metadata":{"id":"7sC76wQUiUfj","executionInfo":{"status":"ok","timestamp":1626973561687,"user_tz":-540,"elapsed":4,"user":{"displayName":"박정열","photoUrl":"","userId":"02719436629239662639"}}},"source":["# 실패.... 변수를 하나만 받아야 하기 때문이다."],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKR9YrtwiXvW"},"source":[""],"execution_count":null,"outputs":[]}]}